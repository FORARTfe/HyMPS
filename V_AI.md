# [![VIDEO](https://flat.badgen.net/badge/HyMPS/VIDEO/green?scale=1.8)](https://github.com/forart/HyMPS#-1 "VIDEO resources") [![AI-based projects](https://flat.badgen.net/badge/HyMPS/AI-based%20projects/blue?scale=1.8&label=)](https://github.com/forart/HyMPS#ai-based-1 "AI-based") <img align="right" alt="stable" src="https://user-images.githubusercontent.com/171307/210727719-14b940a2-d1dc-4991-b6a4-7add74463ce8.png" width="5%" />

### [Editing](#editing-) - [Enhancers](#enhancers-) - [Mixing](#mixing-) - [Restoring](#restoring-) - [Denoisers](#denoisers-) - [Deblurrers](#deblurrers-) - [Artifacts reduction](#artifacts-reduction-) - [Colorization](#colorization-)

$\color{orange}\textsf{\Large\&#x24D8;\kern{0.1cm}\small {SORTING: Language (a>z) > License (openness) > Name / URL (a>z)}}$ 

### Editing [⌂](#--)
|Name + URL|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[ai_video_editor](https://github.com/alumiaCoder/expS_ai_video_editor#readme)|A yolov7 based, human aware video editor for real time video manipulation|[![](https://img.shields.io/github/languages/top/alumiaCoder/expS_ai_video_editor?color=pink&style=flat-square)](https://github.com/alumiaCoder/expS_ai_video_editor/graphs/contributors)|[![](https://flat.badgen.net/github/license/alumiaCoder/expS_ai_video_editor?label=)](https://github.com/alumiaCoder/expS_ai_video_editor/blob/main/LICENSE)|[![](https://flat.badgen.net/github/last-commit/alumiaCoder/expS_ai_video_editor/main?label=)](https://github.com/alumiaCoder/expS_ai_video_editor/graphs/code-frequency)|
|[Framester](https://github.com/mohitgupta3/Framester#readme)|An AI driven Video manipulation toolkit|[![](https://img.shields.io/github/languages/top/mohitgupta3/Framester?color=pink&style=flat-square)](https://github.com/mohitgupta3/Framester/graphs/contributors)|[![](https://flat.badgen.net/github/license/mohitgupta3/Framester?label=)](https://github.com/mohitgupta3/Framester/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/mohitgupta3/Framester/main?label=)](https://github.com/mohitgupta3/Framester/graphs/code-frequency)|
|[VideoEditor](https://github.com/parthdomadia/VideoEditor#readme)|AI assisted video editor based on motion difference between the frames of given videos|[![](https://img.shields.io/github/languages/top/parthdomadia/VideoEditor?color=pink&style=flat-square)](https://github.com/parthdomadia/VideoEditor/graphs/contributors)|[![](https://flat.badgen.net/github/license/parthdomadia/VideoEditor?label=)](https://github.com/parthdomadia/VideoEditor/blob/master/LICENSE.md)|[![](https://flat.badgen.net/github/last-commit/parthdomadia/VideoEditor/master?label=)](https://github.com/parthdomadia/VideoEditor/graphs/code-frequency)|
|[folioviz.ai](https://github.com/darekm101/folioviz.ai#readme)|Video Editor driven by Ai|[![](https://img.shields.io/github/languages/top/darekm101/folioviz.ai?color=pink&style=flat-square)](https://github.com/darekm101/folioviz.ai/graphs/contributors)|[![](https://flat.badgen.net/github/license/darekm101/folioviz.ai?label=)](https://github.com/darekm101/folioviz.ai/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/darekm101/folioviz.ai/main?label=)](https://github.com/darekm101/folioviz.ai/graphs/code-frequency)|
|[ClipIQ](https://github.com/michaelbudko/ClipIQ#readme)|AI-powered video editor|[![](https://img.shields.io/github/languages/top/michaelbudko/ClipIQ?color=pink&style=flat-square)](https://github.com/michaelbudko/ClipIQ/graphs/contributors)|[![](https://flat.badgen.net/github/license/michaelbudko/ClipIQ?label=)](https://github.com/michaelbudko/ClipIQ/blob/main/LICENSE)|[![](https://flat.badgen.net/github/last-commit/michaelbudko/ClipIQ/main?label=)](https://github.com/michaelbudko/ClipIQ/graphs/code-frequency)|

### Enhancers [⌂](#--)
|Name + URL|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[InterUpTool](https://github.com/GhostPoro/InterUpTool#readme)|GUI Tool for control, queue and automate video enhancing process, provided by FFMPEG video encoder, Real-ESRGAN image upscaler and RIFE/DAIN video frame interpolators|[![](https://img.shields.io/github/languages/top/GhostPoro/InterUpTool?color=pink&style=flat-square)](https://github.com/GhostPoro/InterUpTool/graphs/contributors)|[![](https://flat.badgen.net/github/license/GhostPoro/InterUpTool?label=)](https://github.com/GhostPoro/InterUpTool/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/GhostPoro/InterUpTool?label=)](https://github.com/GhostPoro/InterUpTool/graphs/code-frequency)|
|[enhancr](https://github.com/mafiosnik777/enhancr#readme)|An elegant and easy to use GUI for Video Frame Interpolation and Video Upscaling which takes advantage of artificial intelligence|[![](https://img.shields.io/github/languages/top/mafiosnik777/enhancr?color=pink&style=flat-square)](https://github.com/mafiosnik777/enhancr/graphs/contributors)|[![](https://flat.badgen.net/github/license/mafiosnik777/enhancr?label=)](https://github.com/mafiosnik777/enhancr/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/mafiosnik777/enhancr?label=)](https://github.com/mafiosnik777/enhancr/graphs/code-frequency)|
|[Flowframes](https://github.com/n00mkrad/flowframes#readme)|Windows GUI for video interpolation using DAIN (NCNN) or RIFE (CUDA/NCNN)|[![](https://img.shields.io/github/languages/top/n00mkrad/flowframes?color=pink&style=flat-square)](https://github.com/n00mkrad/flowframes/graphs/contributors)|[![](https://flat.badgen.net/github/license/n00mkrad/flowframes?label=)](https://github.com/n00mkrad/flowframes/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/n00mkrad/flowframes/main?label=)](https://github.com/n00mkrad/flowframes/graphs/code-frequency)|.
|[PRINCIPI](https://github.com/Rob00t-unimi/progetto-principi#readme)|Fully customizable video frame rate up-conversion and video resolution upscaling with sharpening and denoising editor with GUI|[![](https://img.shields.io/github/languages/top/Rob00t-unimi/progetto-principi?color=pink&style=flat-square)](https://github.com/Rob00t-unimi/progetto-principi/graphs/contributors)|[![](https://flat.badgen.net/github/license/Rob00t-unimi/progetto-principi?label=)](https://github.com/Rob00t-unimi/progetto-principi/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/Rob00t-unimi/progetto-principi/main?label=)](https://github.com/Rob00t-unimi/progetto-principi/graphs/code-frequency)|
|[VSGAN-tensorrt-docker](https://github.com/styler00dollar/VSGAN-tensorrt-docker#readme)|Super resolution models and video frame interpolation models and also trying to speed them up with TensorRT|[![](https://img.shields.io/github/languages/top/styler00dollar/VSGAN-tensorrt-docker?color=pink&style=flat-square)](https://github.com/styler00dollar/VSGAN-tensorrt-docker/graphs/contributors)|[![](https://flat.badgen.net/github/license/styler00dollar/VSGAN-tensorrt-docker?label=)](https://github.com/styler00dollar/VSGAN-tensorrt-docker/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/styler00dollar/VSGAN-tensorrt-docker?label=)](https://github.com/styler00dollar/VSGAN-tensorrt-docker/graphs/code-frequency)|

### Mixing [⌂](#--)
|Name + URL|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Automatic Mixing of Audio and Video](https://github.com/rissalhedna/Automatic-Mixing-of-Audio-and-Video#readme)|Proposing a comprehensive method for assisting video editing tasks using neural networks|[![](https://img.shields.io/github/languages/top/rissalhedna/Automatic-Mixing-of-Audio-and-Video?color=pink&style=flat-square)](https://github.com/rissalhedna/Automatic-Mixing-of-Audio-and-Video/graphs/contributors)|[![](https://flat.badgen.net/github/license/rissalhedna/Automatic-Mixing-of-Audio-and-Video?label=)](https://github.com/rissalhedna/Automatic-Mixing-of-Audio-and-Video/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/rissalhedna/Automatic-Mixing-of-Audio-and-Video/main?label=)](https://github.com/rissalhedna/Automatic-Mixing-of-Audio-and-Video/graphs/code-frequency)|

### Restoring [⌂](#--)
|Name + URL|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[TOFlow](http://toflow.csail.mit.edu/)|[Video Enhancement with Task-Oriented Flow](http://toflow.csail.mit.edu/) IJCV publication implementation|[![](https://img.shields.io/github/languages/top/anchen1011/toflow?color=pink&style=flat-square)](https://github.com/anchen1011/toflow/graphs/contributors)|[![](https://flat.badgen.net/github/license/anchen1011/toflow?label=)](https://github.com/anchen1011/toflow/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/anchen1011/toflow?label=)](https://github.com/anchen1011/toflow/graphs/code-frequency)|
|[DeOldify](https://github.com/jantic/DeOldify#readme)|A Deep Learning based project for colorizing and restoring old images (and video!)|[![](https://img.shields.io/github/languages/top/jantic/DeOldify?color=pink&style=flat-square)](https://github.com/jantic/DeOldify/graphs/contributors)|[![](https://flat.badgen.net/github/license/jantic/DeOldify?label=)](https://github.com/jantic/DeOldify/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/jantic/DeOldify/master?label=)](https://github.com/jantic/DeOldify/graphs/code-frequency)|
|[BasicSR](https://github.com/XPixelGroup/BasicSR#readme)|Open Source Image and Video Restoration Toolbox for Super-resolution, Denoise, Deblurring, etc|[![](https://img.shields.io/github/languages/top/XPixelGroup/BasicSR?color=pink&style=flat-square)](https://github.com/XPixelGroup/BasicSR/graphs/contributors)|[![](https://flat.badgen.net/github/license/XPixelGroup/BasicSR?label=)](https://github.com/XPixelGroup/BasicSR/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/XPixelGroup/BasicSR?label=)](https://github.com/XPixelGroup/BasicSR/graphs/code-frequency)|


### Denoisers [⌂](#--)
|Name + URL|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Model-Blind Video Denoising Via Frame-to-frame Training](https://github.com/tehret/blind-denoising#readme)|[Model-blind Video Denoising Via Frame-to-frame Training](https://arxiv.org/abs/1811.12766) implementation|[![](https://img.shields.io/github/languages/top/tehret/blind-denoising?color=pink&style=flat-square)](https://github.com/tehret/blind-denoising/graphs/contributors)|[![](https://flat.badgen.net/github/license/tehret/blind-denoising?label=)](https://github.com/tehret/blind-denoising/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/tehret/blind-denoising?label=)](https://github.com/tehret/blind-denoising/graphs/code-frequency)|
|[Non-local Bayesian Video Denoising](https://github.com/pariasm/vnlb#readme)|A C/C++ implementation of the [Video Denoising via Empirical Bayesian Estimation of Space-Time Patches](https://link.springer.com/article/10.1007/s10851-017-0742-4) paper|[![](https://img.shields.io/github/languages/top/pariasm/vnlb?color=pink&style=flat-square)](https://github.com/pariasm/vnlb/graphs/contributors)|[![](https://flat.badgen.net/github/license/pariasm/vnlb?label=)](https://github.com/pariasm/vnlb/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/pariasm/vnlb?label=)](https://github.com/pariasm/vnlb/graphs/code-frequency)|
|[RNLF](https://github.com/csutour/RNLF#readme)|Image noise estimation and RNL image and video denoising|[![](https://img.shields.io/github/languages/top/csutour/RNLF?color=pink&style=flat-square)](https://github.com/csutour/RNLF/graphs/contributors)|[![](https://flat.badgen.net/github/license/csutour/RNLF?label=)](https://github.com/csutour/RNLF/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/csutour/RNLF?label=)](https://github.com/csutour/RNLF/graphs/code-frequency)|
|[VIDOSAT video denoising](https://github.com/wenbihan/vidosat_icip2015#readme)|A video denoising framework based on online 3D spatio-temporal sparsifying transform learning|[![](https://img.shields.io/github/languages/top/wenbihan/vidosat_icip2015?color=pink&style=flat-square)](https://github.com/wenbihan/vidosat_icip2015/graphs/contributors)|[![](https://flat.badgen.net/github/license/wenbihan/vidosat_icip2015?label=)](https://github.com/wenbihan/vidosat_icip2015/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/wenbihan/vidosat_icip2015?label=)](https://github.com/wenbihan/vidosat_icip2015/graphs/code-frequency)|
|[SALT based Video Denoising](https://github.com/wenbihan/salt_iccv2017#readme)|A video denoising method, based on a novel Sparse And Low-rank Tensor (SALT) model|[![](https://img.shields.io/github/languages/top/wenbihan/salt_iccv2017?color=pink&style=flat-square)](https://github.com/wenbihan/salt_iccv2017/graphs/contributors)|[![](https://flat.badgen.net/github/license/wenbihan/salt_iccv2017?label=)](https://github.com/wenbihan/salt_iccv2017/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/wenbihan/salt_iccv2017?label=)](https://github.com/wenbihan/salt_iccv2017/graphs/code-frequency)|
|[vnlnet](https://github.com/axeldavy/vnlnet#readme)|A Video denoising CNN with Non-locality information|[![](https://img.shields.io/github/languages/top/axeldavy/vnlnet?color=pink&style=flat-square)](https://github.com/axeldavy/vnlnet/graphs/contributors)|[![](https://flat.badgen.net/github/license/axeldavy/vnlnet?label=)](https://github.com/axeldavy/vnlnet/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/axeldavy/vnlnet?label=)](https://github.com/axeldavy/vnlnet/graphs/code-frequency)|
|[FastDVDnet](https://github.com/m-tassano/fastdvdnet#readme)|A state-of-the-art, simple and fast network for Deep Video Denoising which uses no motion compensation|[![](https://img.shields.io/github/languages/top/m-tassano/fastdvdnet?color=pink&style=flat-square)](https://github.com/m-tassano/fastdvdnet/graphs/contributors)|[![](https://flat.badgen.net/github/license/m-tassano/fastdvdnet?label=)](https://github.com/m-tassano/fastdvdnet/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/m-tassano/fastdvdnet?label=)](https://github.com/m-tassano/fastdvdnet/graphs/code-frequency)|
|[MaskDnGAN](https://github.com/avinashpaliwal/MaskDnGAN#readme)|This is the official implementation of  "[Multi-Stage Raw Video Denoising with Adversarial Loss and Gradient Mask](https://arxiv.org/abs/2103.02861)" paper|[![](https://img.shields.io/github/languages/top/avinashpaliwal/MaskDnGAN?color=pink&style=flat-square)](https://github.com/avinashpaliwal/MaskDnGAN/graphs/contributors)|[![](https://flat.badgen.net/github/license/avinashpaliwal/MaskDnGAN?label=)](https://github.com/avinashpaliwal/MaskDnGAN/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/avinashpaliwal/MaskDnGAN?label=)](https://github.com/avinashpaliwal/MaskDnGAN/graphs/code-frequency)|
|[ViDeNN](https://github.com/clausmichele/ViDeNN#readme)|[Deep Blind Video Denoising](https://arxiv.org/abs/1904.10898) implementation|[![](https://img.shields.io/github/languages/top/clausmichele/ViDeNN?color=pink&style=flat-square)](https://github.com/clausmichele/ViDeNN/graphs/contributors)|[![](https://flat.badgen.net/github/license/clausmichele/ViDeNN?label=)](https://github.com/clausmichele/ViDeNN/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/clausmichele/ViDeNN?label=)](https://github.com/clausmichele/ViDeNN/graphs/code-frequency)|
|[Deformable-Kernels-For-Video-Denoising](https://github.com/z-bingo/Deformable-Kernels-For-Video-Denoising#readme)|An implement of paper [Learning Deformable Kernels for Image and Video Denoising](https://arxiv.org/abs/1904.06903) in PyTorch|[![](https://img.shields.io/github/languages/top/z-bingo/Deformable-Kernels-For-Video-Denoising?color=pink&style=flat-square)](https://github.com/z-bingo/Deformable-Kernels-For-Video-Denoising/graphs/contributors)|[![](https://flat.badgen.net/github/license/z-bingo/Deformable-Kernels-For-Video-Denoising?label=)](https://github.com/z-bingo/Deformable-Kernels-For-Video-Denoising/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/z-bingo/Deformable-Kernels-For-Video-Denoising?label=)](https://github.com/z-bingo/Deformable-Kernels-For-Video-Denoising/graphs/code-frequency)|
|[PaCNet](https://github.com/grishavak/PaCNet-denoiser#readme)|This is the official implementation of "[Patch Craft: Video Denoising by Deep Modeling and Patch Matching](https://arxiv.org/abs/2103.13767)" paper|[![](https://img.shields.io/github/languages/top/grishavak/PaCNet-denoiser?color=pink&style=flat-square)](https://github.com/grishavak/PaCNet-denoiser/graphs/contributors)|[![](https://flat.badgen.net/github/license/grishavak/PaCNet-denoiser?label=)](https://github.com/grishavak/PaCNet-denoiser/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/grishavak/PaCNet-denoiser?label=)](https://github.com/grishavak/PaCNet-denoiser/graphs/code-frequency)|
|[STPAN](https://github.com/jojo23333/STPAN#readme)|This is the official implementation of "[Learning Spatial and Spatio-Temporal Pixel Aggregations for Image and Video Denoising](https://arxiv.org/abs/2101.10760)" paper|[![](https://img.shields.io/github/languages/top/jojo23333/STPAN?color=pink&style=flat-square)](https://github.com/jojo23333/STPAN/graphs/contributors)|[![](https://flat.badgen.net/github/license/jojo23333/STPAN?label=)](https://github.com/jojo23333/STPAN/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/jojo23333/STPAN?label=)](https://github.com/jojo23333/STPAN/graphs/code-frequency)|
|[RViDeNet](https://github.com/cao-cong/RViDeNet#readme)|This is the official implementation of "[Supervised Raw Video Denoising with a Benchmark Dataset on Dynamic Scenes](https://arxiv.org/abs/2003.14013) paper|[![](https://img.shields.io/github/languages/top/cao-cong/RViDeNet?color=pink&style=flat-square)](https://github.com/cao-cong/RViDeNet/graphs/contributors)|[![](https://flat.badgen.net/github/license/cao-cong/RViDeNet?label=)](https://github.com/cao-cong/RViDeNet/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/cao-cong/RViDeNet?label=)](https://github.com/cao-cong/RViDeNet/graphs/code-frequency)|

### Deblurrers [⌂](#--)
|Name + URL|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Deep Video Deblurring for Hand-held Cameras](http://www.cs.ubc.ca/labs/imager/tr/2017/DeepVideoDeblurring/)|This is the demo code for "[Deep Video Deblurring for Hand-held Cameras](http://www.cs.ubc.ca/labs/imager/tr/2017/DeepVideoDeblurring/)" paper|[![](https://img.shields.io/github/languages/top/shuochsu/DeepVideoDeblurring?color=pink&style=flat-square)](https://github.com/shuochsu/DeepVideoDeblurring/graphs/contributors)|[![](https://flat.badgen.net/github/license/shuochsu/DeepVideoDeblurring?label=)](https://github.com/shuochsu/DeepVideoDeblurring/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/shuochsu/DeepVideoDeblurring?label=)](https://github.com/shuochsu/DeepVideoDeblurring/graphs/code-frequency)|
|[PVDNet](https://github.com/codeslake/PVDNet#readme)|Official PyTorch Implementation for "[Recurrent Video Deblurring with Blur-Invariant Motion Estimation and Pixel Volumes](https://arxiv.org/abs/2108.09982)"paper|[![](https://img.shields.io/github/languages/top/codeslake/PVDNet?color=pink&style=flat-square)](https://github.com/codeslake/PVDNet/graphs/contributors)|[![](https://flat.badgen.net/github/license/codeslake/PVDNet?label=)](https://github.com/codeslake/PVDNet/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/codeslake/PVDNet?label=)](https://github.com/codeslake/PVDNet/graphs/code-frequency)|
|[CDVD-TSP](https://github.com/csbhr/CDVD-TSP#readme)|Official implementation of "[Cascaded Deep Video Deblurring Using Temporal Sharpness Prior](https://arxiv.org/abs/2004.02501)" paper|[![](https://img.shields.io/github/languages/top/csbhr/CDVD-TSP?color=pink&style=flat-square)](https://github.com/csbhr/CDVD-TSP/graphs/contributors)|[![](https://flat.badgen.net/github/license/csbhr/CDVD-TSP?label=)](https://github.com/csbhr/CDVD-TSP/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/csbhr/CDVD-TSP?label=)](https://github.com/csbhr/CDVD-TSP/graphs/code-frequency)|
|[ESTRNN & BSD](https://github.com/zzh-tech/ESTRNN#readme)|This work presents an efficient RNN-based model and the first real-world dataset for image/video deblurring|[![](https://img.shields.io/github/languages/top/zzh-tech/ESTRNN?color=pink&style=flat-square)](https://github.com/zzh-tech/ESTRNN/graphs/contributors)|[![](https://flat.badgen.net/github/license/zzh-tech/ESTRNN?label=)](https://github.com/zzh-tech/ESTRNN/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/zzh-tech/ESTRNN?label=)](https://github.com/zzh-tech/ESTRNN/graphs/code-frequency)|
|[STFAN](https://github.com/sczhou/STFAN#readme)|Code repo for the "[Spatio-Temporal Filter Adaptive Network for Video Deblurring](https://shangchenzhou.com/projects/stfan/)" paper|[![](https://img.shields.io/github/languages/top/sczhou/STFAN?color=pink&style=flat-square)](https://github.com/sczhou/STFAN/graphs/contributors)|[![](https://flat.badgen.net/github/license/sczhou/STFAN?label=)](https://github.com/sczhou/STFAN/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/sczhou/STFAN?label=)](https://github.com/sczhou/STFAN/graphs/code-frequency)|

### Artifacts reduction [⌂](#--)
|Name + URL|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[MFQE 2.0](https://github.com/RyanXingQL/MFQEv2.0#readme)|Official repository of "[MFQE 2.0: A New Approach for Multi-frame Quality Enhancement on Compressed Video](https://arxiv.org/abs/1902.09707)" paper|[![](https://img.shields.io/github/languages/top/RyanXingQL/MFQEv2.0?color=pink&style=flat-square)](https://github.com/RyanXingQL/MFQEv2.0/graphs/contributors)|[![](https://flat.badgen.net/github/license/RyanXingQL/MFQEv2.0?label=)](https://github.com/RyanXingQL/MFQEv2.0/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/RyanXingQL/MFQEv2.0?label=)](https://github.com/RyanXingQL/MFQEv2.0/graphs/code-frequency)|
|[RFDA-Pytorch](https://github.com/zhaominyiz/RFDA-PyTorch#readme)|Official Code for "[Recursive Fusion and Deformable Spatiotemporal Attention for Video Compression Artifact Reduction](https://arxiv.org/abs/2108.02110)" paper|[![](https://img.shields.io/github/languages/top/zhaominyiz/RFDA-PyTorch?color=pink&style=flat-square)](https://github.com/zhaominyiz/RFDA-PyTorch/graphs/contributors)|[![](https://flat.badgen.net/github/license/zhaominyiz/RFDA-PyTorch?label=)](https://github.com/zhaominyiz/RFDA-PyTorch/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/zhaominyiz/RFDA-PyTorch?label=)](https://github.com/zhaominyiz/RFDA-PyTorch/graphs/code-frequency)|
|[STDF](https://github.com/RyanXingQL/STDF-PyTorch#readme)|PyTorch implementation of [Spatio-Temporal Deformable Convolution for Compressed Video Quality Enhancement](https://www.researchgate.net/publication/342540674_Spatio-Temporal_Deformable_Convolution_for_Compressed_Video_Quality_Enhancement) paper|[![](https://img.shields.io/github/languages/top/RyanXingQL/STDF-PyTorch?color=pink&style=flat-square)](https://github.com/RyanXingQL/STDF-PyTorch/graphs/contributors)|[![](https://flat.badgen.net/github/license/RyanXingQL/STDF-PyTorch?label=)](https://github.com/RyanXingQL/STDF-PyTorch/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/RyanXingQL/STDF-PyTorch?label=)](https://github.com/RyanXingQL/STDF-PyTorch/graphs/code-frequency)|
|[NL-ConvLSTM](https://github.com/xyiyy/NL-ConvLSTM#readme)|[Non-Local ConvLSTM for Video Compression Artifact Reduction](https://arxiv.org/abs/1910.12286) implementation|[![](https://img.shields.io/github/languages/top/xyiyy/NL-ConvLSTM?color=pink&style=flat-square)](https://github.com/xyiyy/NL-ConvLSTM/graphs/contributors)|[![](https://flat.badgen.net/github/license/xyiyy/NL-ConvLSTM?label=)](https://github.com/xyiyy/NL-ConvLSTM/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/xyiyy/NL-ConvLSTM?label=)](https://github.com/xyiyy/NL-ConvLSTM/graphs/code-frequency)|
|[QG-ConvLSTM](https://github.com/ryangchn/QG-ConvLSTM#readme)|Project page of "[Quality-Gated Convolutional LSTM for Enhancing Compressed Video](https://arxiv.org/abs/1903.04596)" paper|[![](https://img.shields.io/github/languages/top/ryangchn/QG-ConvLSTM?color=pink&style=flat-square)](https://github.com/ryangchn/QG-ConvLSTM/graphs/contributors)|[![](https://flat.badgen.net/github/license/ryangchn/QG-ConvLSTM?label=)](https://github.com/ryangchn/QG-ConvLSTM/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/ryangchn/QG-ConvLSTM?label=)](https://github.com/ryangchn/QG-ConvLSTM/graphs/code-frequency)|


### Colorization [⌂](#--)
|Name + URL|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Deep Exemplar-based Video Colorization](https://github.com/zhangmozhe/Deep-Exemplar-based-Video-Colorization#readme)|PyTorch implementation for the [Deep Exemplar-based Video Colorization](https://arxiv.org/abs/1906.09909) paper|[![](https://img.shields.io/github/languages/top/zhangmozhe/Deep-Exemplar-based-Video-Colorization?color=pink&style=flat-square)](https://github.com/zhangmozhe/Deep-Exemplar-based-Video-Colorization/graphs/contributors)|[![](https://flat.badgen.net/github/license/zhangmozhe/Deep-Exemplar-based-Video-Colorization?label=)](https://github.com/zhangmozhe/Deep-Exemplar-based-Video-Colorization/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/zhangmozhe/Deep-Exemplar-based-Video-Colorization?label=)](https://github.com/zhangmozhe/Deep-Exemplar-based-Video-Colorization/graphs/code-frequency)|
|[DeepRemaster](http://iizuka.cs.tsukuba.ac.jp/projects/remastering/)|PyTorch implementation for the "[DeepRemaster: Temporal Source-Reference Attention Networks for Comprehensive Video Enhancement](https://arxiv.org/abs/2009.08692)" paper|[![](https://img.shields.io/github/languages/top/satoshiiizuka/siggraphasia2019_remastering?color=pink&style=flat-square)](https://github.com/satoshiiizuka/siggraphasia2019_remastering/graphs/contributors)|[![](https://flat.badgen.net/badge/license/CC-BYNCSA/blue?label=)](https://github.com/satoshiiizuka/siggraphasia2019_remastering/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/satoshiiizuka/siggraphasia2019_remastering?label=)](https://github.com/satoshiiizuka/siggraphasia2019_remastering/graphs/code-frequency)|
|[Fully Automatic Video Colorization](https://leichenyang.weebly.com/project-color.html)|Tensorflow implementation for the "[Fully Automatic Video Colorization with Self-Regularization and Diversity](https://arxiv.org/abs/1908.01311)" paper|[![](https://img.shields.io/github/languages/top/ChenyangLEI/automatic-video-colorization?color=pink&style=flat-square)](https://github.com/ChenyangLEI/automatic-video-colorization/graphs/contributors)|[![](https://flat.badgen.net/github/license/ChenyangLEI/automatic-video-colorization?label=)](https://github.com/ChenyangLEI/automatic-video-colorization/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/ChenyangLEI/automatic-video-colorization?label=)](https://github.com/ChenyangLEI/automatic-video-colorization/graphs/code-frequency)|
|[SVCNet](https://github.com/zhaoyuzhi/SVCNet#readme)|PyTorch implementation of the "[SVCNet: Scribble-based Video Colorization Network with Temporal Aggregation" paper](https://arxiv.org/abs/2303.11591)|[![](https://img.shields.io/github/languages/top/zhaoyuzhi/SVCNet?color=pink&style=flat-square)](https://github.com/zhaoyuzhi/SVCNet/graphs/contributors)|[![](https://flat.badgen.net/github/license/zhaoyuzhi/SVCNet?label=)](https://github.com/zhaoyuzhi/SVCNet/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/zhaoyuzhi/SVCNet?label=)](https://github.com/zhaoyuzhi/SVCNet/graphs/code-frequency)|

Other resources:
- [Video Frame Interpolation Rankings and Video Deblurring Rankings](https://github.com/AIVFI/Video-Frame-Interpolation-Rankings-and-Video-Deblurring-Rankings)
- [Awesome Video Diffusion](https://github.com/showlab/Awesome-Video-Diffusion#awesome-video-diffusion--)
- [Awesome-Image-Colorization](https://github.com/MarkMoHR/Awesome-Image-Colorization#awesome-image-colorization)/[Video Colorization](https://github.com/MarkMoHR/Awesome-Image-Colorization#4-video-colorization)
- [Video restoration based on deep learning: a comprehensive survey](https://github.com/claudiom4sir/VideoRestoration)
