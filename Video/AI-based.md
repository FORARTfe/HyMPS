# [![VIDEO](https://flat.badgen.net/badge/HyMPS/VIDEO/green?scale=1.8)](https://github.com/FORARTfe/HyMPS#-1 "VIDEO section") [![AI-based](https://flat.badgen.net/badge/HyMPS/AI-based/blue?scale=1.8&label=)](https://github.com/FORARTfe/HyMPS/blob/main/Video/AI-based.md#-- "AI-based page") <img align="right" alt="stable" src="https://user-images.githubusercontent.com/171307/210727719-14b940a2-d1dc-4991-b6a4-7add74463ce8.png" width="5%" />

### [Aligning/Synching](#aligningsynching-) - [Editing](#editing-) - [Enhancers](#enhancers-) - [Mixing](#mixing-) - [Restoring](#restoring-) - [Denoisers](#denoisers-) - [Deblurrers](#deblurrers-) - [Artifacts reduction](#artifacts-reduction-) - [Colorization](#colorization-) - [Compression](#compression-) - [Stabilizers](#stabilizers-) - [Upscalers](#upscalers-) - [Web-oriented](#web-oriented-) - [Other resources](#other-resources-)

> [!WARNING]
> $\color{orange}\textsf{{SORTING: Language (a>z) > License (openness) > Repository (a>z)}}$

### Aligning/Synching [⌂](#--)
|Resource|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[AV-Align](https://github.com/SajayR/AV-Align#readme)|Unsupervised Audio-Visual feature alignment: audio and visual features embedding onto the same latent space for downstream tasks|[![](https://img.shields.io/github/languages/top/SajayR/AV-Align?color=pink&style=flat-square)](https://github.com/SajayR/AV-Align/graphs/contributors)|[![](https://flat.badgen.net/github/license/SajayR/AV-Align?label=)](https://github.com/SajayR/AV-Align/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/SajayR/AV-Align?style=flat-square&label=)](https://github.com/SajayR/AV-Align/graphs/code-frequency)|

### Editing [⌂](#--)
|Resource|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[AIVideoEditor](https://github.com/rameshavinash94/AIVideoEditor#readme)|An all-in-one collaborative AI audio and video editing application that is as simple to use as editing a Google Doc based on text extracted from transcription|[![](https://img.shields.io/github/languages/top/rameshavinash94/AIVideoEditor?color=pink&style=flat-square)](https://github.com/rameshavinash94/AIVideoEditor/graphs/contributors)|[![](https://flat.badgen.net/github/license/rameshavinash94/AIVideoEditor?label=)](https://github.com/rameshavinash94/AIVideoEditor/issues/1)|[![](https://img.shields.io/github/last-commit/rameshavinash94/AIVideoEditor?style=flat-square&label=)](https://github.com/rameshavinash94/AIVideoEditor/graphs/code-frequency)|
|[ai_video_editor](https://github.com/alumiaCoder/expS_ai_video_editor#readme)|A yolov7 based, human aware video editor for real time video manipulation|[![](https://img.shields.io/github/languages/top/alumiaCoder/expS_ai_video_editor?color=pink&style=flat-square)](https://github.com/alumiaCoder/expS_ai_video_editor/graphs/contributors)|[![](https://flat.badgen.net/github/license/alumiaCoder/expS_ai_video_editor?label=)](https://github.com/alumiaCoder/expS_ai_video_editor/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/alumiaCoder/expS_ai_video_editor?style=flat-square&label=)](https://github.com/alumiaCoder/expS_ai_video_editor/graphs/code-frequency)|
|[AutomEditor](https://github.com/toxtli/AutomEditor#readme)|A video editor that helps video bloggers to remove bloopers automatically|[![](https://img.shields.io/github/languages/top/toxtli/AutomEditor?color=pink&style=flat-square)](https://github.com/toxtli/AutomEditor/graphs/contributors)|[![](https://flat.badgen.net/github/license/toxtli/AutomEditor?label=)](https://github.com/toxtli/AutomEditor/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/toxtli/AutomEditor?style=flat-square&label=)](https://github.com/toxtli/AutomEditor/graphs/code-frequency)|
|[Framester](https://github.com/mohitgupta3/Framester#readme)|An AI driven Video manipulation toolkit|[![](https://img.shields.io/github/languages/top/mohitgupta3/Framester?color=pink&style=flat-square)](https://github.com/mohitgupta3/Framester/graphs/contributors)|[![](https://flat.badgen.net/github/license/mohitgupta3/Framester?label=)](https://github.com/mohitgupta3/Framester/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/mohitgupta3/Framester?style=flat-square&label=)](https://github.com/mohitgupta3/Framester/graphs/code-frequency)|
|[VideoEditor](https://github.com/parthdomadia/VideoEditor#readme)|AI assisted video editor based on motion difference between the frames of given videos|[![](https://img.shields.io/github/languages/top/parthdomadia/VideoEditor?color=pink&style=flat-square)](https://github.com/parthdomadia/VideoEditor/graphs/contributors)|[![](https://flat.badgen.net/github/license/parthdomadia/VideoEditor?label=)](https://github.com/parthdomadia/VideoEditor/blob/master/LICENSE.md)|[![](https://img.shields.io/github/last-commit/parthdomadia/VideoEditor?style=flat-square&label=)](https://github.com/parthdomadia/VideoEditor/graphs/code-frequency)|
|[Automatic Video Editor for Reportages Assisted by Unsupervised Machine Learning](https://github.com/goodPointP/Automatic-Video-Editor-for-Reportages-Assisted-by-Unsupervised-Machine-Learning#readme)|Code for [Automatic Video Editor for Reportages Assisted by Unsupervised Machine Learning](https://www.springerprofessional.de/en/automatic-video-editor-for-reportages-assisted-by-unsupervised-m/19036978) paper|[![](https://img.shields.io/github/languages/top/goodPointP/Automatic-Video-Editor-for-Reportages-Assisted-by-Unsupervised-Machine-Learning?color=pink&style=flat-square)](https://github.com/goodPointP/Automatic-Video-Editor-for-Reportages-Assisted-by-Unsupervised-Machine-Learning/graphs/contributors)|[![](https://flat.badgen.net/github/license/goodPointP/Automatic-Video-Editor-for-Reportages-Assisted-by-Unsupervised-Machine-Learning?label=)](https://github.com/goodPointP/Automatic-Video-Editor-for-Reportages-Assisted-by-Unsupervised-Machine-Learning/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/goodPointP/Automatic-Video-Editor-for-Reportages-Assisted-by-Unsupervised-Machine-Learning?style=flat-square&label=)](https://github.com/goodPointP/Automatic-Video-Editor-for-Reportages-Assisted-by-Unsupervised-Machine-Learning/graphs/code-frequency)|
|[videdit](https://github.com/brunoklein99/videdit#readme)|A Deep Learning based automatic video editor|[![](https://img.shields.io/github/languages/top/brunoklein99/videdit?color=pink&style=flat-square)](https://github.com/brunoklein99/videdit/graphs/contributors)|[![](https://flat.badgen.net/github/license/brunoklein99/videdit?label=)](https://github.com/brunoklein99/videdit/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/brunoklein99/videdit?style=flat-square&label=)](https://github.com/brunoklein99/videdit/graphs/code-frequency)|
|[folioviz.ai](https://github.com/darekm101/folioviz.ai#readme)|Video Editor driven by Ai|[![](https://img.shields.io/github/languages/top/darekm101/folioviz.ai?color=pink&style=flat-square)](https://github.com/darekm101/folioviz.ai/graphs/contributors)|[![](https://flat.badgen.net/github/license/darekm101/folioviz.ai?label=)](https://github.com/darekm101/folioviz.ai/issues/2)|[![](https://img.shields.io/github/last-commit/darekm101/folioviz.ai?style=flat-square&label=)](https://github.com/darekm101/folioviz.ai/graphs/code-frequency)|
|[ClipIQ](https://github.com/michaelbudko/ClipIQ#readme)|AI-powered video editor|[![](https://img.shields.io/github/languages/top/michaelbudko/ClipIQ?color=pink&style=flat-square)](https://github.com/michaelbudko/ClipIQ/graphs/contributors)|[![](https://flat.badgen.net/github/license/michaelbudko/ClipIQ?label=)](https://github.com/michaelbudko/ClipIQ/issues/1)|[![](https://img.shields.io/github/last-commit/michaelbudko/ClipIQ?style=flat-square&label=)](https://github.com/michaelbudko/ClipIQ/graphs/code-frequency)|
|[speech-separation](https://github.com/ggorti3/speech-separation#readme)|Use Deep Learning to automatically edit multicam videos|[![](https://img.shields.io/github/languages/top/ggorti3/speech-separation?color=pink&style=flat-square)](https://github.com/ggorti3/speech-separation/graphs/contributors)|[![](https://flat.badgen.net/github/license/ggorti3/speech-separation?label=)](https://github.com/ggorti3/speech-separation/issues/1)|[![](https://img.shields.io/github/last-commit/ggorti3/speech-separation?style=flat-square&label=)](https://github.com/ggorti3/speech-separation/graphs/code-frequency)|
|[Video Mashup](https://github.com/LamboCreeper/video-mashup#readme)|Uses Video Intelligence to analyse and edit a video based on a given sentence.|[![](https://img.shields.io/github/languages/top/LamboCreeper/video-mashup?color=pink&style=flat-square)](https://github.com/LamboCreeper/video-mashup/graphs/contributors)|[![](https://flat.badgen.net/github/license/LamboCreeper/video-mashup?label=)](https://github.com/LamboCreeper/video-mashup/issues/3)|[![](https://img.shields.io/github/last-commit/LamboCreeper/video-mashup?style=flat-square&label=)](https://github.com/LamboCreeper/video-mashup/graphs/code-frequency)|
|[soundblast-fe](https://github.com/TahirMontgomery/soundblast-fe#readme)|Frontend for AI powered video editor [backend](https://github.com/TahirMontgomery/soundblast-be)|[![](https://img.shields.io/github/languages/top/TahirMontgomery/soundblast-fe?color=pink&style=flat-square)](https://github.com/TahirMontgomery/soundblast-fe/graphs/contributors)|[![](https://flat.badgen.net/github/license/TahirMontgomery/soundblast-fe?label=)](https://github.com/TahirMontgomery/soundblast-fe/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/TahirMontgomery/soundblast-fe?style=flat-square&label=)](https://github.com/TahirMontgomery/soundblast-fe/graphs/code-frequency)|
|[TopView.ai](https://github.com/topviewai/ai-video-editor#readme)|Just provide your raw materials and ideas; AI does the rest, from scriptwriting to selecting shots, editing, narrating, and beautifying your video|[![](https://img.shields.io/github/languages/top/topviewai/ai-video-editor?color=pink&style=flat-square)](https://github.com/topviewai/ai-video-editor/graphs/contributors)|[![](https://flat.badgen.net/github/license/topviewai/ai-video-editor?label=)](https://github.com/topviewai/ai-video-editor/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/topviewai/ai-video-editor?style=flat-square&label=)](https://github.com/topviewai/ai-video-editor/graphs/code-frequency)|
|[Turn-Movie-Clips-to-Narration-Videos](https://github.com/JollyToday/Turn-Movie-Clips-to-Narration-Videos#readme)|Automatically extracts dialogue, identifies characters, generates commentary based on the plot, separates background noise, and aligns audio/video|[![](https://img.shields.io/github/languages/top/JollyToday/Turn-Movie-Clips-to-Narration-Videos?color=pink&style=flat-square)](https://github.com/JollyToday/Turn-Movie-Clips-to-Narration-Videos/graphs/contributors)|[![](https://flat.badgen.net/github/license/JollyToday/Turn-Movie-Clips-to-Narration-Videos?label=)](https://github.com/JollyToday/Turn_Movie_Clips_to_Narration_Videos/issues/1)|[![](https://img.shields.io/github/last-commit/JollyToday/Turn-Movie-Clips-to-Narration-Videos?style=flat-square&label=)](https://github.com/JollyToday/Turn-Movie-Clips-to-Narration-Videos/graphs/code-frequency)|

### Enhancers [⌂](#--)
|Resource|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[vs-mlrt](https://github.com/AmusementClub/vs-mlrt#readme)|Efficient CPU/GPU/[Vulkan ML](https://www.khronos.org/machine-learning) Runtimes for [VapourSynth](https://www.vapoursynth.com/) (with built-in support for [waifu2x](https://www.waifu2x.net/), [DPIR](https://github.com/cszn/DPIR), [RealESRGAN](https://github.com/xinntao/Real-ESRGAN#readme)v2/v3, [Real-CUGAN](https://github.com/bilibili/ailab), [RIFE](https://arxiv.org/abs/2011.06294), [SCUNet](https://arxiv.org/abs/2203.13278) and more!)|[![](https://img.shields.io/github/languages/top/AmusementClub/vs-mlrt?color=pink&style=flat-square)](https://github.com/AmusementClub/vs-mlrt/graphs/contributors)|[![](https://flat.badgen.net/github/license/AmusementClub/vs-mlrt?label=)](https://github.com/AmusementClub/vs-mlrt/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/AmusementClub/vs-mlrt?style=flat-square&label=)](https://github.com/AmusementClub/vs-mlrt/graphs/code-frequency)|
|[InterUpTool](https://github.com/GhostPoro/InterUpTool#readme)|GUI Tool for control, queue and automate video enhancing process, provided by [FFMPEG](https://ffmpeg.org/) video encoder, [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN#readme) image upscaler and [RIFE](https://arxiv.org/abs/2011.06294)/[DAIN](https://sites.google.com/view/wenbobao/dain) video frame interpolators|[![](https://img.shields.io/github/languages/top/GhostPoro/InterUpTool?color=pink&style=flat-square)](https://github.com/GhostPoro/InterUpTool/graphs/contributors)|[![](https://flat.badgen.net/github/license/GhostPoro/InterUpTool?label=)](https://github.com/GhostPoro/InterUpTool/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/GhostPoro/InterUpTool?style=flat-square&label=)](https://github.com/GhostPoro/InterUpTool/graphs/code-frequency)|
|[enhancr](https://github.com/mafiosnik777/enhancr#readme)|An elegant and easy to use GUI for Video Frame Interpolation and Video Upscaling which takes advantage of artificial intelligence|[![](https://img.shields.io/github/languages/top/mafiosnik777/enhancr?color=pink&style=flat-square)](https://github.com/mafiosnik777/enhancr/graphs/contributors)|[![](https://flat.badgen.net/github/license/mafiosnik777/enhancr?label=)](https://github.com/mafiosnik777/enhancr/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/mafiosnik777/enhancr?style=flat-square&label=)](https://github.com/mafiosnik777/enhancr/graphs/code-frequency)|
|[flowframes](https://github.com/n00mkrad/flowframes#readme)|Windows GUI for video interpolation using [DAIN](https://sites.google.com/view/wenbobao/dain) (NCNN) or [RIFE](https://arxiv.org/abs/2011.06294) (CUDA/NCNN)|[![](https://img.shields.io/github/languages/top/n00mkrad/flowframes?color=pink&style=flat-square)](https://github.com/n00mkrad/flowframes/graphs/contributors)|[![](https://flat.badgen.net/github/license/n00mkrad/flowframes?label=)](https://github.com/n00mkrad/flowframes/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/n00mkrad/flowframes?style=flat-square&label=)](https://github.com/n00mkrad/flowframes/graphs/code-frequency)|
|[PRINCIPI](https://github.com/Rob00t-unimi/progetto-principi#readme)|Fully customizable video frame rate up-conversion and video resolution upscaling with sharpening and denoising editor with GUI|[![](https://img.shields.io/github/languages/top/Rob00t-unimi/progetto-principi?color=pink&style=flat-square)](https://github.com/Rob00t-unimi/progetto-principi/graphs/contributors)|[![](https://flat.badgen.net/github/license/Rob00t-unimi/progetto-principi?label=)](https://github.com/Rob00t-unimi/Video-Enhancement-Suite-Frame-Interpolation-Upscaling/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/Rob00t-unimi/progetto-principi?style=flat-square&label=)](https://github.com/Rob00t-unimi/progetto-principi/graphs/code-frequency)|
|[QualityScaler](https://github.com/Djdefrag/QualityScaler#readme)|A Windows app powered by AI to enhance, upscale and de-noise photographs and videos|[![](https://img.shields.io/github/languages/top/Djdefrag/QualityScaler?color=pink&style=flat-square)](https://github.com/Djdefrag/QualityScaler/graphs/contributors)|[![](https://flat.badgen.net/github/license/Djdefrag/QualityScaler?label=)](https://github.com/Djdefrag/QualityScaler/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/Djdefrag/QualityScaler?style=flat-square&label=)](https://github.com/Djdefrag/QualityScaler/graphs/code-frequency)|
|[RealScaler](https://github.com/Djdefrag/RealScaler#readme)|A Windows app powered by [RealESRGAN](https://github.com/xinntao/Real-ESRGAN#readme) AI to enhance, upscale and de-noise photos and videos|[![](https://img.shields.io/github/languages/top/Djdefrag/RealScaler?color=pink&style=flat-square)](https://github.com/Djdefrag/RealScaler/graphs/contributors)|[![](https://flat.badgen.net/github/license/Djdefrag/RealScaler?label=)](https://github.com/Djdefrag/RealScaler/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/Djdefrag/RealScaler?style=flat-square&label=)](https://github.com/Djdefrag/RealScaler/graphs/code-frequency)|
|[VSGAN-tensorrt-docker](https://github.com/styler00dollar/VSGAN-tensorrt-docker#readme)|Fastest ([TensorRT](https://developer.nvidia.com/tensorrt)) inference code to use super resolution and video frame interpolation models|[![](https://img.shields.io/github/languages/top/styler00dollar/VSGAN-tensorrt-docker?color=pink&style=flat-square)](https://github.com/styler00dollar/VSGAN-tensorrt-docker/graphs/contributors)|[![](https://flat.badgen.net/github/license/styler00dollar/VSGAN-tensorrt-docker?label=)](https://github.com/styler00dollar/VSGAN-tensorrt-docker/blob/main/LICENSE.txt)|[![](https://img.shields.io/github/last-commit/styler00dollar/VSGAN-tensorrt-docker?style=flat-square&label=)](https://github.com/styler00dollar/VSGAN-tensorrt-docker/graphs/code-frequency)|

### Mixing [⌂](#--)
|Resource|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Automatic Mixing of Audio and Video](https://github.com/rissalhedna/Automatic-Mixing-of-Audio-and-Video#readme)|Proposing a comprehensive method for assisting video editing tasks using neural networks|[![](https://img.shields.io/github/languages/top/rissalhedna/Automatic-Mixing-of-Audio-and-Video?color=pink&style=flat-square)](https://github.com/rissalhedna/Automatic-Mixing-of-Audio-and-Video/graphs/contributors)|[![](https://flat.badgen.net/github/license/rissalhedna/Automatic-Mixing-of-Audio-and-Video?label=)](https://github.com/rissalhedna/Automatic-Mixing-of-Audio-and-Video/issues/1)|[![](https://img.shields.io/github/last-commit/rissalhedna/Automatic-Mixing-of-Audio-and-Video?style=flat-square&label=)](https://github.com/rissalhedna/Automatic-Mixing-of-Audio-and-Video/graphs/code-frequency)|


### Restoring [⌂](#--)
|Resource|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[DeFlicker PRISM](https://github.com/hrishikeshkh/DeFlicker-PRISM#readme)|Samsung PRISM project: removing flickering in high fps videos|[![](https://img.shields.io/github/languages/top/hrishikeshkh/DeFlicker-PRISM?color=pink&style=flat-square)](https://github.com/hrishikeshkh/DeFlicker-PRISM/graphs/contributors)|[![](https://flat.badgen.net/github/license/hrishikeshkh/DeFlicker-PRISM?label=)](https://github.com/hrishikeshkh/DeFlicker-PRISM/issues/1)|[![](https://img.shields.io/github/last-commit/hrishikeshkh/DeFlicker-PRISM?style=flat-square&label=)](https://github.com/hrishikeshkh/DeFlicker-PRISM/graphs/code-frequency)|
|[Samsung_Deflicker](https://github.com/RahulVishal/Samsung_Deflicker#readme)|A machine learning solution to remove flickering in high-speed videos|[![](https://img.shields.io/github/languages/top/RahulVishal/Samsung_Deflicker?color=pink&style=flat-square)](https://github.com/RahulVishal/Samsung_Deflicker/graphs/contributors)|[![](https://flat.badgen.net/github/license/RahulVishal/Samsung_Deflicker?label=)](https://github.com/RahulVishal/Samsung_Deflicker/issues/1)|[![](https://img.shields.io/github/last-commit/RahulVishal/Samsung_Deflicker?style=flat-square&label=)](https://github.com/RahulVishal/Samsung_Deflicker/graphs/code-frequency)|
|[TOFlow](http://toflow.csail.mit.edu/)|[Video Enhancement with Task-Oriented Flow](http://toflow.csail.mit.edu/) IJCV publication implementation|[![](https://img.shields.io/github/languages/top/anchen1011/toflow?color=pink&style=flat-square)](https://github.com/anchen1011/toflow/graphs/contributors)|[![](https://flat.badgen.net/github/license/anchen1011/toflow?label=)](https://github.com/anchen1011/toflow/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/anchen1011/toflow?style=flat-square&label=)](https://github.com/anchen1011/toflow/graphs/code-frequency)|
|[DeepRemaster](http://iizuka.cs.tsukuba.ac.jp/projects/remastering/)|PyTorch implementation for the "[DeepRemaster: Temporal Source-Reference Attention Networks for Comprehensive Video Enhancement](https://arxiv.org/abs/2009.08692)" paper|[![](https://img.shields.io/github/languages/top/satoshiiizuka/siggraphasia2019_remastering?color=pink&style=flat-square)](https://github.com/satoshiiizuka/siggraphasia2019_remastering/graphs/contributors)|[<img src="https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png" height="20">](https://github.com/JusperLee/Apollo/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/satoshiiizuka/siggraphasia2019_remastering?style=flat-square&label=)](https://github.com/satoshiiizuka/siggraphasia2019_remastering/graphs/code-frequency)|
|[EMA-VFI-WebUI](https://github.com/jhogsett/EMA-VFI-WebUI#readme)|Advanced AI-Based Video Renovation UI Using [EMA-VFI](https://arxiv.org/abs/2303.00440) & [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN#readme)|[![](https://img.shields.io/github/languages/top/jhogsett/EMA-VFI-WebUI?color=pink&style=flat-square)](https://github.com/jhogsett/EMA-VFI-WebUI/graphs/contributors)|[![](https://flat.badgen.net/github/license/jhogsett/EMA-VFI-WebUI?label=)](https://github.com/jhogsett/EMA-VFI-WebUI/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/jhogsett/EMA-VFI-WebUI?style=flat-square&label=)](https://github.com/jhogsett/EMA-VFI-WebUI/graphs/code-frequency)|
|[BasicSR](https://github.com/XPixelGroup/BasicSR#readme)|Open Source Image and Video Restoration Toolbox for Super-resolution, Denoise, Deblurring, etc|[![](https://img.shields.io/github/languages/top/XPixelGroup/BasicSR?color=pink&style=flat-square)](https://github.com/XPixelGroup/BasicSR/graphs/contributors)|[![](https://flat.badgen.net/github/license/XPixelGroup/BasicSR?label=)](https://github.com/XPixelGroup/BasicSR/blob/master/LICENSE.txt)|[![](https://img.shields.io/github/last-commit/XPixelGroup/BasicSR?style=flat-square&label=)](https://github.com/XPixelGroup/BasicSR/graphs/code-frequency)|
|[All-In-One-Deflicker](https://github.com/ChenyangLEI/All-In-One-Deflicker#readme)|Code for [Blind Video Deflickering by Neural Filtering with a Flawed Atlas](https://arxiv.org/abs/2303.08120) paper|[![](https://img.shields.io/github/languages/top/ChenyangLEI/All-In-One-Deflicker?color=pink&style=flat-square)](https://github.com/ChenyangLEI/All-In-One-Deflicker/graphs/contributors)|[![](https://flat.badgen.net/github/license/ChenyangLEI/All-In-One-Deflicker?label=)](https://github.com/ChenyangLEI/All-In-One-Deflicker/issues/35)|[![](https://img.shields.io/github/last-commit/ChenyangLEI/All-In-One-Deflicker?style=flat-square&label=)](https://github.com/ChenyangLEI/All-In-One-Deflicker/graphs/code-frequency)|

### Denoisers [⌂](#--)
|Resource|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Model-Blind Video Denoising Via Frame-to-frame Training](https://github.com/tehret/blind-denoising#readme)|[Model-blind Video Denoising Via Frame-to-frame Training](https://arxiv.org/abs/1811.12766) implementation|[![](https://img.shields.io/github/languages/top/tehret/blind-denoising?color=pink&style=flat-square)](https://github.com/tehret/blind-denoising/graphs/contributors)|[![](https://flat.badgen.net/github/license/tehret/blind-denoising?label=)](https://github.com/tehret/blind-denoising/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/tehret/blind-denoising?style=flat-square&label=)](https://github.com/tehret/blind-denoising/graphs/code-frequency)|
|[Non-local Bayesian Video Denoising](https://github.com/pariasm/vnlb#readme)|A C/C++ implementation of the [Video Denoising via Empirical Bayesian Estimation of Space-Time Patches](https://link.springer.com/article/10.1007/s10851-017-0742-4) paper|[![](https://img.shields.io/github/languages/top/pariasm/vnlb?color=pink&style=flat-square)](https://github.com/pariasm/vnlb/graphs/contributors)|[![](https://flat.badgen.net/github/license/pariasm/vnlb?label=)](https://github.com/pariasm/vnlb/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/pariasm/vnlb?style=flat-square&label=)](https://github.com/pariasm/vnlb/graphs/code-frequency)|
|[RNLF](https://github.com/csutour/RNLF#readme)|Image noise estimation and RNL image and video denoising|[![](https://img.shields.io/github/languages/top/csutour/RNLF?color=pink&style=flat-square)](https://github.com/csutour/RNLF/graphs/contributors)|[![](https://flat.badgen.net/github/license/csutour/RNLF?label=)](https://github.com/csutour/RNLF/issues/1)|[![](https://img.shields.io/github/last-commit/csutour/RNLF?style=flat-square&label=)](https://github.com/csutour/RNLF/graphs/code-frequency)|
|[VIDOSAT video denoising](https://github.com/wenbihan/vidosat_icip2015#readme)|A video denoising framework based on online 3D spatio-temporal sparsifying transform learning|[![](https://img.shields.io/github/languages/top/wenbihan/vidosat_icip2015?color=pink&style=flat-square)](https://github.com/wenbihan/vidosat_icip2015/graphs/contributors)|[![](https://flat.badgen.net/github/license/wenbihan/vidosat_icip2015?label=)](https://github.com/wenbihan/vidosat_icip2015/issues/1)|[![](https://img.shields.io/github/last-commit/wenbihan/vidosat_icip2015?style=flat-square&label=)](https://github.com/wenbihan/vidosat_icip2015/graphs/code-frequency)|
|[SALT based Video Denoising](https://github.com/wenbihan/salt_iccv2017#readme)|A video denoising method, based on a novel Sparse And Low-rank Tensor (SALT) model|[![](https://img.shields.io/github/languages/top/wenbihan/salt_iccv2017?color=pink&style=flat-square)](https://github.com/wenbihan/salt_iccv2017/graphs/contributors)|[![](https://flat.badgen.net/github/license/wenbihan/salt_iccv2017?label=)](https://github.com/wenbihan/salt_iccv2017/issues/1)|[![](https://img.shields.io/github/last-commit/wenbihan/salt_iccv2017?style=flat-square&label=)](https://github.com/wenbihan/salt_iccv2017/graphs/code-frequency)|
|[vnlnet](https://github.com/axeldavy/vnlnet#readme)|A Video denoising CNN with Non-locality information|[![](https://img.shields.io/github/languages/top/axeldavy/vnlnet?color=pink&style=flat-square)](https://github.com/axeldavy/vnlnet/graphs/contributors)|[![](https://flat.badgen.net/github/license/axeldavy/vnlnet?label=)](https://github.com/axeldavy/vnlnet/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/axeldavy/vnlnet?style=flat-square&label=)](https://github.com/axeldavy/vnlnet/graphs/code-frequency)|
|[FastDVDnet](https://github.com/m-tassano/fastdvdnet#readme)|A state-of-the-art, simple and fast network for Deep Video Denoising which uses no motion compensation|[![](https://img.shields.io/github/languages/top/m-tassano/fastdvdnet?color=pink&style=flat-square)](https://github.com/m-tassano/fastdvdnet/graphs/contributors)|[![](https://flat.badgen.net/github/license/m-tassano/fastdvdnet?label=)](https://github.com/m-tassano/fastdvdnet/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/m-tassano/fastdvdnet?style=flat-square&label=)](https://github.com/m-tassano/fastdvdnet/graphs/code-frequency)|
|[MaskDnGAN](https://github.com/avinashpaliwal/MaskDnGAN#readme)|This is the official implementation of  "[Multi-Stage Raw Video Denoising with Adversarial Loss and Gradient Mask](https://arxiv.org/abs/2103.02861)" paper|[![](https://img.shields.io/github/languages/top/avinashpaliwal/MaskDnGAN?color=pink&style=flat-square)](https://github.com/avinashpaliwal/MaskDnGAN/graphs/contributors)|[![](https://flat.badgen.net/github/license/avinashpaliwal/MaskDnGAN?label=)](https://github.com/avinashpaliwal/MaskDnGAN/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/avinashpaliwal/MaskDnGAN?style=flat-square&label=)](https://github.com/avinashpaliwal/MaskDnGAN/graphs/code-frequency)|
|[ViDeNN](https://github.com/clausmichele/ViDeNN#readme)|[Deep Blind Video Denoising](https://arxiv.org/abs/1904.10898) implementation|[![](https://img.shields.io/github/languages/top/clausmichele/ViDeNN?color=pink&style=flat-square)](https://github.com/clausmichele/ViDeNN/graphs/contributors)|[![](https://flat.badgen.net/github/license/clausmichele/ViDeNN?label=)](https://github.com/clausmichele/ViDeNN/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/clausmichele/ViDeNN?style=flat-square&label=)](https://github.com/clausmichele/ViDeNN/graphs/code-frequency)|
|[Deformable-Kernels-For-Video-Denoising](https://github.com/z-bingo/Deformable-Kernels-For-Video-Denoising#readme)|An implement of paper [Learning Deformable Kernels for Image and Video Denoising](https://arxiv.org/abs/1904.06903) in PyTorch|[![](https://img.shields.io/github/languages/top/z-bingo/Deformable-Kernels-For-Video-Denoising?color=pink&style=flat-square)](https://github.com/z-bingo/Deformable-Kernels-For-Video-Denoising/graphs/contributors)|[![](https://flat.badgen.net/github/license/z-bingo/Deformable-Kernels-For-Video-Denoising?label=)](https://github.com/z-bingo/Deformable-Kernels-For-Video-Denoising/issues/3)|[![](https://img.shields.io/github/last-commit/z-bingo/Deformable-Kernels-For-Video-Denoising?style=flat-square&label=)](https://github.com/z-bingo/Deformable-Kernels-For-Video-Denoising/graphs/code-frequency)|
|[PaCNet](https://github.com/grishavak/PaCNet-denoiser#readme)|This is the official implementation of "[Patch Craft: Video Denoising by Deep Modeling and Patch Matching](https://arxiv.org/abs/2103.13767)" paper|[![](https://img.shields.io/github/languages/top/grishavak/PaCNet-denoiser?color=pink&style=flat-square)](https://github.com/grishavak/PaCNet-denoiser/graphs/contributors)|[![](https://flat.badgen.net/github/license/grishavak/PaCNet-denoiser?label=)](https://github.com/grishavak/PaCNet-denoiser/issues/5)|[![](https://img.shields.io/github/last-commit/grishavak/PaCNet-denoiser?style=flat-square&label=)](https://github.com/grishavak/PaCNet-denoiser/graphs/code-frequency)|
|[STBN](https://github.com/ZKCCZ/STBN#readme)|The official implementation for the [Spatiotemporal Blind-Spot Network with Calibrated Flow Alignment for Self-Supervised Video Denoising](https://arxiv.org/abs/2412.11820) paper|[![](https://img.shields.io/github/languages/top/ZKCCZ/STBN?color=pink&style=flat-square)](https://github.com/ZKCCZ/STBN/graphs/contributors)|[![](https://flat.badgen.net/github/license/ZKCCZ/STBN?label=)](https://github.com/ZKCCZ/STBN/issues/3)|[![](https://img.shields.io/github/last-commit/ZKCCZ/STBN?style=flat-square&label=)](https://github.com/ZKCCZ/STBN/graphs/code-frequency)|
|[STPAN](https://github.com/jojo23333/STPAN#readme)|This is the official implementation of "[Learning Spatial and Spatio-Temporal Pixel Aggregations for Image and Video Denoising](https://arxiv.org/abs/2101.10760)" paper|[![](https://img.shields.io/github/languages/top/jojo23333/STPAN?color=pink&style=flat-square)](https://github.com/jojo23333/STPAN/graphs/contributors)|[![](https://flat.badgen.net/github/license/jojo23333/STPAN?label=)](https://github.com/jojo23333/STPAN/issues/3)|[![](https://img.shields.io/github/last-commit/jojo23333/STPAN?style=flat-square&label=)](https://github.com/jojo23333/STPAN/graphs/code-frequency)|
|[RViDeNet](https://github.com/cao-cong/RViDeNet#readme)|This is the official implementation of "[Supervised Raw Video Denoising with a Benchmark Dataset on Dynamic Scenes](https://arxiv.org/abs/2003.14013) paper|[![](https://img.shields.io/github/languages/top/cao-cong/RViDeNet?color=pink&style=flat-square)](https://github.com/cao-cong/RViDeNet/graphs/contributors)|[![](https://flat.badgen.net/github/license/cao-cong/RViDeNet?label=)](https://github.com/cao-cong/RViDeNet/issues/20)|[![](https://img.shields.io/github/last-commit/cao-cong/RViDeNet?style=flat-square&label=)](https://github.com/cao-cong/RViDeNet/graphs/code-frequency)|


### Deblurrers [⌂](#--)
|Resource|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Deep Video Deblurring for Hand-held Cameras](http://www.cs.ubc.ca/labs/imager/tr/2017/DeepVideoDeblurring/)|This is the demo code for "[Deep Video Deblurring for Hand-held Cameras](http://www.cs.ubc.ca/labs/imager/tr/2017/DeepVideoDeblurring/)" paper|[![](https://img.shields.io/github/languages/top/shuochsu/DeepVideoDeblurring?color=pink&style=flat-square)](https://github.com/shuochsu/DeepVideoDeblurring/graphs/contributors)|[![](https://flat.badgen.net/github/license/shuochsu/DeepVideoDeblurring?label=)](https://github.com/shuochsu/DeepVideoDeblurring/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/shuochsu/DeepVideoDeblurring?style=flat-square&label=)](https://github.com/shuochsu/DeepVideoDeblurring/graphs/code-frequency)|
|[PVDNet](https://github.com/codeslake/PVDNet#readme)|Official PyTorch Implementation for "[Recurrent Video Deblurring with Blur-Invariant Motion Estimation and Pixel Volumes](https://arxiv.org/abs/2108.09982)"paper|[![](https://img.shields.io/github/languages/top/codeslake/PVDNet?color=pink&style=flat-square)](https://github.com/codeslake/PVDNet/graphs/contributors)|[![](https://flat.badgen.net/github/license/codeslake/PVDNet?label=)](https://github.com/codeslake/PVDNet/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/codeslake/PVDNet?style=flat-square&label=)](https://github.com/codeslake/PVDNet/graphs/code-frequency)|
|[CDVD-TSP](https://github.com/csbhr/CDVD-TSP#readme)|Official implementation of "[Cascaded Deep Video Deblurring Using Temporal Sharpness Prior](https://arxiv.org/abs/2004.02501)" paper|[![](https://img.shields.io/github/languages/top/csbhr/CDVD-TSP?color=pink&style=flat-square)](https://github.com/csbhr/CDVD-TSP/graphs/contributors)|[![](https://flat.badgen.net/github/license/csbhr/CDVD-TSP?label=)](https://github.com/csbhr/CDVD-TSP/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/csbhr/CDVD-TSP?style=flat-square&label=)](https://github.com/csbhr/CDVD-TSP/graphs/code-frequency)|
|[ESTRNN & BSD](https://github.com/zzh-tech/ESTRNN#readme)|This work presents an efficient RNN-based model and the first real-world dataset for image/video deblurring|[![](https://img.shields.io/github/languages/top/zzh-tech/ESTRNN?color=pink&style=flat-square)](https://github.com/zzh-tech/ESTRNN/graphs/contributors)|[![](https://flat.badgen.net/github/license/zzh-tech/ESTRNN?label=)](https://github.com/zzh-tech/ESTRNN/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/zzh-tech/ESTRNN?style=flat-square&label=)](https://github.com/zzh-tech/ESTRNN/graphs/code-frequency)|
|[STFAN](https://github.com/sczhou/STFAN#readme)|Code repo for the "[Spatio-Temporal Filter Adaptive Network for Video Deblurring](https://shangchenzhou.com/projects/stfan/)" paper|[![](https://img.shields.io/github/languages/top/sczhou/STFAN?color=pink&style=flat-square)](https://github.com/sczhou/STFAN/graphs/contributors)|[![](https://flat.badgen.net/github/license/sczhou/STFAN?label=)](https://github.com/sczhou/STFAN/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/sczhou/STFAN?style=flat-square&label=)](https://github.com/sczhou/STFAN/graphs/code-frequency)|
|[Deblur](https://github.com/Volleria/Deblur#readme)|-|[![](https://img.shields.io/github/languages/top/Volleria/Deblur?color=pink&style=flat-square)](https://github.com/Volleria/Deblur/graphs/contributors)|[![](https://flat.badgen.net/github/license/Volleria/Deblur?label=)](https://github.com/Volleria/Deblur/issues/1)|[![](https://img.shields.io/github/last-commit/Volleria/Deblur?style=flat-square&label=)](https://github.com/Volleria/Deblur/graphs/code-frequency)|

### Artifacts reduction [⌂](#--)
|Resource|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[MFQE 2.0](https://github.com/RyanXingQL/MFQEv2.0#readme)|Official repository of "[MFQE 2.0: A New Approach for Multi-frame Quality Enhancement on Compressed Video](https://arxiv.org/abs/1902.09707)" paper|[![](https://img.shields.io/github/languages/top/RyanXingQL/MFQEv2.0?color=pink&style=flat-square)](https://github.com/RyanXingQL/MFQEv2.0/graphs/contributors)|[![](https://flat.badgen.net/github/license/RyanXingQL/MFQEv2.0?label=)](https://github.com/RyanXingQL/MFQEv2.0/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/RyanXingQL/MFQEv2.0?style=flat-square&label=)](https://github.com/RyanXingQL/MFQEv2.0/graphs/code-frequency)|
|[STDF](https://github.com/RyanXingQL/STDF-PyTorch#readme)|PyTorch implementation of [Spatio-Temporal Deformable Convolution for Compressed Video Quality Enhancement](https://www.researchgate.net/publication/342540674_Spatio-Temporal_Deformable_Convolution_for_Compressed_Video_Quality_Enhancement) paper|[![](https://img.shields.io/github/languages/top/RyanXingQL/STDF-PyTorch?color=pink&style=flat-square)](https://github.com/RyanXingQL/STDF-PyTorch/graphs/contributors)|[![](https://flat.badgen.net/github/license/RyanXingQL/STDF-PyTorch?label=)](https://github.com/RyanXingQL/STDF-PyTorch/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/RyanXingQL/STDF-PyTorch?style=flat-square&label=)](https://github.com/RyanXingQL/STDF-PyTorch/graphs/code-frequency)|
|[NL-ConvLSTM](https://github.com/xyiyy/NL-ConvLSTM#readme)|[Non-Local ConvLSTM for Video Compression Artifact Reduction](https://arxiv.org/abs/1910.12286) implementation|[![](https://img.shields.io/github/languages/top/xyiyy/NL-ConvLSTM?color=pink&style=flat-square)](https://github.com/xyiyy/NL-ConvLSTM/graphs/contributors)|[![](https://flat.badgen.net/github/license/xyiyy/NL-ConvLSTM?label=)](https://github.com/xyiyy/NL-ConvLSTM/issues/7)|[![](https://img.shields.io/github/last-commit/xyiyy/NL-ConvLSTM?style=flat-square&label=)](https://github.com/xyiyy/NL-ConvLSTM/graphs/code-frequency)|
|[QG-ConvLSTM](https://github.com/ryangchn/QG-ConvLSTM#readme)|Project page of "[Quality-Gated Convolutional LSTM for Enhancing Compressed Video](https://arxiv.org/abs/1903.04596)" paper|[![](https://img.shields.io/github/languages/top/ryangchn/QG-ConvLSTM?color=pink&style=flat-square)](https://github.com/ryangchn/QG-ConvLSTM/graphs/contributors)|[![](https://flat.badgen.net/github/license/ryangchn/QG-ConvLSTM?label=)](https://github.com/ryangchn/QG-ConvLSTM/issues/4)|[![](https://img.shields.io/github/last-commit/ryangchn/QG-ConvLSTM?style=flat-square&label=)](https://github.com/ryangchn/QG-ConvLSTM/graphs/code-frequency)|


### Colorization [⌂](#--)
|Resource|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Deep Exemplar-based Video Colorization](https://github.com/zhangmozhe/Deep-Exemplar-based-Video-Colorization#readme)|PyTorch implementation for the [Deep Exemplar-based Video Colorization](https://arxiv.org/abs/1906.09909) paper|[![](https://img.shields.io/github/languages/top/zhangmozhe/Deep-Exemplar-based-Video-Colorization?color=pink&style=flat-square)](https://github.com/zhangmozhe/Deep-Exemplar-based-Video-Colorization/graphs/contributors)|[![](https://flat.badgen.net/github/license/zhangmozhe/Deep-Exemplar-based-Video-Colorization?label=)](https://github.com/zhangmozhe/Deep-Exemplar-based-Video-Colorization/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/zhangmozhe/Deep-Exemplar-based-Video-Colorization?style=flat-square&label=)](https://github.com/zhangmozhe/Deep-Exemplar-based-Video-Colorization/graphs/code-frequency)|
|[DeOldify](https://github.com/jantic/DeOldify#readme)|A Deep Learning based project for colorizing and restoring old images (and video!)|[![](https://img.shields.io/github/languages/top/jantic/DeOldify?color=pink&style=flat-square)](https://github.com/jantic/DeOldify/graphs/contributors)|[![](https://flat.badgen.net/github/license/jantic/DeOldify?label=)](https://github.com/jantic/DeOldify/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/jantic/DeOldify/master?style=flat-square&label=)](https://github.com/jantic/DeOldify/graphs/code-frequency)|
|[Fully Automatic Video Colorization](https://leichenyang.weebly.com/project-color.html)|Tensorflow implementation for the "[Fully Automatic Video Colorization with Self-Regularization and Diversity](https://arxiv.org/abs/1908.01311)" paper|[![](https://img.shields.io/github/languages/top/ChenyangLEI/automatic-video-colorization?color=pink&style=flat-square)](https://github.com/ChenyangLEI/automatic-video-colorization/graphs/contributors)|[![](https://flat.badgen.net/github/license/ChenyangLEI/automatic-video-colorization?label=)](https://github.com/ChenyangLEI/automatic-video-colorization/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/ChenyangLEI/automatic-video-colorization?style=flat-square&label=)](https://github.com/ChenyangLEI/automatic-video-colorization/graphs/code-frequency)|
|[SVCNet](https://github.com/zhaoyuzhi/SVCNet#readme)|PyTorch implementation of the "[SVCNet: Scribble-based Video Colorization Network with Temporal Aggregation" paper](https://arxiv.org/abs/2303.11591)|[![](https://img.shields.io/github/languages/top/zhaoyuzhi/SVCNet?color=pink&style=flat-square)](https://github.com/zhaoyuzhi/SVCNet/graphs/contributors)|[![](https://flat.badgen.net/github/license/zhaoyuzhi/SVCNet?label=)](https://github.com/zhaoyuzhi/SVCNet/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/zhaoyuzhi/SVCNet?style=flat-square&label=)](https://github.com/zhaoyuzhi/SVCNet/graphs/code-frequency)|
|[DDColor](https://github.com/piddnad/DDColor#readme)|Official PyTorch implementation of the "[DDColor: Towards Photo-Realistic Image Colorization via Dual Decoders](https://arxiv.org/abs/2212.11613)" paper|[![](https://img.shields.io/github/languages/top/piddnad/DDColor?color=pink&style=flat-square)](https://github.com/piddnad/DDColor/graphs/contributors)|[![](https://flat.badgen.net/github/license/piddnad/DDColor?label=)](https://github.com/piddnad/DDColor/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/piddnad/DDColor?style=flat-square&label=)](https://github.com/piddnad/DDColor/graphs/code-frequency)|

### Compression [⌂](#--)
|Resource|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Deep-Video-Compression](https://github.com/Video-Tech/Deep-Video-Compression#readme)|Video compression using deep neural networks|[![](https://img.shields.io/github/languages/top/Video-Tech/Deep-Video-Compression?color=pink&style=flat-square)](https://github.com/Video-Tech/Deep-Video-Compression/graphs/contributors)|[![](https://flat.badgen.net/github/license/Video-Tech/Deep-Video-Compression?label=)](https://github.com/Video-Tech/Deep-Video-Compression/issues/1)|[![](https://img.shields.io/github/last-commit/Video-Tech/Deep-Video-Compression?style=flat-square&label=)](https://github.com/Video-Tech/Deep-Video-Compression/graphs/code-frequency)|
|[Deep_Learning_Video_compression](https://github.com/henry0408/Deep_Learning_Video_compression#readme)|Used deep learning for video compression|[![](https://img.shields.io/github/languages/top/henry0408/Deep_Learning_Video_compression?color=pink&style=flat-square)](https://github.com/henry0408/Deep_Learning_Video_compression/graphs/contributors)|[![](https://flat.badgen.net/github/license/henry0408/Deep_Learning_Video_compression?label=)](https://github.com/henry0408/Deep_Learning_Video_compression/issues/2)|[![](https://img.shields.io/github/last-commit/henry0408/Deep_Learning_Video_compression?style=flat-square&label=)](https://github.com/henry0408/Deep_Learning_Video_compression/graphs/code-frequency)|
|[Neural Video Compression](https://github.com/AdityaDusi97/NeuralVideoCompression#readme)|An implementation of the "[Learning Binary Residual Representations for Domain-specific Video Streaming](https://arxiv.org/abs/1712.05087)" paper|[![](https://img.shields.io/github/languages/top/AdityaDusi97/NeuralVideoCompression?color=pink&style=flat-square)](https://github.com/AdityaDusi97/NeuralVideoCompression/graphs/contributors)|[![](https://flat.badgen.net/github/license/AdityaDusi97/NeuralVideoCompression?label=)](https://github.com/AdityaDusi97/NeuralVideoCompression/issues/1)|[![](https://img.shields.io/github/last-commit/AdityaDusi97/NeuralVideoCompression?style=flat-square&label=)](https://github.com/AdityaDusi97/NeuralVideoCompression/graphs/code-frequency)|
|[neural-video-compress](https://github.com/vlad-danaila/neural-video-compress#readme)|Video compression using neural networks|[![](https://img.shields.io/github/languages/top/vlad-danaila/neural-video-compress?color=pink&style=flat-square)](https://github.com/vlad-danaila/neural-video-compress/graphs/contributors)|[![](https://flat.badgen.net/github/license/vlad-danaila/neural-video-compress?label=)](https://github.com/vlad-danaila/neural-video-compress/issues/1)|[![](https://img.shields.io/github/last-commit/vlad-danaila/neural-video-compress?style=flat-square&label=)](https://github.com/vlad-danaila/neural-video-compress/graphs/code-frequency)|
|[Video compression](https://github.com/ajayjain/video-compression#readme)|Experimental project for neural image and video compression|[![](https://img.shields.io/github/languages/top/ajayjain/video-compression?color=pink&style=flat-square)](https://github.com/ajayjain/video-compression/graphs/contributors)|[![](https://flat.badgen.net/github/license/ajayjain/video-compression?label=)](https://github.com/ajayjain/video-compression/issues/1)|[![](https://img.shields.io/github/last-commit/ajayjain/video-compression?style=flat-square&label=)](https://github.com/ajayjain/video-compression/graphs/code-frequency)|
|[Video-Compression-Net](https://github.com/tukilabs/Video-Compression-Net#readme)|A new approach to video compression by refining the shortcomings of conventional approach and substituting each traditional component with their neural network counterpart|[![](https://img.shields.io/github/languages/top/tukilabs/Video-Compression-Net?color=pink&style=flat-square)](https://github.com/tukilabs/Video-Compression-Net/graphs/contributors)|[![](https://flat.badgen.net/github/license/tukilabs/Video-Compression-Net?label=)](https://github.com/tukilabs/Video-Compression-Net/issues/6)|[![](https://img.shields.io/github/last-commit/tukilabs/Video-Compression-Net?style=flat-square&label=)](https://github.com/tukilabs/Video-Compression-Net/graphs/code-frequency)|
|[Spacevid](https://github.com/faissaloo/Spacevid#readme)|A neural net based tool for transcoding large videos to fit a specified file size with minimal adjustment to the bitrate|[![](https://img.shields.io/github/languages/top/faissaloo/Spacevid?color=pink&style=flat-square)](https://github.com/faissaloo/Spacevid/graphs/contributors)|[![](https://flat.badgen.net/github/license/faissaloo/Spacevid?label=)](https://github.com/faissaloo/Spacevid/blob/master/LICENCE.md)|[![](https://img.shields.io/github/last-commit/faissaloo/Spacevid?style=flat-square&label=)](https://github.com/faissaloo/Spacevid/graphs/code-frequency)|
|[deepzipper](https://github.com/jomanovic/deepzipper#readme)|An Intelligent video compression framework utilizing neural networks|[![](https://img.shields.io/github/languages/top/jomanovic/deepzipper?color=pink&style=flat-square)](https://github.com/jomanovic/deepzipper/graphs/contributors)|[![](https://flat.badgen.net/github/license/jomanovic/deepzipper?label=)](https://github.com/jomanovic/deepzipper/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/jomanovic/deepzipper?style=flat-square&label=)](https://github.com/jomanovic/deepzipper/graphs/code-frequency)|
|[HiNeRV](https://hmkx.github.io/hinerv/)|Code for "[HiNeRV: Video Compression with Hierarchical Encoding-based Neural Representation](https://arxiv.org/abs/2306.09818)" paper|[![](https://img.shields.io/github/languages/top/hmkx/HiNeRV?color=pink&style=flat-square)](https://github.com/hmkx/HiNeRV/graphs/contributors)|[![](https://flat.badgen.net/github/license/hmkx/HiNeRV?label=)](https://github.com/hmkx/HiNeRV/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/hmkx/HiNeRV?style=flat-square&label=)](https://github.com/hmkx/HiNeRV/graphs/code-frequency)|
|[Hier-Video-Compression](https://github.com/mandt-lab/Hier-Video-Compression#readme)|Codebase for [Hierarchical Autoregressive Modeling for Neural Video Compression](https://arxiv.org/abs/2010.10258)|[![](https://img.shields.io/github/languages/top/mandt-lab/Hier-Video-Compression?color=pink&style=flat-square)](https://github.com/mandt-lab/Hier-Video-Compression/graphs/contributors)|[![](https://flat.badgen.net/github/license/mandt-lab/Hier-Video-Compression?label=)](https://github.com/mandt-lab/Hier-Video-Compression/issues/1)|[![](https://img.shields.io/github/last-commit/mandt-lab/Hier-Video-Compression?style=flat-square&label=)](https://github.com/mandt-lab/Hier-Video-Compression/graphs/code-frequency)|
|[Ureca-Deep-neural-network-based-video-compression](https://github.com/ZhangJiayu99/Ureca-Deep-neural-network-based-video-compression#readme)|Investigate methodologies that combine neural networks and video compression|[![](https://img.shields.io/github/languages/top/ZhangJiayu99/Ureca-Deep-neural-network-based-video-compression?color=pink&style=flat-square)](https://github.com/ZhangJiayu99/Ureca-Deep-neural-network-based-video-compression/graphs/contributors)|[![](https://flat.badgen.net/github/license/ZhangJiayu99/Ureca-Deep-neural-network-based-video-compression?label=)](https://github.com/ZhangJiayu99/Ureca-Deep-neural-network-based-video-compression/issues/1)|[![](https://img.shields.io/github/last-commit/ZhangJiayu99/Ureca-Deep-neural-network-based-video-compression?style=flat-square&label=)](https://github.com/ZhangJiayu99/Ureca-Deep-neural-network-based-video-compression/graphs/code-frequency)|
|[video-compression-dnn](https://github.com/isseu/video-compression-dnn#readme)|Video compression using deep convolutional neural networks and autoencoders|[![](https://img.shields.io/github/languages/top/isseu/video-compression-dnn?color=pink&style=flat-square)](https://github.com/isseu/video-compression-dnn/graphs/contributors)|[![](https://flat.badgen.net/github/license/isseu/video-compression-dnn?label=)](https://github.com/isseu/video-compression-dnn/issues/3)|[![](https://img.shields.io/github/last-commit/isseu/video-compression-dnn?style=flat-square&label=)](https://github.com/isseu/video-compression-dnn/graphs/code-frequency)|

### Stabilizers [⌂](#--)
|Resource|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Trajectory Optimization based Video Stabilization](https://github.com/btxviny/Trajectory-Optimization-and-Parametric-filtering-based-Video-Stabilization#readme)|A custom [MeshFlow](http://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Minimum_Latency_Deep_Online_Video_Stabilization_ICCV_2023_paper.pdf) implementation|[![](https://img.shields.io/github/languages/top/btxviny/Trajectory-Optimization-and-Parametric-filtering-based-Video-Stabilization?color=pink&style=flat-square)](https://github.com/btxviny/Trajectory-Optimization-and-Parametric-filtering-based-Video-Stabilization/graphs/contributors)|[![](https://flat.badgen.net/github/license/btxviny/Trajectory-Optimization-and-Parametric-filtering-based-Video-Stabilization?label=)](https://github.com/btxviny/Trajectory-Optimization-and-Parametric-filtering-based-Video-Stabilization/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/btxviny/Trajectory-Optimization-and-Parametric-filtering-based-Video-Stabilization?style=flat-square&label=)](https://github.com/btxviny/Trajectory-Optimization-and-Parametric-filtering-based-Video-Stabilization/graphs/code-frequency)|
|[Deep3D Stabilizer](https://yaochih.github.io/deep3d-stabilizer.io/)|3D Video Stabilization with Depth Estimation by CNN-based Optimization|[![](https://img.shields.io/github/languages/top/yaochih/Deep3D-Stabilizer-release?color=pink&style=flat-square)](https://github.com/yaochih/Deep3D-Stabilizer-release/graphs/contributors)|[![](https://flat.badgen.net/github/license/yaochih/Deep3D-Stabilizer-release?label=)](https://github.com/yaochih/Deep3D-Stabilizer-release/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/yaochih/Deep3D-Stabilizer-release/master?style=flat-square&label=)](https://github.com/yaochih/Deep3D-Stabilizer-release/graphs/code-frequency)|
|[DIFRINT](https://github.com/jinsc37/DIFRINT#readme)|Test code reference implementation of "[Deep Iterative Frame Interpolation for Full-frame Video Stabilization](https://arxiv.org/pdf/1909.02641.pdf "Download PDF")", using PyTorch|[![](https://img.shields.io/github/languages/top/jinsc37/DIFRINT?color=pink&style=flat-square)](https://github.com/jinsc37/DIFRINT/graphs/contributors)|[![](https://flat.badgen.net/github/license/jinsc37/DIFRINT?label=)](https://github.com/jinsc37/DIFRINT/issues/13)|[![](https://img.shields.io/github/last-commit/jinsc37/DIFRINT/master?style=flat-square&label=)](https://github.com/jinsc37/DIFRINT/graphs/code-frequency)|
|[DUT](https://github.com/Annbless/DUTCode#readme)|Pytorch implementation of "[DUT: Learning Video Stabilization by Simply Watching Unstable Videos](https://arxiv.org/pdf/2011.14574.pdf "Download PDF")"|[![](https://img.shields.io/github/languages/top/Annbless/DUTCode?color=pink&style=flat-square)](https://github.com/Annbless/DUTCode/graphs/contributors)|[![](https://flat.badgen.net/github/license/Annbless/DUTCode?label=)](https://github.com/Annbless/DUTCode/issues/27)|[![](https://img.shields.io/github/last-commit/Annbless/DUTCode/main?style=flat-square&label=)](https://github.com/Annbless/DUTCode/graphs/code-frequency)|
|[FuSta](https://alex04072000.github.io/FuSta/)|Hybrid Neural Fusion for Full-frame Video Stabilization|[![](https://img.shields.io/github/languages/top/alex04072000/FuSta?color=pink&style=flat-square)](https://github.com/alex04072000/FuSta/graphs/contributors)|[![](https://flat.badgen.net/github/license/alex04072000/FuSta?label=)](https://github.com/alex04072000/FuSta/issues/28)|[![](https://img.shields.io/github/last-commit/alex04072000/FuSta/main?style=flat-square&label=)](https://github.com/alex04072000/FuSta/graphs/code-frequency)|
|[Real-Time Selfie Video Stabilization](https://github.com/jiy173/selfievideostabilization#readme)|Official implementation of paper "[Real-Time Selfie Video Stabilization](https://cseweb.ucsd.edu//~ravir/jiyangcvpr21.pdf "Download PDF")"|[![](https://img.shields.io/github/languages/top/jiy173/selfievideostabilization?color=pink&style=flat-square)](https://github.com/jiy173/selfievideostabilization/graphs/contributors)|[![](https://flat.badgen.net/github/license/jiy173/selfievideostabilization?label=)](https://github.com/jiy173/selfievideostabilization/issues/8)|[![](https://img.shields.io/github/last-commit/jiy173/selfievideostabilization/master?style=flat-square&label=)](https://github.com/jiy173/selfievideostabilization/graphs/code-frequency)|

### Upscalers [⌂](#--)
|Resource|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Intel® Library for Video Super Resolution](https://github.com/OpenVisualCloud/Video-Super-Resolution-Library#readme)|Native C and C++ implementation of [RAISR: Rapid and Accurate Image Super Resolution](https://arxiv.org/abs/1606.01299) paper |[![](https://img.shields.io/github/languages/top/OpenVisualCloud/Video-Super-Resolution-Library?color=pink&style=flat-square)](https://github.com/OpenVisualCloud/Video-Super-Resolution-Library/graphs/contributors)|[![](https://flat.badgen.net/github/license/OpenVisualCloud/Video-Super-Resolution-Library?label=)](https://github.com/OpenVisualCloud/Video-Super-Resolution-Library/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/OpenVisualCloud/Video-Super-Resolution-Library?style=flat-square&label=)](https://github.com/OpenVisualCloud/Video-Super-Resolution-Library/graphs/code-frequency)|
|[vs-NNVISR](https://github.com/tongyuantongyu/vs-NNVISR#readme)|Neural Network Video Interpolation / Super Resolution Filter for VapourSynth|[![](https://img.shields.io/github/languages/top/tongyuantongyu/vs-NNVISR?color=pink&style=flat-square)](https://github.com/tongyuantongyu/vs-NNVISR/graphs/contributors)|[![](https://flat.badgen.net/github/license/tongyuantongyu/vs-NNVISR?label=)](https://github.com/tongyuantongyu/vs-NNVISR/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/tongyuantongyu/vs-NNVISR?style=flat-square&label=)](https://github.com/tongyuantongyu/vs-NNVISR/graphs/code-frequency)|
|[Fast-SRGAN](https://github.com/HasnainRaz/Fast-SRGAN#readme)|A Fast Deep Learning Model to Upsample Low Resolution Videos to High Resolution at 30fps|[![](https://img.shields.io/github/languages/top/HasnainRaz/Fast-SRGAN?color=pink&style=flat-square)](https://github.com/HasnainRaz/Fast-SRGAN/graphs/contributors)|[![](https://flat.badgen.net/github/license/HasnainRaz/Fast-SRGAN?label=)](https://github.com/HasnainRaz/Fast-SRGAN/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/HasnainRaz/Fast-SRGAN?style=flat-square&label=)](https://github.com/HasnainRaz/Fast-SRGAN/graphs/code-frequency)|
|[FMA-Net](https://github.com/KAIST-VICLab/FMA-Net#readme)|Official repository for "[Flow-Guided Dynamic Filtering and Iterative Feature Refinement with Multi-Attention for Joint Video Super-Resolution and Deblurring](https://arxiv.org/abs/2401.03707)" paper|[![](https://img.shields.io/github/languages/top/KAIST-VICLab/FMA-Net?color=pink&style=flat-square)](https://github.com/KAIST-VICLab/FMA-Net/graphs/contributors)|[![](https://flat.badgen.net/github/license/KAIST-VICLab/FMA-Net?label=)](https://github.com/KAIST-VICLab/FMA-Net/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/KAIST-VICLab/FMA-Net?style=flat-square&label=)](https://github.com/KAIST-VICLab/FMA-Net/graphs/code-frequency)|
|[IART](https://github.com/kai422/IART#readme)|[Enhancing Video Super-Resolution via Implicit Resampling-based Alignment](https://arxiv.org/abs/2305.00163)|[![](https://img.shields.io/github/languages/top/kai422/IART?color=pink&style=flat-square)](https://github.com/kai422/IART/graphs/contributors)|[![](https://flat.badgen.net/github/license/kai422/IART?label=)](https://github.com/kai422/IART/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/kai422/IART?style=flat-square&label=)](https://github.com/kai422/IART/graphs/code-frequency)|
|[RealViformer](https://github.com/Yuehan717/RealViformer#readme)|The Official Code for "[Investigating Attention for Real-World Video Super-Resolution](https://arxiv.org/abs/2407.13987)" paper|[![](https://img.shields.io/github/languages/top/Yuehan717/RealViformer?color=pink&style=flat-square)](https://github.com/Yuehan717/RealViformer/graphs/contributors)|[![](https://flat.badgen.net/github/license/Yuehan717/RealViformer?label=)](https://github.com/Yuehan717/RealViformer/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/Yuehan717/RealViformer?style=flat-square&label=)](https://github.com/Yuehan717/RealViformer/graphs/code-frequency)|
|[ST-AVSR](https://github.com/shangwei5/ST-AVSR#readme)|[Arbitrary-Scale Video Super-Resolution with Structural and Textural Priors](https://arxiv.org/abs/2407.09919)|[![](https://img.shields.io/github/languages/top/shangwei5/ST-AVSR?color=pink&style=flat-square)](https://github.com/shangwei5/ST-AVSR/graphs/contributors)|[![](https://flat.badgen.net/github/license/shangwei5/ST-AVSR?label=)](https://github.com/shangwei5/ST-AVSR/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/shangwei5/ST-AVSR?style=flat-square&label=)](https://github.com/shangwei5/ST-AVSR/graphs/code-frequency)|
|[StableVSR](https://github.com/claudiom4sir/StableVSR#readme)|[Enhancing Perceptual Quality in Video Super-Resolution through Temporally-Consistent Detail Synthesis using Diffusion Models](https://arxiv.org/abs/2311.15908)|[![](https://img.shields.io/github/languages/top/claudiom4sir/StableVSR?color=pink&style=flat-square)](https://github.com/claudiom4sir/StableVSR/graphs/contributors)|[![](https://flat.badgen.net/github/license/claudiom4sir/StableVSR?label=)](https://github.com/claudiom4sir/StableVSR/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/claudiom4sir/StableVSR?style=flat-square&label=)](https://github.com/claudiom4sir/StableVSR/graphs/code-frequency)|
|[AnimeSR](https://github.com/TencentARC/AnimeSR#readme)|Codes for "[Learning Real-World Super-Resolution Models for Animation Videos](https://arxiv.org/abs/2206.07038)" paper|[![](https://img.shields.io/github/languages/top/TencentARC/AnimeSR?color=pink&style=flat-square)](https://github.com/TencentARC/AnimeSR/graphs/contributors)|[![](https://flat.badgen.net/github/license/TencentARC/AnimeSR?label=)](https://github.com/TencentARC/AnimeSR/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/TencentARC/AnimeSR?style=flat-square&label=)](https://github.com/TencentARC/AnimeSR/graphs/code-frequency)|
|[BasicVSR++](https://github.com/renaissanceee/BasicVSR_PlusPlus#readme)|[Improving Video Super-Resolution with Enhanced Propagation and Alignment](https://arxiv.org/abs/2104.13371)|[![](https://img.shields.io/github/languages/top/renaissanceee/BasicVSR_PlusPlus?color=pink&style=flat-square)](https://github.com/renaissanceee/BasicVSR_PlusPlus/graphs/contributors)|[![](https://flat.badgen.net/github/license/renaissanceee/BasicVSR_PlusPlus?label=)](https://github.com/renaissanceee/BasicVSR_PlusPlus/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/renaissanceee/BasicVSR_PlusPlus?style=flat-square&label=)](https://github.com/renaissanceee/BasicVSR_PlusPlus/graphs/code-frequency)|
|[EvTexture](https://github.com/DachunKai/EvTexture#readme)|[Event-driven Texture Enhancement for Video Super-Resolution](https://arxiv.org/abs/2406.13457)|[![](https://img.shields.io/github/languages/top/dachunkai/evtexture?color=pink&style=flat-square)](https://github.com/DachunKai/EvTexture/graphs/contributors)|[![](https://flat.badgen.net/github/license/dachunkai/evtexture?label=)](https://github.com/DachunKai/EvTexture/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/dachunkai/evtexture?style=flat-square&label=)](https://github.com/DachunKai/EvTexture/graphs/code-frequency)|
|[MIA-VSR](https://github.com/LabShuHangGU/MIA-VSR#readme)|[Video Super-Resolution Transformer with Masked Inter&Intra-Frame Attention](https://arxiv.org/abs/2401.06312)|[![](https://img.shields.io/github/languages/top/LabShuHangGU/MIA-VSR?color=pink&style=flat-square)](https://github.com/LabShuHangGU/MIA-VSR/graphs/contributors)|[![](https://flat.badgen.net/github/license/LabShuHangGU/MIA-VSR?label=)](https://github.com/LabShuHangGU/MIA-VSR/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/LabShuHangGU/MIA-VSR?style=flat-square&label=)](https://github.com/LabShuHangGU/MIA-VSR/graphs/code-frequency)|
|[PP-MSVSR](https://github.com/PaddlePaddle/PaddleGAN/blob/develop/docs/en_US/tutorials/video_super_resolution.md#-pp-msvsr-)|[Multi-Stage Video Super-Resolution](https://arxiv.org/abs/2112.02828) (part of [PaddlePaddle GAN library](https://github.com/PaddlePaddle/PaddleGAN#readme))|[![](https://img.shields.io/github/languages/top/PaddlePaddle/PaddleGAN?color=pink&style=flat-square)](https://github.com/PaddlePaddle/PaddleGAN/graphs/contributors)|[![](https://flat.badgen.net/github/license/PaddlePaddle/PaddleGAN?label=)](https://github.com/PaddlePaddle/PaddleGAN/blob/develop/LICENSE)|[![](https://img.shields.io/github/last-commit/PaddlePaddle/PaddleGAN?style=flat-square&label=)](https://github.com/PaddlePaddle/PaddleGAN/graphs/code-frequency)|
|[RealBasicVSR](https://github.com/ckkelvinchan/RealBasicVSR#readme)|Official repository for "[Investigating Tradeoffs in Real-World Video Super-Resolution](https://arxiv.org/abs/2111.12704)" paper|[![](https://img.shields.io/github/languages/top/ckkelvinchan/RealBasicVSR?color=pink&style=flat-square)](https://github.com/ckkelvinchan/RealBasicVSR/graphs/contributors)|[![](https://flat.badgen.net/github/license/ckkelvinchan/RealBasicVSR?label=)](https://github.com/ckkelvinchan/RealBasicVSR/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/ckkelvinchan/RealBasicVSR?style=flat-square&label=)](https://github.com/ckkelvinchan/RealBasicVSR/graphs/code-frequency)|
|[KEEP](https://github.com/jnjaby/KEEP#readme)|[Kalman-Inspired Feature Propagation for Video Face Super-Resolution](https://arxiv.org/abs/2408.05205)|[![](https://img.shields.io/github/languages/top/jnjaby/KEEP?color=pink&style=flat-square)](https://github.com/jnjaby/KEEP/graphs/contributors)|[![](https://flat.badgen.net/badge/license/Other/blue?label=)](https://github.com/jnjaby/KEEP/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/jnjaby/KEEP?style=flat-square&label=)](https://github.com/jnjaby/KEEP/graphs/code-frequency)|
|[MGLD-VSR](https://github.com/IanYeung/MGLD-VSR#readme)|Code for "[Motion-Guided Latent Diffusion for Temporally Consistent Real-world Video Super-resolution](https://arxiv.org/abs/2312.00853)" paper|[![](https://img.shields.io/github/languages/top/IanYeung/MGLD-VSR?color=pink&style=flat-square)](https://github.com/IanYeung/MGLD-VSR/graphs/contributors)|[![](https://flat.badgen.net/badge/license/Other/blue?label=)](https://github.com/IanYeung/MGLD-VSR/blob/main/LICENSE.txt)|[![](https://img.shields.io/github/last-commit/IanYeung/MGLD-VSR?style=flat-square&label=)](https://github.com/IanYeung/MGLD-VSR/graphs/code-frequency)|
|[INR-Event-VSR](https://github.com/yunfanLu/INR-Event-VSR#readme)|[Learning Spatial-Temporal Implicit Neural Representations for Event-Guided Video Super-Resolution](https://arxiv.org/abs/2303.13767)|[![](https://img.shields.io/github/languages/top/yunfanLu/INR-Event-VSR?color=pink&style=flat-square)](https://github.com/yunfanLu/INR-Event-VSR/graphs/contributors)|[![](https://flat.badgen.net/github/license/yunfanLu/INR-Event-VSR?label=)](https://github.com/yunfanLu/INR-Event-VSR/issues/13)|[![](https://img.shields.io/github/last-commit/yunfanLu/INR-Event-VSR?style=flat-square&label=)](https://github.com/yunfanLu/INR-Event-VSR/graphs/code-frequency)|
|[STDO-CVPR2023](https://github.com/coulsonlee/STDO-CVPR2023#readme)|[Towards High-Quality and Efficient Video Super-Resolution via Spatial-Temporal Data Overfitting](https://arxiv.org/abs/2303.08331)|[![](https://img.shields.io/github/languages/top/coulsonlee/STDO-CVPR2023?color=pink&style=flat-square)](https://github.com/coulsonlee/STDO-CVPR2023/graphs/contributors)|[![](https://flat.badgen.net/github/license/coulsonlee/STDO-CVPR2023?label=)](https://github.com/coulsonlee/STDO-CVPR2023/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/coulsonlee/STDO-CVPR2023?style=flat-square&label=)](https://github.com/coulsonlee/STDO-CVPR2023/graphs/code-frequency)|
|[ControlNetVSR](https://github.com/nrdyava/ControlNetVSR#readme)|Video Super-Resolution using Latent Diffusion Models|[![](https://img.shields.io/github/languages/top/nrdyava/ControlNetVSR?color=pink&style=flat-square)](https://github.com/nrdyava/ControlNetVSR/graphs/contributors)|[![](https://flat.badgen.net/github/license/nrdyava/ControlNetVSR?label=)](https://github.com/nrdyava/ControlNetVSR/issues/1)|[![](https://img.shields.io/github/last-commit/nrdyava/ControlNetVSR?style=flat-square&label=)](https://github.com/nrdyava/ControlNetVSR/graphs/code-frequency)|

### Web-oriented [⌂](#--)
|Resource|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Video_Editor_AI](https://github.com/mihiragath/Video_Editor_AI#readme)|-|[![](https://img.shields.io/github/languages/top/mihiragath/Video_Editor_AI?color=pink&style=flat-square)](https://github.com/mihiragath/Video_Editor_AI/graphs/contributors)|[![](https://flat.badgen.net/github/license/mihiragath/Video_Editor_AI?label=)](https://github.com/mihiragath/Video_Editor_AI/issues/1)|[![](https://img.shields.io/github/last-commit/mihiragath/Video_Editor_AI?style=flat-square&label=)](https://github.com/mihiragath/Video_Editor_AI/graphs/code-frequency)|

### Other resources [⌂](#--)
- [Video Frame Interpolation Rankings and Video Deblurring Rankings](https://github.com/AIVFI/Video-Frame-Interpolation-Rankings-and-Video-Deblurring-Rankings)
- [Awesome Video Diffusion](https://github.com/showlab/Awesome-Video-Diffusion#awesome-video-diffusion--)
- [Awesome-Image-Colorization](https://github.com/MarkMoHR/Awesome-Image-Colorization#awesome-image-colorization)/[Video Colorization](https://github.com/MarkMoHR/Awesome-Image-Colorization#4-video-colorization)
- [Video restoration based on deep learning: a comprehensive survey](https://github.com/claudiom4sir/VideoRestoration)
- [Deep-Image-Compression-Video-Coding](https://github.com/WenxueCui/Deep-Image-Compression-Video-Coding#readme)
- [Learning-based-Image-Video-Compression](https://github.com/deeptimhe/Learning-based-Image-Video-Compression#readme)
- [Awesome Deep Learning Based Video Compression](https://github.com/ppingzhang/Awesome-Deep-Learning-Based-Video-Compression#readme)
- [Awesome-Deep-Compression](https://github.com/wyf0912/Awesome-Deep-Compression#readme)



![Visitors](https://api.visitorbadge.io/api/daily?path=https%3A%2F%2Fgithub.com%2FFORARTfe%2FHyMPS&label=DV&countColor=%23dce775&style=flat-square&labelStyle=none)
