# [![AUDIO](https://flat.badgen.net/badge/HyMPS/AUDIO/green?scale=1.8)](https://github.com/forart/HyMPS#-1 "AUDIO resources") [![AI-based projects](https://flat.badgen.net/badge/HyMPS/AI-based%20projects/blue?scale=1.8&label=)](https://github.com/forart/HyMPS#ai-based "AI-based") <img align="right" alt="stable" src="https://user-images.githubusercontent.com/171307/210727719-14b940a2-d1dc-4991-b6a4-7add74463ce8.png" width="5%" />

## Subsections: [Codecs](#codecs-) - [Mixing](#mixing-) - [Drums](#drums-) - [Bass](#bass-) - [Guitar](#guitar-) - [MIDI](#midi-) - [Source Separation](#source-separation-) - [Misc](#misc-)

>**Note**
>_**`SORT: Language (a>z) > License (openness) > Name / URL (a>z)`**_

## Codecs [⌂](#--)
|Git|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[AudioCodec-Hub](https://github.com/ga642381/AudioCodec-Hub#readme)|A Python library for encoding and decoding audio data, supporting various neural audio codec models|[![](https://img.shields.io/github/languages/top/ga642381/AudioCodec-Hub?color=pink&style=flat-square)](https://github.com/ga642381/AudioCodec-Hub/graphs/contributors)|[![](https://flat.badgen.net/github/license/ga642381/AudioCodec-Hub?label=)](https://github.com/ga642381/AudioCodec-Hub/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/ga642381/AudioCodec-Hub/main?label=)](https://github.com/ga642381/AudioCodec-Hub/graphs/code-frequency)|
|[Descript Audio Codec](https://github.com/descriptinc/descript-audio-codec#readme)|A high fidelity general neural audio codec|[![](https://img.shields.io/github/languages/top/descriptinc/descript-audio-codec?color=pink&style=flat-square)](https://github.com/descriptinc/descript-audio-codec/graphs/contributors)|[![](https://flat.badgen.net/github/license/descriptinc/descript-audio-codec?label=)](https://github.com/descriptinc/descript-audio-codec/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/descriptinc/descript-audio-codec/main?label=)](https://github.com/descriptinc/descript-audio-codec/graphs/code-frequency)|
|[EnCodec](https://github.com/facebookresearch/encodec#readme)|State-of-the-art deep learning based audio codec|[![](https://img.shields.io/github/languages/top/facebookresearch/encodec?color=pink&style=flat-square)](https://github.com/facebookresearch/encodec/graphs/contributors)|[![](https://flat.badgen.net/github/license/facebookresearch/encodec?label=)](https://github.com/facebookresearch/encodec/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/facebookresearch/encodec/main?label=)](https://github.com/facebookresearch/encodec/graphs/code-frequency)|
|[SoundStream](https://github.com/haydenshively/SoundStream#readme)|An end-to-end neural audio codec|[![](https://img.shields.io/github/languages/top/haydenshively/SoundStream?color=pink&style=flat-square)](https://github.com/haydenshively/SoundStream/graphs/contributors)|[![](https://flat.badgen.net/github/license/haydenshively/SoundStream?label=)](https://github.com/haydenshively/SoundStream/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/haydenshively/SoundStream/master?label=)](https://github.com/haydenshively/SoundStream/graphs/code-frequency)|
|[encodec-pytorch](https://github.com/NoFish-528/encodec-pytorch#readme)|unofficial implementation of the [High Fidelity Neural Audio Compression](https://arxiv.org/pdf/2210.13438.pdf)|[![](https://img.shields.io/github/languages/top/NoFish-528/encodec-pytorch?color=pink&style=flat-square)](https://github.com/NoFish-528/encodec-pytorch/graphs/contributors)|[![](https://flat.badgen.net/github/license/NoFish-528/encodec-pytorch?label=)](https://github.com/NoFish-528/encodec-pytorch/blob/main/LICENSE)|[![](https://flat.badgen.net/github/last-commit/NoFish-528/encodec-pytorch/main?label=)](https://github.com/NoFish-528/encodec-pytorch/graphs/code-frequency)|
|[Stochastic-Restoration-GAN](https://github.com/abreuwallace/Stochastic-Restoration-GAN#stochastic-restoration-gan)|Stochastic Restoration of Heavily Compressed Musical Audio using Generative Adversarial Networks in Pytorch|[![](https://img.shields.io/github/languages/top/abreuwallace/Stochastic-Restoration-GAN?color=pink&style=flat-square)](https://github.com/abreuwallace/Stochastic-Restoration-GAN/graphs/contributors)|[![](https://flat.badgen.net/github/license/abreuwallace/Stochastic-Restoration-GAN?label=)](https://github.com/abreuwallace/Stochastic-Restoration-GAN/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/abreuwallace/Stochastic-Restoration-GAN?label=)](https://github.com/abreuwallace/Stochastic-Restoration-GAN/graphs/code-frequency)|
|[Siamese SIREN](https://github.com/lucala/siamese-siren#readme)|Audio Compression with Implicit Neural Representations|[![](https://img.shields.io/github/languages/top/lucala/siamese-siren?color=pink&style=flat-square)](https://github.com/lucala/siamese-siren/graphs/contributors)|[![](https://flat.badgen.net/github/license/lucala/siamese-siren?label=)](https://github.com/lucala/siamese-siren/blob/main/LICENSE)|[![](https://flat.badgen.net/github/last-commit/lucala/siamese-siren/main?label=)](https://github.com/lucala/siamese-siren/graphs/code-frequency)|

## Mixing [⌂](#--)
|Git|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[automix-toolkit](https://github.com/csteinmetz1/automix-toolkit#readme)|Models and datasets for training deep learning automatic mixing models|[![](https://img.shields.io/github/languages/top/csteinmetz1/automix-toolkit?color=pink&style=flat-square)](https://github.com/csteinmetz1/automix-toolkit/graphs/contributors)|[![](https://flat.badgen.net/github/license/csteinmetz1/automix-toolkit?label=)](https://github.com/csteinmetz1/automix-toolkit/blob/main/LICENSE)|[![](https://flat.badgen.net/github/last-commit/csteinmetz1/automix-toolkit/main?label=)](https://github.com/csteinmetz1/automix-toolkit/graphs/code-frequency)|
|[DJtransGAN](https://github.com/ChenPaulYu/DJtransGAN#djtransgan-automatic-dj-transitions-with-differentiable-audio-effects-and-generative-adversarial-networks)|Automatic DJ Transitions with Differentiable Audio Effects and Generative Adversarial Networks|[![](https://img.shields.io/github/languages/top/ChenPaulYu/DJtransGAN?color=pink&style=flat-square)](https://github.com/ChenPaulYu/DJtransGAN/graphs/contributors)|[![](https://flat.badgen.net/github/license/ChenPaulYu/DJtransGAN?label=)](https://github.com/ChenPaulYu/DJtransGAN/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/ChenPaulYu/DJtransGAN?label=)](https://github.com/ChenPaulYu/DJtransGAN/graphs/code-frequency)|
|[AudMIX](https://github.com/dssudake/AudMIX#readme)|A web-based system for processing Audio using Deep Learning|[![](https://img.shields.io/github/languages/top/dssudake/AudMIX?color=pink&style=flat-square)](https://github.com/dssudake/AudMIX/graphs/contributors)|[![](https://flat.badgen.net/github/license/dssudake/AudMIX?label=)](https://github.com/dssudake/AudMIX/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/dssudake/AudMIX/master?label=)](https://github.com/dssudake/AudMIX/graphs/code-frequency)|
|[deep-audio-mixer](https://github.com/apelykh/deep-audio-mixer#readme)|Deep Learning based system for audio mixing|[![](https://img.shields.io/github/languages/top/apelykh/deep-audio-mixer?color=pink&style=flat-square)](https://github.com/apelykh/deep-audio-mixer/graphs/contributors)|[![](https://flat.badgen.net/github/license/apelykh/deep-audio-mixer?label=)](https://github.com/apelykh/deep-audio-mixer/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/apelykh/deep-audio-mixer/master?label=)](https://github.com/apelykh/deep-audio-mixer/graphs/code-frequency)|

## Drums [⌂](#--)
|Git|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Mix-Wave-U-Net](https://github.com/f90/Mix-Wave-U-Net/#readme)|Implementation of the [Mix-Wave-U-Net](https://www.aes.org/e-lib/browse.cfm?elib=21023) for automatic mixing of drums|[![](https://img.shields.io/github/languages/top/f90/Mix-Wave-U-Net/?color=pink&style=flat-square)](https://github.com/f90/Mix-Wave-U-Net//graphs/contributors)|[![](https://flat.badgen.net/github/license/f90/Mix-Wave-U-Net/?label=)](https://github.com/f90/Mix-Wave-U-Net//blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/f90/Mix-Wave-U-Net//master?label=)](https://github.com/f90/Mix-Wave-U-Net//graphs/code-frequency)|

## Bass [⌂](#--)
|Git|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Beatle-Basslines](https://github.com/jmineroff/Beatle-Basslines#readme)|Deep Learning model for creation of an instrument track in a performer's style from other tracks in a MIDI file|[![](https://img.shields.io/github/languages/top/jmineroff/Beatle-Basslines?color=pink&style=flat-square)](https://github.com/jmineroff/Beatle-Basslines/graphs/contributors)|[![](https://flat.badgen.net/github/license/jmineroff/Beatle-Basslines?label=)](https://github.com/jmineroff/Beatle-Basslines/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/jmineroff/Beatle-Basslines/master?label=)](https://github.com/jmineroff/Beatle-Basslines/graphs/code-frequency)|

## Guitar [⌂](#--)
|Git|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[SmartAmpPro](https://github.com/GuitarML/SmartAmpPro#readme)|Guitar plugin made with JUCE that uses neural network models to emulate real world hardware|[![](https://img.shields.io/github/languages/top/GuitarML/SmartAmpPro?color=pink&style=flat-square)](https://github.com/GuitarML/SmartAmpPro/graphs/contributors)|[![](https://flat.badgen.net/github/license/GuitarML/SmartAmpPro?label=)](https://github.com/GuitarML/SmartAmpPro/blob/main/LICENSE.txt)|[![](https://flat.badgen.net/github/last-commit/GuitarML/SmartAmpPro?label=)](https://github.com/GuitarML/SmartAmpPro/graphs/code-frequency)|
|[SmartGuitarAmp](https://github.com/GuitarML/SmartGuitarAmp#readme)|Guitar plugin made with JUCE that uses neural network models to emulate real world hardware|[![](https://img.shields.io/github/languages/top/GuitarML/SmartGuitarAmp?color=pink&style=flat-square)](https://github.com/GuitarML/SmartGuitarAmp/graphs/contributors)|[![](https://flat.badgen.net/github/license/GuitarML/SmartGuitarAmp?label=)](https://github.com/GuitarML/SmartGuitarAmp/blob/main/LICENSE.txt)|[![](https://flat.badgen.net/github/last-commit/GuitarML/SmartGuitarAmp?label=)](https://github.com/GuitarML/SmartGuitarAmp/graphs/code-frequency)|
|[GuitarAmp](https://github.com/apohl79/GuitarAmp#readme)|Guitar plugin using neural networks to capture real amps and pedals|[![](https://img.shields.io/github/languages/top/apohl79/GuitarAmp?color=pink&style=flat-square)](https://github.com/apohl79/GuitarAmp/graphs/contributors)|[![](https://flat.badgen.net/badge/license/OWN/blue?label=)](https://www.cockos.com/wdl/)|[![](https://flat.badgen.net/github/last-commit/apohl79/GuitarAmp?label=)](https://github.com/apohl79/GuitarAmp/graphs/code-frequency)|
|[Automated-Guitar Amplifier Modelling](https://github.com/Alec-Wright/Automated-GuitarAmpModelling#readme)|Neural network training scripts and trained models of guitar amplifiers and distortion pedals|[![](https://img.shields.io/github/languages/top/Alec-Wright/Automated-GuitarAmpModelling?color=pink&style=flat-square)](https://github.com/Alec-Wright/Automated-GuitarAmpModelling/graphs/contributors)|[![](https://flat.badgen.net/github/license/Alec-Wright/Automated-GuitarAmpModelling?label=)](https://github.com/Alec-Wright/Automated-GuitarAmpModelling/blob/main/LICENSE.md)|[![](https://flat.badgen.net/github/last-commit/Alec-Wright/Automated-GuitarAmpModelling?label=)](https://github.com/Alec-Wright/Automated-GuitarAmpModelling/graphs/code-frequency)|
|[GuitarLSTM](https://github.com/GuitarML/GuitarLSTM#readme)|Deep learning models for guitar amp/pedal emulation using LSTM with Keras|[![](https://img.shields.io/github/languages/top/GuitarML/GuitarLSTM?color=pink&style=flat-square)](https://github.com/GuitarML/GuitarLSTM/graphs/contributors)|[![](https://flat.badgen.net/github/license/GuitarML/GuitarLSTM?label=)](https://github.com/GuitarML/GuitarLSTM/blob/main/LICENSE.txt)|[![](https://flat.badgen.net/github/last-commit/GuitarML/GuitarLSTM?label=)](https://github.com/GuitarML/GuitarLSTM/graphs/code-frequency)|
|[NAM: neural amp modeler](https://github.com/sdatkinson/neural-amp-modeler#readme)|Neural network emulator for guitar amplifiers|[![](https://img.shields.io/github/languages/top/sdatkinson/neural-amp-modeler?color=pink&style=flat-square)](https://github.com/sdatkinson/neural-amp-modeler/graphs/contributors)|[![](https://flat.badgen.net/github/license/sdatkinson/neural-amp-modeler?label=)](https://github.com/sdatkinson/neural-amp-modeler/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/sdatkinson/neural-amp-modeler?label=)](https://github.com/sdatkinson/neural-amp-modeler/graphs/code-frequency)|
|[CNN Distortion](https://github.com/mganger/cnn-distortion#readme)|Combine deep learning and DSP|[![](https://img.shields.io/github/languages/top/mganger/cnn-distortion?color=pink&style=flat-square)](https://github.com/mganger/cnn-distortion/graphs/contributors)|[![](https://flat.badgen.net/github/license/mganger/cnn-distortion?label=)](https://github.com/mganger/cnn-distortion/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/mganger/cnn-distortion?label=)](https://github.com/mganger/cnn-distortion/graphs/code-frequency)|
|[Deep Guitar Amplifier](https://github.com/salvatorefara/deepGuitarAmp#readme)|A little project to practice Tensorflow/Keras where I use deep learning for black-box modelling of a guitar amplifier|[![](https://img.shields.io/github/languages/top/salvatorefara/deepGuitarAmp?color=pink&style=flat-square)](https://github.com/salvatorefara/deepGuitarAmp/graphs/contributors)|[![](https://flat.badgen.net/github/license/salvatorefara/deepGuitarAmp?label=)](https://github.com/salvatorefara/deepGuitarAmp/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/salvatorefara/deepGuitarAmp?label=)](https://github.com/salvatorefara/deepGuitarAmp/graphs/code-frequency)|

## MIDI [⌂](#--)
|Git|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[NeuralNote](https://github.com/DamRsn/NeuralNote#readme)|Audio Plugin for Audio to MIDI transcription using deep learning|[![](https://img.shields.io/github/languages/top/DamRsn/NeuralNote?color=pink&style=flat-square)](https://github.com/DamRsn/NeuralNote/graphs/contributors)|[![](https://flat.badgen.net/github/license/DamRsn/NeuralNote?label=)](https://github.com/DamRsn/NeuralNote/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/DamRsn/NeuralNote/master?label=)](https://github.com/DamRsn/NeuralNote/graphs/code-frequency)|

## Source Separation [⌂](#--)
|Git|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[audioss](https://github.com/victor23k/audioss#readme)|Audio source separation tool using a neural network|[![](https://img.shields.io/github/languages/top/victor23k/audioss?color=pink&style=flat-square)](https://github.com/victor23k/audioss/graphs/contributors)|[![](https://flat.badgen.net/github/license/victor23k/audioss?label=)](https://github.com/victor23k/audioss/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/victor23k/audioss?label=)](https://github.com/victor23k/audioss/graphs/code-frequency)|
|[DeepConvSep](https://github.com/MTG/DeepConvSep#readme)|Deep Convolutional Neural Networks for Musical Source Separation|[![](https://img.shields.io/github/languages/top/MTG/DeepConvSep?color=pink&style=flat-square)](https://github.com/MTG/DeepConvSep/graphs/contributors)|[![](https://flat.badgen.net/github/license/MTG/DeepConvSep?label=)](https://github.com/MTG/DeepConvSep/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/MTG/DeepConvSep?label=)](https://github.com/MTG/DeepConvSep/graphs/code-frequency)|
|[Audio Source Separation using Low Latency Neural Network](https://github.com/SConsul/audio-source-separation#readme)|PyTorch code based on "[Monoaural Audio Source Separation Using Deep Convolutional Neural Networks](https://pdfs.semanticscholar.org/fede/f8eedef76692d805a6a3380159a95b79b4de.pdf)" to separate instruments from music using a low-latency neural network|[![](https://img.shields.io/github/languages/top/SConsul/audio-source-separation?color=pink&style=flat-square)](https://github.com/SConsul/audio-source-separation/graphs/contributors)|[![](https://flat.badgen.net/github/license/SConsul/audio-source-separation?label=)](https://github.com/SConsul/audio-source-separation/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/SConsul/audio-source-separation?label=)](https://github.com/SConsul/audio-source-separation/graphs/code-frequency)|
|[A Wavenet for Music Source Separation](https://github.com/francesclluis/source-separation-wavenet#readme)|A neural network for end-to-end music source separation|[![](https://img.shields.io/github/languages/top/francesclluis/source-separation-wavenet?color=pink&style=flat-square)](https://github.com/francesclluis/source-separation-wavenet/graphs/contributors)|[![](https://flat.badgen.net/github/license/francesclluis/source-separation-wavenet?label=)](https://github.com/francesclluis/source-separation-wavenet/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/francesclluis/source-separation-wavenet?label=)](https://github.com/francesclluis/source-separation-wavenet/graphs/code-frequency)|
|[BS-RoFormer](https://github.com/lucidrains/BS-RoFormer#readme)|Implementation of [Band Split Roformer](https://arxiv.org/abs/2309.02612), SOTA Attention network for music source separation|[![](https://img.shields.io/github/languages/top/lucidrains/BS-RoFormer?color=pink&style=flat-square)](https://github.com/lucidrains/BS-RoFormer/graphs/contributors)|[![](https://flat.badgen.net/github/license/lucidrains/BS-RoFormer?label=)](https://github.com/lucidrains/BS-RoFormer/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/lucidrains/BS-RoFormer?label=)](https://github.com/lucidrains/BS-RoFormer/graphs/code-frequency)|
|[GAN_SASS_TF](https://github.com/ahmedassal/GAN_SASS_TF#readme)|TensorFlow implementation of "GAN Single Audio Source Separation"|[![](https://img.shields.io/github/languages/top/ahmedassal/GAN_SASS_TF?color=pink&style=flat-square)](https://github.com/ahmedassal/GAN_SASS_TF/graphs/contributors)|[![](https://flat.badgen.net/github/license/ahmedassal/GAN_SASS_TF?label=)](https://github.com/ahmedassal/GAN_SASS_TF/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/ahmedassal/GAN_SASS_TF?label=)](https://github.com/ahmedassal/GAN_SASS_TF/graphs/code-frequency)|
|[Audio Source Separation](https://github.com/Ankit123Mishra/audio-source-separation#readme)|Deep Neural Network model for Audio source separation|[![](https://img.shields.io/github/languages/top/Ankit123Mishra/audio-source-separation?color=pink&style=flat-square)](https://github.com/Ankit123Mishra/audio-source-separation/graphs/contributors)|[![](https://flat.badgen.net/github/license/Ankit123Mishra/audio-source-separation?label=)](https://github.com/Ankit123Mishra/audio-source-separation/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/Ankit123Mishra/audio-source-separation?label=)](https://github.com/Ankit123Mishra/audio-source-separation/graphs/code-frequency)|
|[CASS](https://github.com/ongyongzheng/cass#readme)|CROSS ADVERSARIAL SOURCE SEPARATION VIA AUTOENCODER|[![](https://img.shields.io/github/languages/top/ongyongzheng/cass?color=pink&style=flat-square)](https://github.com/ongyongzheng/cass/graphs/contributors)|[![](https://flat.badgen.net/github/license/ongyongzheng/cass?label=)](https://github.com/ongyongzheng/cass/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/ongyongzheng/cass?label=)](https://github.com/ongyongzheng/cass/graphs/code-frequency)|
|[GENERATIVE ADVERSARIAL SOURCE SEPARATION](https://github.com/ycemsubakan/sourceseparation_misc#readme)|Generative sourceseparation with GANs|[![](https://img.shields.io/github/languages/top/ycemsubakan/sourceseparation_misc?color=pink&style=flat-square)](https://github.com/ycemsubakan/sourceseparation_misc/graphs/contributors)|[![](https://flat.badgen.net/github/license/ycemsubakan/sourceseparation_misc?label=)](https://github.com/ycemsubakan/sourceseparation_misc/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/ycemsubakan/sourceseparation_misc?label=)](https://github.com/ycemsubakan/sourceseparation_misc/graphs/code-frequency)|

## Misc [⌂](#--)
|Git|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Automatic Transcription via DL](https://github.com/9rg/AutomaticTranscription-viaDL#readme)|Deep learning Japanese instruments - flute and drum - automatic transcription|[![](https://img.shields.io/github/languages/top/9rg/AutomaticTranscription-viaDL?color=pink&style=flat-square)](https://github.com/9rg/AutomaticTranscription-viaDL/graphs/contributors)|[![](https://flat.badgen.net/github/license/9rg/AutomaticTranscription-viaDL?label=)](https://github.com/9rg/AutomaticTranscription-viaDL/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/9rg/AutomaticTranscription-viaDL/master?label=)](https://github.com/9rg/AutomaticTranscription-viaDL/graphs/code-frequency)|
|[Audio-Bleeding-Removal](https://github.com/its-rajesh/Audio-Bleeding-Removal#readme)|Neural networks for removal of bleeding in music signals|[![](https://img.shields.io/github/languages/top/its-rajesh/Audio-Bleeding-Removal?color=pink&style=flat-square)](https://github.com/its-rajesh/Audio-Bleeding-Removal/graphs/contributors)|[![](https://flat.badgen.net/github/license/its-rajesh/Audio-Bleeding-Removal?label=)](https://github.com/its-rajesh/Audio-Bleeding-Removal/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/its-rajesh/Audio-Bleeding-Removal/main?label=)](https://github.com/its-rajesh/Audio-Bleeding-Removal/graphs/code-frequency)|
|[Musical-Accompaniment-GAN](https://github.com/RaphRozenblum/Musical-Accompaniment-GAN#readme)|Deep Learning project to create a model for accompaniment of piano tracks with guitar, strings, bass and drums|[![](https://img.shields.io/github/languages/top/RaphRozenblum/Musical-Accompaniment-GAN?color=pink&style=flat-square)](https://github.com/RaphRozenblum/Musical-Accompaniment-GAN/graphs/contributors)|[![](https://flat.badgen.net/github/license/RaphRozenblum/Musical-Accompaniment-GAN?label=)](https://github.com/RaphRozenblum/Musical-Accompaniment-GAN/blob/master/LICENSE)|[![](https://flat.badgen.net/github/last-commit/RaphRozenblum/Musical-Accompaniment-GAN/master?label=)](https://github.com/RaphRozenblum/Musical-Accompaniment-GAN/graphs/code-frequency)|
