# [![AUDIO](https://flat.badgen.net/badge/HyMPS/AUDIO/green?scale=1.8)](https://github.com/FORARTfe/HyMPS#- "AUDIO section") [![Effects](https://flat.badgen.net/badge/HyMPS/AI-based/blue?scale=1.8&label=)](https://github.com/FORARTfe/HyMPS/blob/main/Audio/AI-based.md#-- "AI-based category") [![Voicing](https://flat.badgen.net/badge/HyMPS/Voicing/red?scale=1.8&label=)](https://github.com/FORARTfe/HyMPS/blob/main/Audio/AI-Voicing.md#--- "Voicing page") <img align="right" alt="stable" src="https://user-images.githubusercontent.com/171307/210727719-14b940a2-d1dc-4991-b6a4-7add74463ce8.png" width="5%" />

### ðŸ“ [Cloners](#cloners-) - [Denoisers](#denoisers-) - [Dubbers](#dubbers-) - [Enhancers](#enhancers-) - [Stylers](#stylers-) - [Speech](#speech) - [TTSers](#ttsers-)

> [!WARNING]
> $\color{orange}\textsf{{SORTING: Language (a>z) > License (openness) > Repository (a>z)}}$

### Cloners [âŒ‚](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Applio](https://github.com/IAHispano/Applio#readme)|VITS-based Voice Conversion focused on simplicity, quality and performance|[![](https://img.shields.io/github/languages/top/IAHispano/Applio?color=pink&style=flat-square)](https://github.com/IAHispano/Applio/graphs/contributors)|[![](https://flat.badgen.net/github/license/IAHispano/Applio?label=)](https://github.com/IAHispano/Applio/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/IAHispano/Applio?style=flat-square&label=)](https://github.com/IAHispano/Applio/graphs/code-frequency)|
|[OpenVoice](https://github.com/myshell-ai/OpenVoice#readme)|Versatile Instant Voice Cloning ([paper](https://arxiv.org/abs/2312.01479))|[![](https://img.shields.io/github/languages/top/myshell-ai/OpenVoice?color=pink&style=flat-square)](https://github.com/myshell-ai/OpenVoice/graphs/contributors)|[![](https://flat.badgen.net/github/license/myshell-ai/OpenVoice?label=)](https://github.com/myshell-ai/OpenVoice/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/myshell-ai/OpenVoice?style=flat-square&label=)](https://github.com/myshell-ai/OpenVoice/graphs/code-frequency)|
|[Real-Time-Voice-Cloning](https://github.com/CorentinJ/Real-Time-Voice-Cloning#readme)|Clone a voice in 5 seconds to generate arbitrary speech in real-time|[![](https://img.shields.io/github/languages/top/CorentinJ/Real-Time-Voice-Cloning?color=pink&style=flat-square)](https://github.com/CorentinJ/Real-Time-Voice-Cloning/graphs/contributors)|[![](https://flat.badgen.net/github/license/CorentinJ/Real-Time-Voice-Cloning?label=)](https://github.com/CorentinJ/Real-Time-Voice-Cloning/issues/1291)|[![](https://img.shields.io/github/last-commit/CorentinJ/Real-Time-Voice-Cloning?style=flat-square&label=)](https://github.com/CorentinJ/Real-Time-Voice-Cloning/graphs/code-frequency)|

### Denoisers [âŒ‚](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Resemble Enhance](https://github.com/resemble-ai/resemble-enhance#readme)|AI powered speech denoising and enhancement|[![](https://img.shields.io/github/languages/top/resemble-ai/resemble-enhance?color=pink&style=flat-square)](https://github.com/resemble-ai/resemble-enhance/graphs/contributors)|[![](https://flat.badgen.net/github/license/resemble-ai/resemble-enhance?label=)](https://github.com/resemble-ai/resemble-enhance/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/resemble-ai/resemble-enhance?style=flat-square&label=)](https://github.com/resemble-ai/resemble-enhance/graphs/code-frequency)|
|[speech-denoiser](https://github.com/MateuszKrol13/speech-denoiser#readme)|denoiser|[![](https://img.shields.io/github/languages/top/MateuszKrol13/speech-denoiser?color=pink&style=flat-square)](https://github.com/MateuszKrol13/speech-denoiser/graphs/contributors)|[![](https://flat.badgen.net/github/license/MateuszKrol13/speech-denoiser?label=)](https://github.com/MateuszKrol13/speech-denoiser/issues/1)|[![](https://img.shields.io/github/last-commit/MateuszKrol13/speech-denoiser?style=flat-square&label=)](https://github.com/MateuszKrol13/speech-denoiser/graphs/code-frequency)|

### Dubbers [âŒ‚](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Kara-Audio](https://github.com/abus-aikorea/kara-audio#readme)|Gradio web-ui for vocal remover that uses [demucs](https://github.com/facebookresearch/demucs#readme) and [mdx-net](https://github.com/kuielab/mdx-net) + automatic subtitle creation using faster [whisper](https://github.com/openai/whisper)|[![](https://img.shields.io/github/languages/top/abus-aikorea/kara-audio?color=pink&style=flat-square)](https://github.com/abus-aikorea/kara-audio/graphs/contributors)|[![](https://flat.badgen.net/github/license/abus-aikorea/kara-audio?label=)]()|[![](https://img.shields.io/github/last-commit/abus-aikorea/kara-audio?style=flat-square&label=)](https://github.com/abus-aikorea/kara-audio/graphs/code-frequency)|
|[VoiceCraftAI](https://github.com/HallowSiddharth/VoiceCraftAI#readme)|A revolutionary AI tool to dub videos into multiple regional languages and lip-sync at the same time|[![](https://img.shields.io/github/languages/top/HallowSiddharth/VoiceCraftAI?color=pink&style=flat-square)](https://github.com/HallowSiddharth/VoiceCraftAI/graphs/contributors)|[![](https://flat.badgen.net/github/license/HallowSiddharth/VoiceCraftAI?label=)](https://github.com/HallowSiddharth/VoiceCraftAI/issues/19)|[![](https://img.shields.io/github/last-commit/HallowSiddharth/VoiceCraftAI?style=flat-square&label=)](https://github.com/HallowSiddharth/VoiceCraftAI/graphs/code-frequency)|
|[Linly-Dubbing](https://github.com/Kedreamix/Linly-Dubbing#readme)|An intelligent multi-language AI dubbing and translation tool that offers diverse and high-quality dubbing options by integrating [Linly-Talker](https://github.com/Kedreamix/Linly-Talker#readme)â€™s digital human lip-sync technology, creating a more natural multi-language video experience|[![](https://img.shields.io/github/languages/top/Kedreamix/Linly-Dubbing?color=pink&style=flat-square)](https://github.com/Kedreamix/Linly-Dubbing/graphs/contributors)|[![](https://flat.badgen.net/github/license/Kedreamix/Linly-Dubbing?label=)](https://github.com/Kedreamix/Linly-Dubbing/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/Kedreamix/Linly-Dubbing?style=flat-square&label=)](https://github.com/Kedreamix/Linly-Dubbing/graphs/code-frequency)
|[voice_ukr_to_eng](https://github.com/Nik-Kras/voice_ukr_to_eng#readme)|Tool to generate English AI Dubbing for a YouTube video|[![](https://img.shields.io/github/languages/top/Nik-Kras/voice_ukr_to_eng?color=pink&style=flat-square)](https://github.com/Nik-Kras/voice_ukr_to_eng/graphs/contributors)|[![](https://flat.badgen.net/github/license/Nik-Kras/voice_ukr_to_eng?label=)](https://github.com/Nik-Kras/voice_ukr_to_eng/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/Nik-Kras/voice_ukr_to_eng?style=flat-square&label=)](https://github.com/Nik-Kras/voice_ukr_to_eng/graphs/code-frequency)|
|[Emotionally-Intelligent-AI-based-movie-dubbing](https://github.com/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing#readme)|AI to seamlessly translate and dub content into any language while preserving the original speaker's emotions, characteristics, and authenticity|[![](https://img.shields.io/github/languages/top/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing?color=pink&style=flat-square)](https://github.com/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing/graphs/contributors)|[![](https://flat.badgen.net/github/license/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing?label=)](https://github.com/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing/issues/1)|[![](https://img.shields.io/github/last-commit/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing?style=flat-square&label=)](https://github.com/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing/graphs/code-frequency)|
|[pyvideotrans](https://github.com/jianchang512/pyvideotrans#readme)|Translate the video from one language to another and add dubbing|[![](https://img.shields.io/github/languages/top/jianchang512/pyvideotrans?color=pink&style=flat-square)](https://github.com/jianchang512/pyvideotrans/graphs/contributors)|[![](https://flat.badgen.net/github/license/jianchang512/pyvideotrans?label=)](https://github.com/jianchang512/pyvideotrans/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/jianchang512/pyvideotrans?style=flat-square&label=)](https://github.com/jianchang512/pyvideotrans/graphs/code-frequency)|
|[AutoDub](https://github.com/frrobledo/AutoDub#readme)|An advanced AI-powered tool that automatically translates and dubs YouTube videos into different languages while dynamically adjusting video speed|[![](https://img.shields.io/github/languages/top/frrobledo/AutoDub?color=pink&style=flat-square)](https://github.com/frrobledo/AutoDub/graphs/contributors)|[![](https://flat.badgen.net/github/license/frrobledo/AutoDub?label=)](https://github.com/frrobledo/AutoDub/issues/2)|[![](https://img.shields.io/github/last-commit/frrobledo/AutoDub?style=flat-square&label=)](https://github.com/frrobledo/AutoDub/graphs/code-frequency)|
|[AI Dubs over Subs](https://github.com/ayushKataria/ai_dub_over_subs#readme)|A set of python scripts that take a video file as input and try to create a new video dubbed by AI|[![](https://img.shields.io/github/languages/top/ayushKataria/ai_dub_over_subs?color=pink&style=flat-square)](https://github.com/ayushKataria/ai_dub_over_subs/graphs/contributors)|[![](https://flat.badgen.net/github/license/ayushKataria/ai_dub_over_subs?label=)](https://github.com/ayushKataria/ai_dub_over_subs/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/ayushKataria/ai_dub_over_subs?style=flat-square&label=)](https://github.com/ayushKataria/ai_dub_over_subs/graphs/code-frequency)|
|[AI Video Dubbing](https://github.com/Aditya1Jhaveri/AI-Video-Dubbing#readme)|Automates translation and dubbing by transcribing audio with Speech-to-Text, translating it with the Translation API, and generating speech with Text-to-Speech using Google APIs|[![](https://img.shields.io/github/languages/top/Aditya1Jhaveri/AI-Video-Dubbing?color=pink&style=flat-square)](https://github.com/Aditya1Jhaveri/AI-Video-Dubbing/graphs/contributors)|[![](https://flat.badgen.net/github/license/Aditya1Jhaveri/AI-Video-Dubbing?label=)](https://github.com/Aditya1Jhaveri/AI-Video-Dubbing/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/Aditya1Jhaveri/AI-Video-Dubbing?style=flat-square&label=)](https://github.com/Aditya1Jhaveri/AI-Video-Dubbing/graphs/code-frequency)|
|[Google AI Dubbing](https://github.com/google/ai_video_dubbing#readme)|Allows you to create localized videos using the same video base and adding translations using Google AI Powered TextToSpeech API|[![](https://img.shields.io/github/languages/top/google/ai_video_dubbing?color=pink&style=flat-square)](https://github.com/google/ai_video_dubbing/graphs/contributors)|[![](https://flat.badgen.net/github/license/google/ai_video_dubbing?label=)](https://github.com/google/ai_video_dubbing/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/google/ai_video_dubbing?style=flat-square&label=)](https://github.com/google/ai_video_dubbing/graphs/code-frequency)|
|[Open dubbing](https://github.com/Softcatala/open-dubbing#readme)|An AI dubbing system which uses machine learning models to automatically translate and synchronize audio dialogue into different languages|[![](https://img.shields.io/github/languages/top/Softcatala/open-dubbing?color=pink&style=flat-square)](https://github.com/Softcatala/open-dubbing/graphs/contributors)|[![](https://flat.badgen.net/github/license/Softcatala/open-dubbing?label=)](https://github.com/Softcatala/open-dubbing/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/Softcatala/open-dubbing?style=flat-square&label=)](https://github.com/Softcatala/open-dubbing/graphs/code-frequency)|
|[YouDub](https://github.com/liuzhao1225/YouDub#readme)|An innovative open source tool that focuses on translating and dubbing premium videos from platforms such as YouTube into Chinese|[![](https://img.shields.io/github/languages/top/liuzhao1225/YouDub?color=pink&style=flat-square)](https://github.com/liuzhao1225/YouDub/graphs/contributors)|[![](https://flat.badgen.net/github/license/liuzhao1225/YouDub?label=)](https://github.com/liuzhao1225/YouDub/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/liuzhao1225/YouDub?style=flat-square&label=)](https://github.com/liuzhao1225/YouDub/graphs/code-frequency)|
|[Open-Source AI Video Dubber](https://github.com/EliasLindbergs/ai-video-dubber#readme)|Automatically dub any video into English while keeping the original voice styles|[![](https://img.shields.io/github/languages/top/EliasLindbergs/ai-video-dubber?color=pink&style=flat-square)](https://github.com/EliasLindbergs/ai-video-dubber/graphs/contributors)|[![](https://flat.badgen.net/github/license/EliasLindbergs/ai-video-dubber?label=)](https://github.com/EliasLindbergs/ai-video-dubber/issues/2)|[![](https://img.shields.io/github/last-commit/EliasLindbergs/ai-video-dubber?style=flat-square&label=)](https://github.com/EliasLindbergs/ai-video-dubber/graphs/code-frequency)|
|[Subdub](https://github.com/lukaszliniewicz/Subdub#readme)|A command line Python app offering a video-to-dubbed-video workflow with transcription, translation and synchronisation|[![](https://img.shields.io/github/languages/top/lukaszliniewicz/Subdub?color=pink&style=flat-square)](https://github.com/lukaszliniewicz/Subdub/graphs/contributors)|[![](https://flat.badgen.net/github/license/lukaszliniewicz/Subdub?label=)](https://github.com/lukaszliniewicz/Subdub/issues/1)|[![](https://img.shields.io/github/last-commit/lukaszliniewicz/Subdub?style=flat-square&label=)](https://github.com/lukaszliniewicz/Subdub/graphs/code-frequency)|
|[WeeaBlind](https://github.com/FlorianEagox/WeeaBlind#readme)|A program to dub non-english media with modern AI speech synthesis, diarization, and voice cloning|[![](https://img.shields.io/github/languages/top/FlorianEagox/WeeaBlind?color=pink&style=flat-square)](https://github.com/FlorianEagox/WeeaBlind/graphs/contributors)|[![](https://flat.badgen.net/github/license/FlorianEagox/WeeaBlind?label=)](https://github.com/FlorianEagox/WeeaBlind/issues/32)|[![](https://img.shields.io/github/last-commit/FlorianEagox/WeeaBlind?style=flat-square&label=)](https://github.com/FlorianEagox/WeeaBlind/graphs/code-frequency)|
|[speech-translator](https://github.com/DigitalEpidemic/ai-voice-translator#readme)|A tool that translates audio into another language with the ability to use your own voice|[![](https://img.shields.io/github/languages/top/DigitalEpidemic/ai-voice-translator?color=pink&style=flat-square)](https://github.com/DigitalEpidemic/ai-voice-translator/graphs/contributors)|[![](https://flat.badgen.net/github/license/DigitalEpidemic/ai-voice-translator?label=)](https://github.com/DigitalEpidemic/ai-voice-translator/issues/2)|[![](https://img.shields.io/github/last-commit/DigitalEpidemic/ai-voice-translator?style=flat-square&label=)](https://github.com/DigitalEpidemic/ai-voice-translator/graphs/code-frequency)|

### Enhancers [âŒ‚](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Speech Enhancement / Noise Reduction](https://github.com/Priyal-0911/Speech-Enhancement-Noise-Reduction#readme)|Demonstrates the process of enhancing and separating mixed audio sources, such as isolating speech from background noise, using a pre-trained model|[![](https://img.shields.io/github/languages/top/Priyal-0911/Speech-Enhancement-Noise-Reduction?color=pink&style=flat-square)](https://github.com/Priyal-0911/Speech-Enhancement-Noise-Reduction/graphs/contributors)|[![](https://flat.badgen.net/github/license/Priyal-0911/Speech-Enhancement-Noise-Reduction?label=)](https://github.com/Priyal-0911/Speech-Enhancement-Noise-Reduction/issues/1)|[![](https://img.shields.io/github/last-commit/Priyal-0911/Speech-Enhancement-Noise-Reduction?style=flat-square&label=)](https://github.com/Priyal-0911/Speech-Enhancement-Noise-Reduction/graphs/code-frequency)|
|[Resemble Enhance](https://github.com/resemble-ai/resemble-enhance#readme)|An AI-powered tool that aims to improve the overall quality of speech by performing denoising and enhancement|[![](https://img.shields.io/github/languages/top/resemble-ai/resemble-enhance?color=pink&style=flat-square)](https://github.com/resemble-ai/resemble-enhance/graphs/contributors)|[![](https://flat.badgen.net/github/license/resemble-ai/resemble-enhance?label=)](https://github.com/resemble-ai/resemble-enhance/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/resemble-ai/resemble-enhance?style=flat-square&label=)](https://github.com/resemble-ai/resemble-enhance/graphs/code-frequency)|
|[ClearerVoice-Studio](https://github.com/modelscope/ClearerVoice-Studio#readme)|An AI-Powered Speech Processing Toolkit and Open Source SOTA Pretrained Models, Supporting Speech Enhancement, Separation, and Target Speaker Extraction|[![](https://img.shields.io/github/languages/top/modelscope/ClearerVoice-Studio?color=pink&style=flat-square)](https://github.com/modelscope/ClearerVoice-Studio/graphs/contributors)|[![](https://flat.badgen.net/github/license/modelscope/ClearerVoice-Studio?label=)](https://github.com/modelscope/ClearerVoice-Studio/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/modelscope/ClearerVoice-Studio?style=flat-square&label=)](https://github.com/modelscope/ClearerVoice-Studio/graphs/code-frequency)|
|[Deep Learning Based Noise Reduction and Speech Enhancement System](https://github.com/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction#readme)|Implements two deep learning models, one can classify the type of noise, the other can retain human voice and reduce environmental noise|[![](https://img.shields.io/github/languages/top/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction?color=pink&style=flat-square)](https://github.com/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction/graphs/contributors)|[![](https://flat.badgen.net/github/license/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction?label=)](https://github.com/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction/issues/1)|[![](https://img.shields.io/github/last-commit/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction?style=flat-square&label=)](https://github.com/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction/graphs/code-frequency)|


### Stylers [âŒ‚](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[AutoPST](https://github.com/auspicious3000/AutoPST#readme)|Global Rhythm Style Transfer Without Text Transcriptions|[![](https://img.shields.io/github/languages/top/auspicious3000/AutoPST?color=pink&style=flat-square)](https://github.com/auspicious3000/AutoPST/graphs/contributors)|[![](https://flat.badgen.net/github/license/auspicious3000/AutoPST?label=)](https://github.com/auspicious3000/AutoPST/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/auspicious3000/AutoPST?style=flat-square&label=)](https://github.com/auspicious3000/AutoPST/graphs/code-frequency)|
|[AutoVC](https://github.com/auspicious3000/autovc#readme)|Zero-Shot Voice Style Transfer with Only Autoencoder Loss|[![](https://img.shields.io/github/languages/top/auspicious3000/autovc?color=pink&style=flat-square)](https://github.com/auspicious3000/autovc/graphs/contributors)|[![](https://flat.badgen.net/github/license/auspicious3000/autovc?label=)](https://github.com/auspicious3000/autovc/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/auspicious3000/autovc?style=flat-square&label=)](https://github.com/auspicious3000/autovc/graphs/code-frequency)|
|[Voice Conversion with Non-Parallel Data](https://github.com/andabi/deep-voice-conversion#readme)|Deep neural networks for voice conversion (voice style transfer) in Tensorflow|[![](https://img.shields.io/github/languages/top/andabi/deep-voice-conversion?color=pink&style=flat-square)](https://github.com/andabi/deep-voice-conversion/graphs/contributors)|[![](https://flat.badgen.net/github/license/andabi/deep-voice-conversion?label=)](https://github.com/andabi/deep-voice-conversion/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/andabi/deep-voice-conversion?style=flat-square&label=)](https://github.com/andabi/deep-voice-conversion/graphs/code-frequency)|
|[StyleSinger](https://github.com/AaronZ345/StyleSinger#readme)|Code for [Style Transfer for Out-of-Domain Singing Voice Synthesis](https://ojs.aaai.org/index.php/AAAI/article/view/29932) paper|[![](https://img.shields.io/github/languages/top/AaronZ345/StyleSinger?color=pink&style=flat-square)](https://github.com/AaronZ345/StyleSinger/graphs/contributors)|[![](https://flat.badgen.net/github/license/AaronZ345/StyleSinger?label=)](https://github.com/AaronZ345/StyleSinger/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/AaronZ345/StyleSinger?style=flat-square&label=)](https://github.com/AaronZ345/StyleSinger/graphs/code-frequency)|
|[Voice style transfer with random CNN](https://github.com/mazzzystar/randomCNN-voice-transfer#readme)|Audio style transfer with shallow random parameters CNN|[![](https://img.shields.io/github/languages/top/mazzzystar/randomCNN-voice-transfer?color=pink&style=flat-square)](https://github.com/mazzzystar/randomCNN-voice-transfer/graphs/contributors)|[![](https://flat.badgen.net/github/license/mazzzystar/randomCNN-voice-transfer?label=)](https://github.com/mazzzystar/randomCNN-voice-transfer/issues/28)|[![](https://img.shields.io/github/last-commit/mazzzystar/randomCNN-voice-transfer?style=flat-square&label=)](https://github.com/mazzzystar/randomCNN-voice-transfer/graphs/code-frequency)|

### Speech [âŒ‚](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[whisper.cpp](https://github.com/ggerganov/whisper.cpp#readme)|High-performance inference of [OpenAI's Whisper](https://github.com/openai/whisper) automatic speech recognition (ASR) model|[![](https://img.shields.io/github/languages/top/ggerganov/whisper.cpp?color=pink&style=flat-square)](https://github.com/ggerganov/whisper.cpp/graphs/contributors)|[![](https://flat.badgen.net/github/license/ggerganov/whisper.cpp?label=)](https://github.com/ggerganov/whisper.cpp/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/ggerganov/whisper.cpp?style=flat-square&label=)](https://github.com/ggerganov/whisper.cpp/graphs/code-frequency)|

### TTSers [âŒ‚](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
