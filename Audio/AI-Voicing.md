# [![AUDIO](https://flat.badgen.net/badge/HyMPS/AUDIO/green?scale=1.8)](https://github.com/FORARTfe/HyMPS#- "AUDIO section") [![Effects](https://flat.badgen.net/badge/HyMPS/AI-based/blue?scale=1.8&label=)](https://github.com/FORARTfe/HyMPS/blob/main/Audio/AI-based.md#-- "AI-based category") [![Voicing](https://flat.badgen.net/badge/HyMPS/Voicing/red?scale=1.8&label=)](https://github.com/FORARTfe/HyMPS/blob/main/Audio/AI-Voicing.md#--- "Voicing page") <a href="https://visitorbadge.io/status?path=https%3A%2F%2Fgithub.com%2FFORARTfe%2FHyMPS%2Fblob%2Fmain%2FAudio%2FAI-Voicing.md"><img align="right" src="https://api.visitorbadge.io/api/combined?path=https%3A%2F%2Fgithub.com%2FFORARTfe%2FHyMPS%2Fblob%2Fmain%2FAudio%2FAI-Voicing.md&label=D%20%2F%20T&labelColor=%23323232&countColor=%23c2ff00&style=flat-square&labelStyle=none" /></a>


### 📁 [Cloners](#cloners-) - [Denoisers](#denoisers-) - [Dubbers](#dubbers-) - [Enhancers](#enhancers-) - [Stylers](#stylers-) - [Speech](#speech-) - [TTSers](#ttsers-)

> [!WARNING]
> $\color{orange}\textsf{{SORTING: Language (a>z) > License (openness) > Repository (a>z)}}$

### Cloners [⌂](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Applio](https://github.com/IAHispano/Applio#readme)|VITS-based Voice Conversion focused on simplicity, quality and performance|[![](https://img.shields.io/github/languages/top/IAHispano/Applio?color=pink&style=flat-square)](https://github.com/IAHispano/Applio/graphs/contributors)|[![](https://flat.badgen.net/github/license/IAHispano/Applio?label=)](https://github.com/IAHispano/Applio/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/IAHispano/Applio?style=flat-square&label=)](https://github.com/IAHispano/Applio/graphs/code-frequency)|
|[OpenVoice](https://github.com/myshell-ai/OpenVoice#readme)|Versatile Instant Voice Cloning ([paper](https://arxiv.org/abs/2312.01479))|[![](https://img.shields.io/github/languages/top/myshell-ai/OpenVoice?color=pink&style=flat-square)](https://github.com/myshell-ai/OpenVoice/graphs/contributors)|[![](https://flat.badgen.net/github/license/myshell-ai/OpenVoice?label=)](https://github.com/myshell-ai/OpenVoice/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/myshell-ai/OpenVoice?style=flat-square&label=)](https://github.com/myshell-ai/OpenVoice/graphs/code-frequency)|
|[Real-Time Voice Cloning](https://github.com/CorentinJ/Real-Time-Voice-Cloning#readme)|Clone a voice in 5 seconds to generate arbitrary speech in real-time|[![](https://img.shields.io/github/languages/top/CorentinJ/Real-Time-Voice-Cloning?color=pink&style=flat-square)](https://github.com/CorentinJ/Real-Time-Voice-Cloning/graphs/contributors)|[![](https://flat.badgen.net/github/license/CorentinJ/Real-Time-Voice-Cloning?label=)](https://github.com/CorentinJ/Real-Time-Voice-Cloning/issues/1291)|[![](https://img.shields.io/github/last-commit/CorentinJ/Real-Time-Voice-Cloning?style=flat-square&label=)](https://github.com/CorentinJ/Real-Time-Voice-Cloning/graphs/code-frequency)|
|[Real-Time Voice Cloning](https://github.com/thummalaharitha2002/Real-Time-Voice-Cloning#readme)|An implementation of [Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://arxiv.org/abs/1806.04558) paper with a vocoder that works in real-time|[![](https://img.shields.io/github/languages/top/thummalaharitha2002/Real-Time-Voice-Cloning?color=pink&style=flat-square)](https://github.com/thummalaharitha2002/Real-Time-Voice-Cloning/graphs/contributors)|[![](https://flat.badgen.net/github/license/thummalaharitha2002/Real-Time-Voice-Cloning?label=)](https://github.com/thummalaharitha2002/Real-Time-Voice-Cloning/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/thummalaharitha2002/Real-Time-Voice-Cloning?style=flat-square&label=)](https://github.com/thummalaharitha2002/Real-Time-Voice-Cloning/graphs/code-frequency)|



### Denoisers [⌂](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[denoise-autoencoder](https://github.com/senior-sigan/denoise-autoencoder#readme)|Denoise audio with convolutional autoencoder|[![](https://img.shields.io/github/languages/top/senior-sigan/denoise-autoencoder?color=pink&style=flat-square)](https://github.com/senior-sigan/denoise-autoencoder/graphs/contributors)|[![](https://flat.badgen.net/github/license/senior-sigan/denoise-autoencoder?label=)](https://github.com/senior-sigan/denoise-autoencoder/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/senior-sigan/denoise-autoencoder?style=flat-square&label=)](https://github.com/senior-sigan/denoise-autoencoder/graphs/code-frequency)|
|[Denoiser](https://github.com/immohann/Denoiser#readme)|An AI model to remove noise from the input audio using deep learning model which predicts the type of noise present and filter it out from the audio to give noise-free results|[![](https://img.shields.io/github/languages/top/immohann/Denoiser?color=pink&style=flat-square)](https://github.com/immohann/Denoiser/graphs/contributors)|[![](https://flat.badgen.net/github/license/immohann/Denoiser?label=)](https://github.com/immohann/Denoiser/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/immohann/Denoiser?style=flat-square&label=)](https://github.com/immohann/Denoiser/graphs/code-frequency)|
|[Noise2Noise-denoising](https://github.com/madhavmk/Noise2Noise-audio_denoising_without_clean_training_data#readme)|Source code for the "[Speech Denoising without Clean Training Data: a Noise2Noise Approach](https://arxiv.org/abs/2104.03838)" paper|[![](https://img.shields.io/github/languages/top/madhavmk/Noise2Noise-audio_denoising_without_clean_training_data?color=pink&style=flat-square)](https://github.com/madhavmk/Noise2Noise-audio_denoising_without_clean_training_data/graphs/contributors)|[![](https://flat.badgen.net/github/license/madhavmk/Noise2Noise-audio_denoising_without_clean_training_data?label=)](https://github.com/madhavmk/Noise2Noise-audio_denoising_without_clean_training_data/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/madhavmk/Noise2Noise-audio_denoising_without_clean_training_data?style=flat-square&label=)](https://github.com/madhavmk/Noise2Noise-audio_denoising_without_clean_training_data/graphs/code-frequency)|
|[Audio-Denoiser-CNN](https://github.com/rdadlaney/Audio-Denoiser-CNN#readme)|-|[![](https://img.shields.io/github/languages/top/rdadlaney/Audio-Denoiser-CNN?color=pink&style=flat-square)](https://github.com/rdadlaney/Audio-Denoiser-CNN/graphs/contributors)|[![](https://flat.badgen.net/github/license/rdadlaney/Audio-Denoiser-CNN?label=)](https://github.com/rdadlaney/Audio-Denoiser-CNN/issues/3)|[![](https://img.shields.io/github/last-commit/rdadlaney/Audio-Denoiser-CNN?style=flat-square&label=)](https://github.com/rdadlaney/Audio-Denoiser-CNN/graphs/code-frequency)|
|[DNP](https://github.com/mosheman5/DNP#readme)|A PyTorch implementation for the "[Speech Denoising by Accumulating Per-Frequency Modeling Fluctuations](https://arxiv.org/abs/1904.07612)" paper|[![](https://img.shields.io/github/languages/top/mosheman5/DNP?color=pink&style=flat-square)](https://github.com/mosheman5/DNP/graphs/contributors)|[![](https://flat.badgen.net/github/license/mosheman5/DNP?label=)](https://github.com/mosheman5/DNP/issues/12)|[![](https://img.shields.io/github/last-commit/mosheman5/DNP?style=flat-square&label=)](https://github.com/mosheman5/DNP/graphs/code-frequency)|
|[SAB-cnn-audio-denoiser](https://github.com/EncoraDigital/SAB-cnn-audio-denoiser#readme)|Tensorflow 2.0 implementation of the paper [A Fully Convolutional Neural Network for Speech Enhancement](https://arxiv.org/abs/1609.07132)|[![](https://img.shields.io/github/languages/top/EncoraDigital/SAB-cnn-audio-denoiser?color=pink&style=flat-square)](https://github.com/EncoraDigital/SAB-cnn-audio-denoiser/graphs/contributors)|[![](https://flat.badgen.net/github/license/EncoraDigital/SAB-cnn-audio-denoiser?label=)](https://github.com/EncoraDigital/SAB-cnn-audio-denoiser/issues/17)|[![](https://img.shields.io/github/last-commit/EncoraDigital/SAB-cnn-audio-denoiser?style=flat-square&label=)](https://github.com/EncoraDigital/SAB-cnn-audio-denoiser/graphs/code-frequency)|
|[Clean Sound with AI](https://github.com/BoTtoGo/FixLowFreqSound#readme)|Aims to clean sound recordings from noisy environments using a Convolutional Neural Network (CNN) based on the [CleanUNet](https://arxiv.org/abs/2202.07790) model|[![](https://img.shields.io/github/languages/top/BoTtoGo/FixLowFreqSound?color=pink&style=flat-square)](https://github.com/BoTtoGo/FixLowFreqSound/graphs/contributors)|[![](https://flat.badgen.net/github/license/BoTtoGo/FixLowFreqSound?label=)](https://github.com/BoTtoGo/FixLowFreqSound/issues/1)|[![](https://img.shields.io/github/last-commit/BoTtoGo/FixLowFreqSound?style=flat-square&label=)](https://github.com/BoTtoGo/FixLowFreqSound/graphs/code-frequency)|
|[denoiser](https://github.com/facebookresearch/denoiser#readme)|A PyTorch implementation for the "[Real Time Speech Enhancement in the Waveform Domain](https://arxiv.org/abs/2006.12847)" paper|[![](https://img.shields.io/github/languages/top/facebookresearch/denoiser?color=pink&style=flat-square)](https://github.com/facebookresearch/denoiser/graphs/contributors)|[![](https://img.shields.io/badge/CC%20BY--NC-blue?style=flat-square)](https://github.com/facebookresearch/denoiser/blob/main/LICENSE)|[![](https://flat.badgen.net/static/status/Archived/624711?label=)](https://github.com/facebookresearch/denoiser/graphs/code-frequency)|
|[Speech-enhancement](https://github.com/vbelz/Speech-enhancement#readme)|Deep learning for audio denoising|[![](https://img.shields.io/github/languages/top/vbelz/Speech-enhancement?color=pink&style=flat-square)](https://github.com/vbelz/Speech-enhancement/graphs/contributors)|[![](https://flat.badgen.net/github/license/vbelz/Speech-enhancement?label=)](https://github.com/vbelz/Speech-enhancement/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/vbelz/Speech-enhancement?style=flat-square&label=)](https://github.com/vbelz/Speech-enhancement/graphs/code-frequency)|
|[Resemble Enhance](https://github.com/resemble-ai/resemble-enhance#readme)|AI powered speech denoising and enhancement|[![](https://img.shields.io/github/languages/top/resemble-ai/resemble-enhance?color=pink&style=flat-square)](https://github.com/resemble-ai/resemble-enhance/graphs/contributors)|[![](https://flat.badgen.net/github/license/resemble-ai/resemble-enhance?label=)](https://github.com/resemble-ai/resemble-enhance/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/resemble-ai/resemble-enhance?style=flat-square&label=)](https://github.com/resemble-ai/resemble-enhance/graphs/code-frequency)|
|[DeepFilterNet](https://github.com/Rikorose/DeepFilterNet#readme)|Noise supression using deep filtering|[![](https://img.shields.io/github/languages/top/Rikorose/DeepFilterNet?color=pink&style=flat-square)](https://github.com/Rikorose/DeepFilterNet/graphs/contributors)|[![](https://flat.badgen.net/badge/license/Other/blue?label=)](https://github.com/Rikorose/DeepFilterNet/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/Rikorose/DeepFilterNet?style=flat-square&label=)](https://github.com/Rikorose/DeepFilterNet/graphs/code-frequency)|
|[speech-denoiser](https://github.com/MateuszKrol13/speech-denoiser#readme)|denoiser|[![](https://img.shields.io/github/languages/top/MateuszKrol13/speech-denoiser?color=pink&style=flat-square)](https://github.com/MateuszKrol13/speech-denoiser/graphs/contributors)|[![](https://flat.badgen.net/github/license/MateuszKrol13/speech-denoiser?label=)](https://github.com/MateuszKrol13/speech-denoiser/issues/1)|[![](https://img.shields.io/github/last-commit/MateuszKrol13/speech-denoiser?style=flat-square&label=)](https://github.com/MateuszKrol13/speech-denoiser/graphs/code-frequency)|
|[DTLN](https://github.com/breizhn/DTLN#readme)|Tensorflow 2.x implementation of the DTLN real time speech denoising model|[![](https://img.shields.io/github/languages/top/breizhn/DTLN?color=pink&style=flat-square)](https://github.com/breizhn/DTLN/graphs/contributors)|[![](https://flat.badgen.net/github/license/breizhn/DTLN?label=)](https://github.com/breizhn/DTLN/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/breizhn/DTLN?style=flat-square&label=)](https://github.com/breizhn/DTLN/graphs/code-frequency)|



### Dubbers [⌂](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Voxella](https://github.com/barzegar77/voxella#readme)|This app leverages advanced AI algorithms to automatically detect audio and text in the original language, providing effortless translation and native-like voice dubbing|[![](https://img.shields.io/github/languages/top/barzegar77/voxella?color=pink&style=flat-square)](https://github.com/barzegar77/voxella/graphs/contributors)|[![](https://flat.badgen.net/github/license/barzegar77/voxella?label=)](https://github.com/barzegar77/voxella/issues/1)|[![](https://img.shields.io/github/last-commit/barzegar77/voxella?style=flat-square&label=)](https://github.com/barzegar77/voxella/graphs/code-frequency)|
|[Voice Craft AI](https://github.com/HallowSiddharth/VoiceCraftAI#readme)|An AI tool to dub videos into multiple regional languages and lip-sync at the same time|[![](https://img.shields.io/github/languages/top/HallowSiddharth/VoiceCraftAI?color=pink&style=flat-square)](https://github.com/HallowSiddharth/VoiceCraftAI/graphs/contributors)|[![](https://flat.badgen.net/github/license/HallowSiddharth/VoiceCraftAI?label=)](https://github.com/HallowSiddharth/VoiceCraftAI/issues/19)|[![](https://img.shields.io/github/last-commit/HallowSiddharth/VoiceCraftAI?style=flat-square&label=)](https://github.com/HallowSiddharth/VoiceCraftAI/graphs/code-frequency)|
|[DubFlow](https://github.com/Badri467/DubFlow#readme)|It lets you effortlessly dub YouTube videos into any language with high-quality translations and synced audio|[![](https://img.shields.io/github/languages/top/Badri467/DubFlow?color=pink&style=flat-square)](https://github.com/Badri467/DubFlow/graphs/contributors)|[![](https://flat.badgen.net/github/license/Badri467/DubFlow?label=)](https://github.com/Badri467/DubFlow/issues/2)|[![](https://img.shields.io/github/last-commit/Badri467/DubFlow?style=flat-square&label=)](https://github.com/Badri467/DubFlow/graphs/code-frequency)|
|[Linly-Dubbing](https://github.com/Kedreamix/Linly-Dubbing#readme)|An intelligent multi-language AI dubbing and translation tool that offers diverse and high-quality dubbing options by integrating [Linly-Talker](https://github.com/Kedreamix/Linly-Talker#readme)’s digital human lip-sync technology, creating a more natural multi-language video experience|[![](https://img.shields.io/github/languages/top/Kedreamix/Linly-Dubbing?color=pink&style=flat-square)](https://github.com/Kedreamix/Linly-Dubbing/graphs/contributors)|[![](https://flat.badgen.net/github/license/Kedreamix/Linly-Dubbing?label=)](https://github.com/Kedreamix/Linly-Dubbing/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/Kedreamix/Linly-Dubbing?style=flat-square&label=)](https://github.com/Kedreamix/Linly-Dubbing/graphs/code-frequency)
|[voice_ukr_to_eng](https://github.com/Nik-Kras/voice_ukr_to_eng#readme)|Tool to generate English AI Dubbing for a YouTube video|[![](https://img.shields.io/github/languages/top/Nik-Kras/voice_ukr_to_eng?color=pink&style=flat-square)](https://github.com/Nik-Kras/voice_ukr_to_eng/graphs/contributors)|[![](https://flat.badgen.net/github/license/Nik-Kras/voice_ukr_to_eng?label=)](https://github.com/Nik-Kras/voice_ukr_to_eng/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/Nik-Kras/voice_ukr_to_eng?style=flat-square&label=)](https://github.com/Nik-Kras/voice_ukr_to_eng/graphs/code-frequency)|
|[Emotionally-Intelligent-AI-based-movie-dubbing](https://github.com/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing#readme)|AI to seamlessly translate and dub content into any language while preserving the original speaker's emotions, characteristics, and authenticity|[![](https://img.shields.io/github/languages/top/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing?color=pink&style=flat-square)](https://github.com/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing/graphs/contributors)|[![](https://flat.badgen.net/github/license/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing?label=)](https://github.com/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing/issues/1)|[![](https://img.shields.io/github/last-commit/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing?style=flat-square&label=)](https://github.com/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing/graphs/code-frequency)|
|[Multilingual audio visual system with lip synchronization using GAN](https://github.com/Goutham-P-S/Multilingual-audio-visual-system-with-lip-synchronization-using-GAN#readme)|This system takes a video in any language and generates a new video with synchronized lip movements speaking in English|[![](https://img.shields.io/github/languages/top/Goutham-P-S/Multilingual-audio-visual-system-with-lip-synchronization-using-GAN?color=pink&style=flat-square)](https://github.com/Goutham-P-S/Multilingual-audio-visual-system-with-lip-synchronization-using-GAN/graphs/contributors)|[![](https://flat.badgen.net/github/license/Goutham-P-S/Multilingual-audio-visual-system-with-lip-synchronization-using-GAN?label=)](https://github.com/Goutham-P-S/Multilingual-audio-visual-system-with-lip-synchronization-using-GAN/issues/2)|[![](https://img.shields.io/github/last-commit/Goutham-P-S/Multilingual-audio-visual-system-with-lip-synchronization-using-GAN?style=flat-square&label=)](https://github.com/Goutham-P-S/Multilingual-audio-visual-system-with-lip-synchronization-using-GAN/graphs/code-frequency)|
|[Video Dubbing Tool](https://github.com/Eng-Elias/video_dubbing_tool#readme)|A fully-featured, multi-language video dubbing tool with a modern Streamlit GUI|[![](https://img.shields.io/github/languages/top/Eng-Elias/video_dubbing_tool?color=pink&style=flat-square)](https://github.com/Eng-Elias/video_dubbing_tool/graphs/contributors)|[![](https://img.shields.io/badge/CC%20BY--NC--SA-blue?style=flat-square)]([https://github.com/facebookresearch/denoiser/blob/main/LICENSE](https://github.com/Eng-Elias/video_dubbing_tool/blob/main/LICENSE))|[![](https://img.shields.io/github/last-commit/Eng-Elias/video_dubbing_tool?style=flat-square&label=)](https://github.com/Eng-Elias/video_dubbing_tool/graphs/code-frequency)|
|[Auto Synced & Translated Dubs](https://github.com/ThioJoe/Auto-Synced-Translated-Dubs#readme)|Automatically translates the text of a video into chosen languages based on a subtitle file, uses AI voice to dub the video, while keeping it properly synced to the original video using the subtitle's timings|[![](https://img.shields.io/github/languages/top/ThioJoe/Auto-Synced-Translated-Dubs?color=pink&style=flat-square)](https://github.com/ThioJoe/Auto-Synced-Translated-Dubs/graphs/contributors)|[![](https://flat.badgen.net/github/license/ThioJoe/Auto-Synced-Translated-Dubs?label=)](https://github.com/ThioJoe/Auto-Synced-Translated-Dubs/blob/main/LICENSE.md)|[![](https://img.shields.io/github/last-commit/ThioJoe/Auto-Synced-Translated-Dubs?style=flat-square&label=)](https://github.com/ThioJoe/Auto-Synced-Translated-Dubs/graphs/code-frequency)|
|[Kara-Audio](https://github.com/abus-aikorea/kara-audio#readme)|Gradio web-ui for vocal remover that uses [demucs](https://github.com/facebookresearch/demucs#readme) and [MDX-Net](https://github.com/kuielab/mdx-net#readme) + automatic subtitle creation using faster [Whisper](https://github.com/openai/whisper#readme)|[![](https://img.shields.io/github/languages/top/abus-aikorea/kara-audio?color=pink&style=flat-square)](https://github.com/abus-aikorea/kara-audio/graphs/contributors)|[![](https://flat.badgen.net/github/license/abus-aikorea/kara-audio?label=)]()|[![](https://img.shields.io/github/last-commit/abus-aikorea/kara-audio?style=flat-square&label=)](https://github.com/abus-aikorea/kara-audio/graphs/code-frequency)|
|[Youtube Auto Dubbing](https://github.com/Mikk0git/youtube-auto-dubbing#readme)|Simple tool for dubbing youtube videos with AI generatied voice (inspired by [Auto Synced & Translated Dubs](https://github.com/ThioJoe/Auto-Synced-Translated-Dubs#readme))|[![](https://img.shields.io/github/languages/top/Mikk0git/youtube-auto-dubbing?color=pink&style=flat-square)](https://github.com/Mikk0git/youtube-auto-dubbing/graphs/contributors)|[![](https://flat.badgen.net/github/license/Mikk0git/youtube-auto-dubbing?label=)](https://github.com/Mikk0git/youtube-auto-dubbing/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/Mikk0git/youtube-auto-dubbing?style=flat-square&label=)](https://github.com/Mikk0git/youtube-auto-dubbing/graphs/code-frequency)|
|[pyvideotrans](https://github.com/jianchang512/pyvideotrans#readme)|Translate the video from one language to another and add dubbing|[![](https://img.shields.io/github/languages/top/jianchang512/pyvideotrans?color=pink&style=flat-square)](https://github.com/jianchang512/pyvideotrans/graphs/contributors)|[![](https://flat.badgen.net/github/license/jianchang512/pyvideotrans?label=)](https://github.com/jianchang512/pyvideotrans/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/jianchang512/pyvideotrans?style=flat-square&label=)](https://github.com/jianchang512/pyvideotrans/graphs/code-frequency)|
|[Srt-AI-Voice-Assistant](https://github.com/YYuX-1145/Srt-AI-Voice-Assistant#readme)|Subtitle dubbing with multiple AI projects|[![](https://img.shields.io/github/languages/top/YYuX-1145/Srt-AI-Voice-Assistant?color=pink&style=flat-square)](https://github.com/YYuX-1145/Srt-AI-Voice-Assistant/graphs/contributors)|[![](https://flat.badgen.net/github/license/YYuX-1145/Srt-AI-Voice-Assistant?label=)](https://github.com/YYuX-1145/Srt-AI-Voice-Assistant/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/YYuX-1145/Srt-AI-Voice-Assistant?style=flat-square&label=)](https://github.com/YYuX-1145/Srt-AI-Voice-Assistant/graphs/code-frequency)|
|[AutoDub](https://github.com/frrobledo/AutoDub#readme)|An advanced AI-powered tool that automatically translates and dubs YouTube videos into different languages while dynamically adjusting video speed|[![](https://img.shields.io/github/languages/top/frrobledo/AutoDub?color=pink&style=flat-square)](https://github.com/frrobledo/AutoDub/graphs/contributors)|[![](https://flat.badgen.net/github/license/frrobledo/AutoDub?label=)](https://github.com/frrobledo/AutoDub/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/frrobledo/AutoDub?style=flat-square&label=)](https://github.com/frrobledo/AutoDub/graphs/code-frequency)|
|[Dubbing AI](https://github.com/mfranzon/dubbing-ai#readme)|Project for dubbing a video in many languages and with many different voices with the power of the AI|[![](https://img.shields.io/github/languages/top/mfranzon/dubbing-ai?color=pink&style=flat-square)](https://github.com/mfranzon/dubbing-ai/graphs/contributors)|[![](https://flat.badgen.net/github/license/mfranzon/dubbing-ai?label=)](https://github.com/mfranzon/dubbing-ai/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/mfranzon/dubbing-ai?style=flat-square&label=)](https://github.com/mfranzon/dubbing-ai/graphs/code-frequency)|
|[Dublaris AI - Video Translator](https://github.com/dublaris/dublaris-video-translator#readme)|An automated tool for multilingual video dubbing and subtitling|[![](https://img.shields.io/github/languages/top/dublaris/dublaris-video-translator?color=pink&style=flat-square)](https://github.com/dublaris/dublaris-video-translator/graphs/contributors)|[![](https://flat.badgen.net/github/license/dublaris/dublaris-video-translator?label=)](https://github.com/dublaris/dublaris-video-translator/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/dublaris/dublaris-video-translator?style=flat-square&label=)](https://github.com/dublaris/dublaris-video-translator/graphs/code-frequency)|
|[Pollyduble](https://github.com/iGerman00/Pollyduble#readme)|Automatic Dubbing with Voice Cloning and Speech Recognition using [OpenVoice](https://github.com/myshell-ai/OpenVoice#readme), [MeloTTS](https://github.com/myshell-ai/MeloTTS#readme), [Faster Whisper](https://github.com/SYSTRAN/faster-whisper#readme), [VoiceFixer](https://github.com/haoheliu/voicefixer#readme), [python-audio-separator](https://github.com/haoheliu/voicefixer#readme) and [FFmpeg](https://ffmpeg.org/)|[![](https://img.shields.io/github/languages/top/iGerman00/Pollyduble?color=pink&style=flat-square)](https://github.com/iGerman00/Pollyduble/graphs/contributors)|[![](https://flat.badgen.net/github/license/iGerman00/Pollyduble?label=)](https://github.com/iGerman00/Pollyduble/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/iGerman00/Pollyduble?style=flat-square&label=)](https://github.com/iGerman00/Pollyduble/graphs/code-frequency)|
|[AI Dubs over Subs](https://github.com/ayushKataria/ai_dub_over_subs#readme)|A set of python scripts that take a video file as input and try to create a new video dubbed by AI|[![](https://img.shields.io/github/languages/top/ayushKataria/ai_dub_over_subs?color=pink&style=flat-square)](https://github.com/ayushKataria/ai_dub_over_subs/graphs/contributors)|[![](https://flat.badgen.net/github/license/ayushKataria/ai_dub_over_subs?label=)](https://github.com/ayushKataria/ai_dub_over_subs/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/ayushKataria/ai_dub_over_subs?style=flat-square&label=)](https://github.com/ayushKataria/ai_dub_over_subs/graphs/code-frequency)|
|[AI Video Dubbing](https://github.com/Aditya1Jhaveri/AI-Video-Dubbing#readme)|Automates translation and dubbing by transcribing audio with Speech-to-Text, translating it with the Translation API, and generating speech with Text-to-Speech using Google APIs|[![](https://img.shields.io/github/languages/top/Aditya1Jhaveri/AI-Video-Dubbing?color=pink&style=flat-square)](https://github.com/Aditya1Jhaveri/AI-Video-Dubbing/graphs/contributors)|[![](https://flat.badgen.net/github/license/Aditya1Jhaveri/AI-Video-Dubbing?label=)](https://github.com/Aditya1Jhaveri/AI-Video-Dubbing/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/Aditya1Jhaveri/AI-Video-Dubbing?style=flat-square&label=)](https://github.com/Aditya1Jhaveri/AI-Video-Dubbing/graphs/code-frequency)|
|[Google AI Dubbing](https://github.com/google/ai_video_dubbing#readme)|Allows you to create localized videos using the same video base and adding translations using Google AI Powered TextToSpeech API|[![](https://img.shields.io/github/languages/top/google/ai_video_dubbing?color=pink&style=flat-square)](https://github.com/google/ai_video_dubbing/graphs/contributors)|[![](https://flat.badgen.net/github/license/google/ai_video_dubbing?label=)](https://github.com/google/ai_video_dubbing/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/google/ai_video_dubbing?style=flat-square&label=)](https://github.com/google/ai_video_dubbing/graphs/code-frequency)|
|[Open dubbing](https://github.com/Softcatala/open-dubbing#readme)|An AI dubbing system which uses machine learning models to automatically translate and synchronize audio dialogue into different languages|[![](https://img.shields.io/github/languages/top/Softcatala/open-dubbing?color=pink&style=flat-square)](https://github.com/Softcatala/open-dubbing/graphs/contributors)|[![](https://flat.badgen.net/github/license/Softcatala/open-dubbing?label=)](https://github.com/Softcatala/open-dubbing/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/Softcatala/open-dubbing?style=flat-square&label=)](https://github.com/Softcatala/open-dubbing/graphs/code-frequency)|
|[YouDub](https://github.com/liuzhao1225/YouDub#readme)|An innovative open source tool that focuses on translating and dubbing premium videos from platforms such as YouTube into Chinese|[![](https://img.shields.io/github/languages/top/liuzhao1225/YouDub?color=pink&style=flat-square)](https://github.com/liuzhao1225/YouDub/graphs/contributors)|[![](https://flat.badgen.net/github/license/liuzhao1225/YouDub?label=)](https://github.com/liuzhao1225/YouDub/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/liuzhao1225/YouDub?style=flat-square&label=)](https://github.com/liuzhao1225/YouDub/graphs/code-frequency)|
|[InstantDubing: AI Video Translator](https://github.com/Mitchaka14/InstantDubing#readme)|It uses cutting-edge AI technology to transcribe, translate, and then re-voice a video into English in the original speaker's voice|[![](https://img.shields.io/github/languages/top/Mitchaka14/InstantDubing?color=pink&style=flat-square)](https://github.com/Mitchaka14/InstantDubing/graphs/contributors)|[![](https://flat.badgen.net/github/license/Mitchaka14/InstantDubing?label=)](https://github.com/Mitchaka14/InstantDubing/issues/2)|[![](https://img.shields.io/github/last-commit/Mitchaka14/InstantDubing?style=flat-square&label=)](https://github.com/Mitchaka14/InstantDubing/graphs/code-frequency)|
|[Multivoice](https://github.com/pnkvalavala/multivoice#readme)|This project uses voice cloning and TTS to deliver natural and engaging dubbed dialogue for a seamless viewing adventure|[![](https://img.shields.io/github/languages/top/pnkvalavala/multivoice?color=pink&style=flat-square)](https://github.com/pnkvalavala/multivoice/graphs/contributors)|[![](https://flat.badgen.net/github/license/pnkvalavala/multivoice?label=)](https://github.com/pnkvalavala/multivoice/issues/3)|[![](https://img.shields.io/github/last-commit/pnkvalavala/multivoice?style=flat-square&label=)](https://github.com/pnkvalavala/multivoice/graphs/code-frequency)|
|[Open-Source AI Video Dubber](https://github.com/EliasLindbergs/ai-video-dubber#readme)|Automatically dub any video into English while keeping the original voice styles|[![](https://img.shields.io/github/languages/top/EliasLindbergs/ai-video-dubber?color=pink&style=flat-square)](https://github.com/EliasLindbergs/ai-video-dubber/graphs/contributors)|[![](https://flat.badgen.net/github/license/EliasLindbergs/ai-video-dubber?label=)](https://github.com/EliasLindbergs/ai-video-dubber/issues/2)|[![](https://img.shields.io/github/last-commit/EliasLindbergs/ai-video-dubber?style=flat-square&label=)](https://github.com/EliasLindbergs/ai-video-dubber/graphs/code-frequency)|
|[Subdub](https://github.com/lukaszliniewicz/Subdub#readme)|A command line Python app offering a video-to-dubbed-video workflow with transcription, translation and synchronisation|[![](https://img.shields.io/github/languages/top/lukaszliniewicz/Subdub?color=pink&style=flat-square)](https://github.com/lukaszliniewicz/Subdub/graphs/contributors)|[![](https://flat.badgen.net/github/license/lukaszliniewicz/Subdub?label=)](https://github.com/lukaszliniewicz/Subdub/issues/1)|[![](https://img.shields.io/github/last-commit/lukaszliniewicz/Subdub?style=flat-square&label=)](https://github.com/lukaszliniewicz/Subdub/graphs/code-frequency)|
|[WeeaBlind](https://github.com/FlorianEagox/WeeaBlind#readme)|A program to dub non-english media with modern AI speech synthesis, diarization, and voice cloning|[![](https://img.shields.io/github/languages/top/FlorianEagox/WeeaBlind?color=pink&style=flat-square)](https://github.com/FlorianEagox/WeeaBlind/graphs/contributors)|[![](https://flat.badgen.net/github/license/FlorianEagox/WeeaBlind?label=)](https://github.com/FlorianEagox/WeeaBlind/issues/32)|[![](https://img.shields.io/github/last-commit/FlorianEagox/WeeaBlind?style=flat-square&label=)](https://github.com/FlorianEagox/WeeaBlind/graphs/code-frequency)|
|[YouTube Auto-Dub](https://github.com/mazzasaverio/youtube-auto-dub#readme)|Automated voice dubbing (for YouTube videos) that translates and dubs videos with original voice timbre|[![](https://img.shields.io/github/languages/top/mazzasaverio/youtube-auto-dub?color=pink&style=flat-square)](https://github.com/mazzasaverio/youtube-auto-dub/graphs/contributors)|[![](https://flat.badgen.net/github/license/mazzasaverio/youtube-auto-dub?label=)](https://github.com/mazzasaverio/youtube-auto-dub/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/mazzasaverio/youtube-auto-dub?style=flat-square&label=)](https://github.com/mazzasaverio/youtube-auto-dub/graphs/code-frequency)|
|[Dubbing Engine with Bun and Typescript](https://github.com/kevinrss01/dubbing-engine#readme)|Typescript tool to translate any video with AI, performing voice cloning, subtitles and LipSync|[![](https://img.shields.io/github/languages/top/kevinrss01/dubbing-engine?color=pink&style=flat-square)](https://github.com/kevinrss01/dubbing-engine/graphs/contributors)|[![](https://img.shields.io/badge/CC%20BY--NC-blue?style=flat-square)](https://github.com/kevinrss01/dubbing-engine/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/kevinrss01/dubbing-engine?style=flat-square&label=)](https://github.com/kevinrss01/dubbing-engine/graphs/code-frequency)|
|[AI Voice Translator](https://github.com/DigitalEpidemic/ai-voice-translator#readme)|A tool that translates audio into another language with the ability to use your own voice|[![](https://img.shields.io/github/languages/top/DigitalEpidemic/ai-voice-translator?color=pink&style=flat-square)](https://github.com/DigitalEpidemic/ai-voice-translator/graphs/contributors)|[![](https://flat.badgen.net/github/license/DigitalEpidemic/ai-voice-translator?label=)](https://github.com/DigitalEpidemic/ai-voice-translator/issues/2)|[![](https://img.shields.io/github/last-commit/DigitalEpidemic/ai-voice-translator?style=flat-square&label=)](https://github.com/DigitalEpidemic/ai-voice-translator/graphs/code-frequency)|





### Enhancers [⌂](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Speech Enhancement / Noise Reduction](https://github.com/Priyal-0911/Speech-Enhancement-Noise-Reduction#readme)|Demonstrates the process of enhancing and separating mixed audio sources, such as isolating speech from background noise, using a pre-trained model|[![](https://img.shields.io/github/languages/top/Priyal-0911/Speech-Enhancement-Noise-Reduction?color=pink&style=flat-square)](https://github.com/Priyal-0911/Speech-Enhancement-Noise-Reduction/graphs/contributors)|[![](https://flat.badgen.net/github/license/Priyal-0911/Speech-Enhancement-Noise-Reduction?label=)](https://github.com/Priyal-0911/Speech-Enhancement-Noise-Reduction/issues/1)|[![](https://img.shields.io/github/last-commit/Priyal-0911/Speech-Enhancement-Noise-Reduction?style=flat-square&label=)](https://github.com/Priyal-0911/Speech-Enhancement-Noise-Reduction/graphs/code-frequency)|
|[AURAL_GAN+predictive_model](https://github.com/Gabeiscool420/AURAL_GAN-predictive_model#readme)|Aims to transform low-quality phone recordings into professional-quality audio using a Generative Adversarial Network (GAN)|[![](https://img.shields.io/github/languages/top/Gabeiscool420/AURAL_GAN-predictive_model?color=pink&style=flat-square)](https://github.com/Gabeiscool420/AURAL_GAN-predictive_model/graphs/contributors)|[![](https://flat.badgen.net/github/license/Gabeiscool420/AURAL_GAN-predictive_model?label=)](https://github.com/Gabeiscool420/AURAL_GAN-predictive_model/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/Gabeiscool420/AURAL_GAN-predictive_model?style=flat-square&label=)](https://github.com/Gabeiscool420/AURAL_GAN-predictive_model/graphs/code-frequency)|
|[Resemble Enhance](https://github.com/resemble-ai/resemble-enhance#readme)|An AI-powered tool that aims to improve the overall quality of speech by performing denoising and enhancement|[![](https://img.shields.io/github/languages/top/resemble-ai/resemble-enhance?color=pink&style=flat-square)](https://github.com/resemble-ai/resemble-enhance/graphs/contributors)|[![](https://flat.badgen.net/github/license/resemble-ai/resemble-enhance?label=)](https://github.com/resemble-ai/resemble-enhance/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/resemble-ai/resemble-enhance?style=flat-square&label=)](https://github.com/resemble-ai/resemble-enhance/graphs/code-frequency)|
|[ClearerVoice-Studio](https://github.com/modelscope/ClearerVoice-Studio#readme)|An AI-Powered Speech Processing Toolkit and Open Source SOTA Pretrained Models, Supporting Speech Enhancement, Separation, and Target Speaker Extraction|[![](https://img.shields.io/github/languages/top/modelscope/ClearerVoice-Studio?color=pink&style=flat-square)](https://github.com/modelscope/ClearerVoice-Studio/graphs/contributors)|[![](https://flat.badgen.net/github/license/modelscope/ClearerVoice-Studio?label=)](https://github.com/modelscope/ClearerVoice-Studio/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/modelscope/ClearerVoice-Studio?style=flat-square&label=)](https://github.com/modelscope/ClearerVoice-Studio/graphs/code-frequency)|
|[Deep Learning Based Noise Reduction and Speech Enhancement System](https://github.com/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction#readme)|Implements two deep learning models, one can classify the type of noise, the other can retain human voice and reduce environmental noise|[![](https://img.shields.io/github/languages/top/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction?color=pink&style=flat-square)](https://github.com/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction/graphs/contributors)|[![](https://flat.badgen.net/github/license/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction?label=)](https://github.com/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction?style=flat-square&label=)](https://github.com/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction/graphs/code-frequency)|
|[DeepFilterNet](https://github.com/Rikorose/DeepFilterNet#readme)|A Low Complexity Speech Enhancement Framework for Full-Band Audio (48kHz) using on Deep Filtering|[![](https://img.shields.io/github/languages/top/Rikorose/DeepFilterNet?color=pink&style=flat-square)](https://github.com/Rikorose/DeepFilterNet/graphs/contributors)|[![](https://flat.badgen.net/badge/license/Other/blue?label=)](https://github.com/Rikorose/DeepFilterNet/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/Rikorose/DeepFilterNet?style=flat-square&label=)](https://github.com/Rikorose/DeepFilterNet/graphs/code-frequency)|
|[Audio Enhancement and Denoising using Autoencoders](https://github.com/quadeer15sh/AudioEnhancementAndDenoisingUsingAutoencoders#readme)|-|[![](https://img.shields.io/github/languages/top/quadeer15sh/AudioEnhancementAndDenoisingUsingAutoencoders?color=pink&style=flat-square)](https://github.com/quadeer15sh/AudioEnhancementAndDenoisingUsingAutoencoders/graphs/contributors)|[![](https://flat.badgen.net/github/license/quadeer15sh/AudioEnhancementAndDenoisingUsingAutoencoders?label=)](https://github.com/quadeer15sh/AudioEnhancementAndDenoisingUsingAutoencoders/issues/1)|[![](https://img.shields.io/github/last-commit/quadeer15sh/AudioEnhancementAndDenoisingUsingAutoencoders?style=flat-square&label=)](https://github.com/quadeer15sh/AudioEnhancementAndDenoisingUsingAutoencoders/graphs/code-frequency)|



### Stylers [⌂](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[AutoPST](https://github.com/auspicious3000/AutoPST#readme)|Global Rhythm Style Transfer Without Text Transcriptions|[![](https://img.shields.io/github/languages/top/auspicious3000/AutoPST?color=pink&style=flat-square)](https://github.com/auspicious3000/AutoPST/graphs/contributors)|[![](https://flat.badgen.net/github/license/auspicious3000/AutoPST?label=)](https://github.com/auspicious3000/AutoPST/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/auspicious3000/AutoPST?style=flat-square&label=)](https://github.com/auspicious3000/AutoPST/graphs/code-frequency)|
|[AutoVC](https://github.com/auspicious3000/autovc#readme)|Zero-Shot Voice Style Transfer with Only Autoencoder Loss|[![](https://img.shields.io/github/languages/top/auspicious3000/autovc?color=pink&style=flat-square)](https://github.com/auspicious3000/autovc/graphs/contributors)|[![](https://flat.badgen.net/github/license/auspicious3000/autovc?label=)](https://github.com/auspicious3000/autovc/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/auspicious3000/autovc?style=flat-square&label=)](https://github.com/auspicious3000/autovc/graphs/code-frequency)|
|[Voice Conversion with Non-Parallel Data](https://github.com/andabi/deep-voice-conversion#readme)|Deep neural networks for voice conversion (voice style transfer) in Tensorflow|[![](https://img.shields.io/github/languages/top/andabi/deep-voice-conversion?color=pink&style=flat-square)](https://github.com/andabi/deep-voice-conversion/graphs/contributors)|[![](https://flat.badgen.net/github/license/andabi/deep-voice-conversion?label=)](https://github.com/andabi/deep-voice-conversion/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/andabi/deep-voice-conversion?style=flat-square&label=)](https://github.com/andabi/deep-voice-conversion/graphs/code-frequency)|
|[StyleSinger](https://github.com/AaronZ345/StyleSinger#readme)|Code for [Style Transfer for Out-of-Domain Singing Voice Synthesis](https://ojs.aaai.org/index.php/AAAI/article/view/29932) paper|[![](https://img.shields.io/github/languages/top/AaronZ345/StyleSinger?color=pink&style=flat-square)](https://github.com/AaronZ345/StyleSinger/graphs/contributors)|[![](https://flat.badgen.net/github/license/AaronZ345/StyleSinger?label=)](https://github.com/AaronZ345/StyleSinger/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/AaronZ345/StyleSinger?style=flat-square&label=)](https://github.com/AaronZ345/StyleSinger/graphs/code-frequency)|
|[Voice style transfer with random CNN](https://github.com/mazzzystar/randomCNN-voice-transfer#readme)|Audio style transfer with shallow random parameters CNN|[![](https://img.shields.io/github/languages/top/mazzzystar/randomCNN-voice-transfer?color=pink&style=flat-square)](https://github.com/mazzzystar/randomCNN-voice-transfer/graphs/contributors)|[![](https://flat.badgen.net/github/license/mazzzystar/randomCNN-voice-transfer?label=)](https://github.com/mazzzystar/randomCNN-voice-transfer/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/mazzzystar/randomCNN-voice-transfer?style=flat-square&label=)](https://github.com/mazzzystar/randomCNN-voice-transfer/graphs/code-frequency)|
|[Robust-Voice-Style-Transfer](https://github.com/jlian2/Robust-Voice-Style-Transfer#readme)|Code for [Robust Disentangled Variational Speech Representation Learning for Zero-Shot Voice Conversion](https://arxiv.org/abs/2203.16705) paper|[![](https://img.shields.io/github/languages/top/jlian2/Robust-Voice-Style-Transfer?color=pink&style=flat-square)](https://github.com/jlian2/Robust-Voice-Style-Transfer/graphs/contributors)|[![](https://flat.badgen.net/github/license/jlian2/Robust-Voice-Style-Transfer?label=)](https://github.com/jlian2/Robust-Voice-Style-Transfer/issues/4)|[![](https://img.shields.io/github/last-commit/jlian2/Robust-Voice-Style-Transfer?style=flat-square&label=)](https://github.com/jlian2/Robust-Voice-Style-Transfer/graphs/code-frequency)|



### Speech [⌂](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[ASRT](https://github.com/nl8590687/ASRT_SpeechRecognition#readme)|A Deep-Learning-Based Chinese Speech Recognition System|[![](https://img.shields.io/github/languages/top/nl8590687/ASRT_SpeechRecognition?color=pink&style=flat-square)](https://github.com/nl8590687/ASRT_SpeechRecognition/graphs/contributors)|[![](https://flat.badgen.net/github/license/nl8590687/ASRT_SpeechRecognition?label=)](https://github.com/nl8590687/ASRT_SpeechRecognition/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/nl8590687/ASRT_SpeechRecognition?style=flat-square&label=)](https://github.com/nl8590687/ASRT_SpeechRecognition/graphs/code-frequency)|
|[whisper.cpp](https://github.com/ggerganov/whisper.cpp#readme)|High-performance inference of [OpenAI's Whisper](https://github.com/openai/whisper) automatic speech recognition (ASR) model|[![](https://img.shields.io/github/languages/top/ggerganov/whisper.cpp?color=pink&style=flat-square)](https://github.com/ggerganov/whisper.cpp/graphs/contributors)|[![](https://flat.badgen.net/github/license/ggerganov/whisper.cpp?label=)](https://github.com/ggerganov/whisper.cpp/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/ggerganov/whisper.cpp?style=flat-square&label=)](https://github.com/ggerganov/whisper.cpp/graphs/code-frequency)|



### TTSers [⌂](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[OpenTTS](https://github.com/ningjx/OpenTTS#readme)|Use Microsoft speech synthesis to generate your own voice package|[![](https://img.shields.io/github/languages/top/ningjx/OpenTTS?color=pink&style=flat-square)](https://github.com/ningjx/OpenTTS/graphs/contributors)|[![](https://flat.badgen.net/github/license/ningjx/OpenTTS?label=)](https://github.com/ningjx/OpenTTS/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/ningjx/OpenTTS?style=flat-square&label=)](https://github.com/ningjx/OpenTTS/graphs/code-frequency)|
|[TorToiSe](https://github.com/neonbjb/tortoise-tts#readme)|A multi-voice TTS system trained with an emphasis on quality|[![](https://img.shields.io/github/languages/top/neonbjb/tortoise-tts?color=pink&style=flat-square)](https://github.com/neonbjb/tortoise-tts/graphs/contributors)|[![](https://flat.badgen.net/github/license/neonbjb/tortoise-tts?label=)](https://github.com/neonbjb/tortoise-tts/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/neonbjb/tortoise-tts?style=flat-square&label=)](https://github.com/neonbjb/tortoise-tts/graphs/code-frequency)|
|[coquiTTS](https://github.com/coqui-ai/TTS#readme)|A deep learning toolkit for Text-to-Speech, battle-tested in research and production|[![](https://img.shields.io/github/languages/top/coqui-ai/TTS?color=pink&style=flat-square)](https://github.com/coqui-ai/TTS/graphs/contributors)|[![](https://flat.badgen.net/github/license/coqui-ai/TTS?label=)](https://github.com/coqui-ai/TTS/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/coqui-ai/TTS?style=flat-square&label=)](https://github.com/coqui-ai/TTS/graphs/code-frequency)|
|[Fish Speech](https://github.com/fishaudio/fish-speech#readme)|SOTA Open Source TTS|[![](https://img.shields.io/github/languages/top/fishaudio/fish-speech?color=pink&style=flat-square)](https://github.com/fishaudio/fish-speech/graphs/contributors)|[![](https://flat.badgen.net/github/license/fishaudio/fish-speech?label=)](https://github.com/fishaudio/fish-speech/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/fishaudio/fish-speech?style=flat-square&label=)](https://github.com/fishaudio/fish-speech/graphs/code-frequency)|
