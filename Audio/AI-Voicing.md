# [![AUDIO](https://flat.badgen.net/badge/HyMPS/AUDIO/green?scale=1.8)](https://github.com/FORARTfe/HyMPS#- "AUDIO section") [![Effects](https://flat.badgen.net/badge/HyMPS/AI-based/blue?scale=1.8&label=)](https://github.com/FORARTfe/HyMPS/blob/main/Audio/AI-based.md#-- "AI-based category") [![Voicing](https://flat.badgen.net/badge/HyMPS/Voicing/red?scale=1.8&label=)](https://github.com/FORARTfe/HyMPS/blob/main/Audio/AI-Voicing.md#--- "Voicing page") <a href="https://visitorbadge.io/status?path=https%3A%2F%2Fgithub.com%2FFORARTfe%2FHyMPS%2Fblob%2Fmain%2FAudio%2FAI-Voicing.md"><img align="right" src="https://api.visitorbadge.io/api/combined?path=https%3A%2F%2Fgithub.com%2FFORARTfe%2FHyMPS%2Fblob%2Fmain%2FAudio%2FAI-Voicing.md&label=D%20%2F%20T&labelColor=%23323232&countColor=%23c2ff00&style=flat-square&labelStyle=none" /></a>


### 📁 [Cloners](#cloners-) - [Denoisers](#denoisers-) - [Dubbers](#dubbers-) - [Enhancers](#enhancers-) - [Stylers](#stylers-) - [Speech](#speech-) - [TTSers](#ttsers-)

> [!WARNING]
> $\color{orange}\textsf{{SORTING: Language (a>z) > License (openness) > Repository (a>z)}}$

### Cloners [⌂](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Applio](https://github.com/IAHispano/Applio#readme)|VITS-based Voice Conversion focused on simplicity, quality and performance|[![](https://img.shields.io/github/languages/top/IAHispano/Applio?color=pink&style=flat-square)](https://github.com/IAHispano/Applio/graphs/contributors)|[![](https://flat.badgen.net/github/license/IAHispano/Applio?label=)](https://github.com/IAHispano/Applio/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/IAHispano/Applio?style=flat-square&label=)](https://github.com/IAHispano/Applio/graphs/code-frequency)|
|[OpenVoice](https://github.com/myshell-ai/OpenVoice#readme)|Versatile Instant Voice Cloning ([paper](https://arxiv.org/abs/2312.01479))|[![](https://img.shields.io/github/languages/top/myshell-ai/OpenVoice?color=pink&style=flat-square)](https://github.com/myshell-ai/OpenVoice/graphs/contributors)|[![](https://flat.badgen.net/github/license/myshell-ai/OpenVoice?label=)](https://github.com/myshell-ai/OpenVoice/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/myshell-ai/OpenVoice?style=flat-square&label=)](https://github.com/myshell-ai/OpenVoice/graphs/code-frequency)|
|[Real-Time-Voice-Cloning](https://github.com/CorentinJ/Real-Time-Voice-Cloning#readme)|Clone a voice in 5 seconds to generate arbitrary speech in real-time|[![](https://img.shields.io/github/languages/top/CorentinJ/Real-Time-Voice-Cloning?color=pink&style=flat-square)](https://github.com/CorentinJ/Real-Time-Voice-Cloning/graphs/contributors)|[![](https://flat.badgen.net/github/license/CorentinJ/Real-Time-Voice-Cloning?label=)](https://github.com/CorentinJ/Real-Time-Voice-Cloning/issues/1291)|[![](https://img.shields.io/github/last-commit/CorentinJ/Real-Time-Voice-Cloning?style=flat-square&label=)](https://github.com/CorentinJ/Real-Time-Voice-Cloning/graphs/code-frequency)|

### Denoisers [⌂](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Noise2Noise-denoising](https://github.com/madhavmk/Noise2Noise-audio_denoising_without_clean_training_data#readme)|Source code for the "[Speech Denoising without Clean Training Data: a Noise2Noise Approach](https://arxiv.org/abs/2104.03838)" paper|[![](https://img.shields.io/github/languages/top/madhavmk/Noise2Noise-audio_denoising_without_clean_training_data?color=pink&style=flat-square)](https://github.com/madhavmk/Noise2Noise-audio_denoising_without_clean_training_data/graphs/contributors)|[![](https://flat.badgen.net/github/license/madhavmk/Noise2Noise-audio_denoising_without_clean_training_data?label=)](https://github.com/madhavmk/Noise2Noise-audio_denoising_without_clean_training_data/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/madhavmk/Noise2Noise-audio_denoising_without_clean_training_data?style=flat-square&label=)](https://github.com/madhavmk/Noise2Noise-audio_denoising_without_clean_training_data/graphs/code-frequency)|
|[DNP](https://github.com/mosheman5/DNP#readme)|A PyTorch implementation of "[Speech Denoising by Accumulating Per-Frequency Modeling Fluctuations](https://arxiv.org/abs/1904.07612)" paper|[![](https://img.shields.io/github/languages/top/mosheman5/DNP?color=pink&style=flat-square)](https://github.com/mosheman5/DNP/graphs/contributors)|[![](https://flat.badgen.net/github/license/mosheman5/DNP?label=)](https://github.com/mosheman5/DNP/issues/12)|[![](https://img.shields.io/github/last-commit/mosheman5/DNP?style=flat-square&label=)](https://github.com/mosheman5/DNP/graphs/code-frequency)|
|[SAB-cnn-audio-denoiser](https://github.com/EncoraDigital/SAB-cnn-audio-denoiser#readme)|Tensorflow 2.0 implementation of the paper [A Fully Convolutional Neural Network for Speech Enhancement](https://arxiv.org/abs/1609.07132)|[![](https://img.shields.io/github/languages/top/EncoraDigital/SAB-cnn-audio-denoiser?color=pink&style=flat-square)](https://github.com/EncoraDigital/SAB-cnn-audio-denoiser/graphs/contributors)|[![](https://flat.badgen.net/github/license/EncoraDigital/SAB-cnn-audio-denoiser?label=)](https://github.com/EncoraDigital/SAB-cnn-audio-denoiser/issues/17)|[![](https://img.shields.io/github/last-commit/EncoraDigital/SAB-cnn-audio-denoiser?style=flat-square&label=)](https://github.com/EncoraDigital/SAB-cnn-audio-denoiser/graphs/code-frequency)|
|[Clean Sound with AI](https://github.com/BoTtoGo/FixLowFreqSound#readme)|Aims to clean sound recordings from noisy environments using a Convolutional Neural Network (CNN) based on the [CleanUNet](https://arxiv.org/abs/2202.07790) model|[![](https://img.shields.io/github/languages/top/BoTtoGo/FixLowFreqSound?color=pink&style=flat-square)](https://github.com/BoTtoGo/FixLowFreqSound/graphs/contributors)|[![](https://flat.badgen.net/github/license/BoTtoGo/FixLowFreqSound?label=)](https://github.com/BoTtoGo/FixLowFreqSound/issues/1)|[![](https://img.shields.io/github/last-commit/BoTtoGo/FixLowFreqSound?style=flat-square&label=)](https://github.com/BoTtoGo/FixLowFreqSound/graphs/code-frequency)|
|[Speech-enhancement](https://github.com/vbelz/Speech-enhancement#readme)|Deep learning for audio denoising|[![](https://img.shields.io/github/languages/top/vbelz/Speech-enhancement?color=pink&style=flat-square)](https://github.com/vbelz/Speech-enhancement/graphs/contributors)|[![](https://flat.badgen.net/github/license/vbelz/Speech-enhancement?label=)](https://github.com/vbelz/Speech-enhancement/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/vbelz/Speech-enhancement?style=flat-square&label=)](https://github.com/vbelz/Speech-enhancement/graphs/code-frequency)|
|[Resemble Enhance](https://github.com/resemble-ai/resemble-enhance#readme)|AI powered speech denoising and enhancement|[![](https://img.shields.io/github/languages/top/resemble-ai/resemble-enhance?color=pink&style=flat-square)](https://github.com/resemble-ai/resemble-enhance/graphs/contributors)|[![](https://flat.badgen.net/github/license/resemble-ai/resemble-enhance?label=)](https://github.com/resemble-ai/resemble-enhance/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/resemble-ai/resemble-enhance?style=flat-square&label=)](https://github.com/resemble-ai/resemble-enhance/graphs/code-frequency)|
|[DeepFilterNet](https://github.com/Rikorose/DeepFilterNet#readme)|Noise supression using deep filtering|[![](https://img.shields.io/github/languages/top/Rikorose/DeepFilterNet?color=pink&style=flat-square)](https://github.com/Rikorose/DeepFilterNet/graphs/contributors)|[![](https://flat.badgen.net/badge/license/Other/blue?label=)](https://github.com/Rikorose/DeepFilterNet/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/Rikorose/DeepFilterNet?style=flat-square&label=)](https://github.com/Rikorose/DeepFilterNet/graphs/code-frequency)|
|[speech-denoiser](https://github.com/MateuszKrol13/speech-denoiser#readme)|denoiser|[![](https://img.shields.io/github/languages/top/MateuszKrol13/speech-denoiser?color=pink&style=flat-square)](https://github.com/MateuszKrol13/speech-denoiser/graphs/contributors)|[![](https://flat.badgen.net/github/license/MateuszKrol13/speech-denoiser?label=)](https://github.com/MateuszKrol13/speech-denoiser/issues/1)|[![](https://img.shields.io/github/last-commit/MateuszKrol13/speech-denoiser?style=flat-square&label=)](https://github.com/MateuszKrol13/speech-denoiser/graphs/code-frequency)|




### Dubbers [⌂](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Kara-Audio](https://github.com/abus-aikorea/kara-audio#readme)|Gradio web-ui for vocal remover that uses [demucs](https://github.com/facebookresearch/demucs#readme) and [mdx-net](https://github.com/kuielab/mdx-net) + automatic subtitle creation using faster [whisper](https://github.com/openai/whisper)|[![](https://img.shields.io/github/languages/top/abus-aikorea/kara-audio?color=pink&style=flat-square)](https://github.com/abus-aikorea/kara-audio/graphs/contributors)|[![](https://flat.badgen.net/github/license/abus-aikorea/kara-audio?label=)]()|[![](https://img.shields.io/github/last-commit/abus-aikorea/kara-audio?style=flat-square&label=)](https://github.com/abus-aikorea/kara-audio/graphs/code-frequency)|
|[VoiceCraftAI](https://github.com/HallowSiddharth/VoiceCraftAI#readme)|A revolutionary AI tool to dub videos into multiple regional languages and lip-sync at the same time|[![](https://img.shields.io/github/languages/top/HallowSiddharth/VoiceCraftAI?color=pink&style=flat-square)](https://github.com/HallowSiddharth/VoiceCraftAI/graphs/contributors)|[![](https://flat.badgen.net/github/license/HallowSiddharth/VoiceCraftAI?label=)](https://github.com/HallowSiddharth/VoiceCraftAI/issues/19)|[![](https://img.shields.io/github/last-commit/HallowSiddharth/VoiceCraftAI?style=flat-square&label=)](https://github.com/HallowSiddharth/VoiceCraftAI/graphs/code-frequency)|
|[Linly-Dubbing](https://github.com/Kedreamix/Linly-Dubbing#readme)|An intelligent multi-language AI dubbing and translation tool that offers diverse and high-quality dubbing options by integrating [Linly-Talker](https://github.com/Kedreamix/Linly-Talker#readme)’s digital human lip-sync technology, creating a more natural multi-language video experience|[![](https://img.shields.io/github/languages/top/Kedreamix/Linly-Dubbing?color=pink&style=flat-square)](https://github.com/Kedreamix/Linly-Dubbing/graphs/contributors)|[![](https://flat.badgen.net/github/license/Kedreamix/Linly-Dubbing?label=)](https://github.com/Kedreamix/Linly-Dubbing/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/Kedreamix/Linly-Dubbing?style=flat-square&label=)](https://github.com/Kedreamix/Linly-Dubbing/graphs/code-frequency)
|[voice_ukr_to_eng](https://github.com/Nik-Kras/voice_ukr_to_eng#readme)|Tool to generate English AI Dubbing for a YouTube video|[![](https://img.shields.io/github/languages/top/Nik-Kras/voice_ukr_to_eng?color=pink&style=flat-square)](https://github.com/Nik-Kras/voice_ukr_to_eng/graphs/contributors)|[![](https://flat.badgen.net/github/license/Nik-Kras/voice_ukr_to_eng?label=)](https://github.com/Nik-Kras/voice_ukr_to_eng/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/Nik-Kras/voice_ukr_to_eng?style=flat-square&label=)](https://github.com/Nik-Kras/voice_ukr_to_eng/graphs/code-frequency)|
|[Emotionally-Intelligent-AI-based-movie-dubbing](https://github.com/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing#readme)|AI to seamlessly translate and dub content into any language while preserving the original speaker's emotions, characteristics, and authenticity|[![](https://img.shields.io/github/languages/top/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing?color=pink&style=flat-square)](https://github.com/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing/graphs/contributors)|[![](https://flat.badgen.net/github/license/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing?label=)](https://github.com/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing/issues/1)|[![](https://img.shields.io/github/last-commit/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing?style=flat-square&label=)](https://github.com/sharmakamal1201/Emotionally-Intelligent-AI-based-movie-dubbing/graphs/code-frequency)|
|[pyvideotrans](https://github.com/jianchang512/pyvideotrans#readme)|Translate the video from one language to another and add dubbing|[![](https://img.shields.io/github/languages/top/jianchang512/pyvideotrans?color=pink&style=flat-square)](https://github.com/jianchang512/pyvideotrans/graphs/contributors)|[![](https://flat.badgen.net/github/license/jianchang512/pyvideotrans?label=)](https://github.com/jianchang512/pyvideotrans/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/jianchang512/pyvideotrans?style=flat-square&label=)](https://github.com/jianchang512/pyvideotrans/graphs/code-frequency)|
|[AutoDub](https://github.com/frrobledo/AutoDub#readme)|An advanced AI-powered tool that automatically translates and dubs YouTube videos into different languages while dynamically adjusting video speed|[![](https://img.shields.io/github/languages/top/frrobledo/AutoDub?color=pink&style=flat-square)](https://github.com/frrobledo/AutoDub/graphs/contributors)|[![](https://flat.badgen.net/github/license/frrobledo/AutoDub?label=)](https://github.com/frrobledo/AutoDub/issues/2)|[![](https://img.shields.io/github/last-commit/frrobledo/AutoDub?style=flat-square&label=)](https://github.com/frrobledo/AutoDub/graphs/code-frequency)|
|[AI Dubs over Subs](https://github.com/ayushKataria/ai_dub_over_subs#readme)|A set of python scripts that take a video file as input and try to create a new video dubbed by AI|[![](https://img.shields.io/github/languages/top/ayushKataria/ai_dub_over_subs?color=pink&style=flat-square)](https://github.com/ayushKataria/ai_dub_over_subs/graphs/contributors)|[![](https://flat.badgen.net/github/license/ayushKataria/ai_dub_over_subs?label=)](https://github.com/ayushKataria/ai_dub_over_subs/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/ayushKataria/ai_dub_over_subs?style=flat-square&label=)](https://github.com/ayushKataria/ai_dub_over_subs/graphs/code-frequency)|
|[AI Video Dubbing](https://github.com/Aditya1Jhaveri/AI-Video-Dubbing#readme)|Automates translation and dubbing by transcribing audio with Speech-to-Text, translating it with the Translation API, and generating speech with Text-to-Speech using Google APIs|[![](https://img.shields.io/github/languages/top/Aditya1Jhaveri/AI-Video-Dubbing?color=pink&style=flat-square)](https://github.com/Aditya1Jhaveri/AI-Video-Dubbing/graphs/contributors)|[![](https://flat.badgen.net/github/license/Aditya1Jhaveri/AI-Video-Dubbing?label=)](https://github.com/Aditya1Jhaveri/AI-Video-Dubbing/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/Aditya1Jhaveri/AI-Video-Dubbing?style=flat-square&label=)](https://github.com/Aditya1Jhaveri/AI-Video-Dubbing/graphs/code-frequency)|
|[Google AI Dubbing](https://github.com/google/ai_video_dubbing#readme)|Allows you to create localized videos using the same video base and adding translations using Google AI Powered TextToSpeech API|[![](https://img.shields.io/github/languages/top/google/ai_video_dubbing?color=pink&style=flat-square)](https://github.com/google/ai_video_dubbing/graphs/contributors)|[![](https://flat.badgen.net/github/license/google/ai_video_dubbing?label=)](https://github.com/google/ai_video_dubbing/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/google/ai_video_dubbing?style=flat-square&label=)](https://github.com/google/ai_video_dubbing/graphs/code-frequency)|
|[Open dubbing](https://github.com/Softcatala/open-dubbing#readme)|An AI dubbing system which uses machine learning models to automatically translate and synchronize audio dialogue into different languages|[![](https://img.shields.io/github/languages/top/Softcatala/open-dubbing?color=pink&style=flat-square)](https://github.com/Softcatala/open-dubbing/graphs/contributors)|[![](https://flat.badgen.net/github/license/Softcatala/open-dubbing?label=)](https://github.com/Softcatala/open-dubbing/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/Softcatala/open-dubbing?style=flat-square&label=)](https://github.com/Softcatala/open-dubbing/graphs/code-frequency)|
|[YouDub](https://github.com/liuzhao1225/YouDub#readme)|An innovative open source tool that focuses on translating and dubbing premium videos from platforms such as YouTube into Chinese|[![](https://img.shields.io/github/languages/top/liuzhao1225/YouDub?color=pink&style=flat-square)](https://github.com/liuzhao1225/YouDub/graphs/contributors)|[![](https://flat.badgen.net/github/license/liuzhao1225/YouDub?label=)](https://github.com/liuzhao1225/YouDub/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/liuzhao1225/YouDub?style=flat-square&label=)](https://github.com/liuzhao1225/YouDub/graphs/code-frequency)|
|[Open-Source AI Video Dubber](https://github.com/EliasLindbergs/ai-video-dubber#readme)|Automatically dub any video into English while keeping the original voice styles|[![](https://img.shields.io/github/languages/top/EliasLindbergs/ai-video-dubber?color=pink&style=flat-square)](https://github.com/EliasLindbergs/ai-video-dubber/graphs/contributors)|[![](https://flat.badgen.net/github/license/EliasLindbergs/ai-video-dubber?label=)](https://github.com/EliasLindbergs/ai-video-dubber/issues/2)|[![](https://img.shields.io/github/last-commit/EliasLindbergs/ai-video-dubber?style=flat-square&label=)](https://github.com/EliasLindbergs/ai-video-dubber/graphs/code-frequency)|
|[Subdub](https://github.com/lukaszliniewicz/Subdub#readme)|A command line Python app offering a video-to-dubbed-video workflow with transcription, translation and synchronisation|[![](https://img.shields.io/github/languages/top/lukaszliniewicz/Subdub?color=pink&style=flat-square)](https://github.com/lukaszliniewicz/Subdub/graphs/contributors)|[![](https://flat.badgen.net/github/license/lukaszliniewicz/Subdub?label=)](https://github.com/lukaszliniewicz/Subdub/issues/1)|[![](https://img.shields.io/github/last-commit/lukaszliniewicz/Subdub?style=flat-square&label=)](https://github.com/lukaszliniewicz/Subdub/graphs/code-frequency)|
|[WeeaBlind](https://github.com/FlorianEagox/WeeaBlind#readme)|A program to dub non-english media with modern AI speech synthesis, diarization, and voice cloning|[![](https://img.shields.io/github/languages/top/FlorianEagox/WeeaBlind?color=pink&style=flat-square)](https://github.com/FlorianEagox/WeeaBlind/graphs/contributors)|[![](https://flat.badgen.net/github/license/FlorianEagox/WeeaBlind?label=)](https://github.com/FlorianEagox/WeeaBlind/issues/32)|[![](https://img.shields.io/github/last-commit/FlorianEagox/WeeaBlind?style=flat-square&label=)](https://github.com/FlorianEagox/WeeaBlind/graphs/code-frequency)|
|[speech-translator](https://github.com/DigitalEpidemic/ai-voice-translator#readme)|A tool that translates audio into another language with the ability to use your own voice|[![](https://img.shields.io/github/languages/top/DigitalEpidemic/ai-voice-translator?color=pink&style=flat-square)](https://github.com/DigitalEpidemic/ai-voice-translator/graphs/contributors)|[![](https://flat.badgen.net/github/license/DigitalEpidemic/ai-voice-translator?label=)](https://github.com/DigitalEpidemic/ai-voice-translator/issues/2)|[![](https://img.shields.io/github/last-commit/DigitalEpidemic/ai-voice-translator?style=flat-square&label=)](https://github.com/DigitalEpidemic/ai-voice-translator/graphs/code-frequency)|

### Enhancers [⌂](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[Speech Enhancement / Noise Reduction](https://github.com/Priyal-0911/Speech-Enhancement-Noise-Reduction#readme)|Demonstrates the process of enhancing and separating mixed audio sources, such as isolating speech from background noise, using a pre-trained model|[![](https://img.shields.io/github/languages/top/Priyal-0911/Speech-Enhancement-Noise-Reduction?color=pink&style=flat-square)](https://github.com/Priyal-0911/Speech-Enhancement-Noise-Reduction/graphs/contributors)|[![](https://flat.badgen.net/github/license/Priyal-0911/Speech-Enhancement-Noise-Reduction?label=)](https://github.com/Priyal-0911/Speech-Enhancement-Noise-Reduction/issues/1)|[![](https://img.shields.io/github/last-commit/Priyal-0911/Speech-Enhancement-Noise-Reduction?style=flat-square&label=)](https://github.com/Priyal-0911/Speech-Enhancement-Noise-Reduction/graphs/code-frequency)|
|[Resemble Enhance](https://github.com/resemble-ai/resemble-enhance#readme)|An AI-powered tool that aims to improve the overall quality of speech by performing denoising and enhancement|[![](https://img.shields.io/github/languages/top/resemble-ai/resemble-enhance?color=pink&style=flat-square)](https://github.com/resemble-ai/resemble-enhance/graphs/contributors)|[![](https://flat.badgen.net/github/license/resemble-ai/resemble-enhance?label=)](https://github.com/resemble-ai/resemble-enhance/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/resemble-ai/resemble-enhance?style=flat-square&label=)](https://github.com/resemble-ai/resemble-enhance/graphs/code-frequency)|
|[ClearerVoice-Studio](https://github.com/modelscope/ClearerVoice-Studio#readme)|An AI-Powered Speech Processing Toolkit and Open Source SOTA Pretrained Models, Supporting Speech Enhancement, Separation, and Target Speaker Extraction|[![](https://img.shields.io/github/languages/top/modelscope/ClearerVoice-Studio?color=pink&style=flat-square)](https://github.com/modelscope/ClearerVoice-Studio/graphs/contributors)|[![](https://flat.badgen.net/github/license/modelscope/ClearerVoice-Studio?label=)](https://github.com/modelscope/ClearerVoice-Studio/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/modelscope/ClearerVoice-Studio?style=flat-square&label=)](https://github.com/modelscope/ClearerVoice-Studio/graphs/code-frequency)|
|[Deep Learning Based Noise Reduction and Speech Enhancement System](https://github.com/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction#readme)|Implements two deep learning models, one can classify the type of noise, the other can retain human voice and reduce environmental noise|[![](https://img.shields.io/github/languages/top/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction?color=pink&style=flat-square)](https://github.com/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction/graphs/contributors)|[![](https://flat.badgen.net/github/license/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction?label=)](https://github.com/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction?style=flat-square&label=)](https://github.com/shhubhxm/Deep-Learning-Based-Speech-Enhancement-System-and-Noise-Reduction/graphs/code-frequency)|


### Stylers [⌂](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[AutoPST](https://github.com/auspicious3000/AutoPST#readme)|Global Rhythm Style Transfer Without Text Transcriptions|[![](https://img.shields.io/github/languages/top/auspicious3000/AutoPST?color=pink&style=flat-square)](https://github.com/auspicious3000/AutoPST/graphs/contributors)|[![](https://flat.badgen.net/github/license/auspicious3000/AutoPST?label=)](https://github.com/auspicious3000/AutoPST/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/auspicious3000/AutoPST?style=flat-square&label=)](https://github.com/auspicious3000/AutoPST/graphs/code-frequency)|
|[AutoVC](https://github.com/auspicious3000/autovc#readme)|Zero-Shot Voice Style Transfer with Only Autoencoder Loss|[![](https://img.shields.io/github/languages/top/auspicious3000/autovc?color=pink&style=flat-square)](https://github.com/auspicious3000/autovc/graphs/contributors)|[![](https://flat.badgen.net/github/license/auspicious3000/autovc?label=)](https://github.com/auspicious3000/autovc/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/auspicious3000/autovc?style=flat-square&label=)](https://github.com/auspicious3000/autovc/graphs/code-frequency)|
|[Voice Conversion with Non-Parallel Data](https://github.com/andabi/deep-voice-conversion#readme)|Deep neural networks for voice conversion (voice style transfer) in Tensorflow|[![](https://img.shields.io/github/languages/top/andabi/deep-voice-conversion?color=pink&style=flat-square)](https://github.com/andabi/deep-voice-conversion/graphs/contributors)|[![](https://flat.badgen.net/github/license/andabi/deep-voice-conversion?label=)](https://github.com/andabi/deep-voice-conversion/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/andabi/deep-voice-conversion?style=flat-square&label=)](https://github.com/andabi/deep-voice-conversion/graphs/code-frequency)|
|[StyleSinger](https://github.com/AaronZ345/StyleSinger#readme)|Code for [Style Transfer for Out-of-Domain Singing Voice Synthesis](https://ojs.aaai.org/index.php/AAAI/article/view/29932) paper|[![](https://img.shields.io/github/languages/top/AaronZ345/StyleSinger?color=pink&style=flat-square)](https://github.com/AaronZ345/StyleSinger/graphs/contributors)|[![](https://flat.badgen.net/github/license/AaronZ345/StyleSinger?label=)](https://github.com/AaronZ345/StyleSinger/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/AaronZ345/StyleSinger?style=flat-square&label=)](https://github.com/AaronZ345/StyleSinger/graphs/code-frequency)|
|[Voice style transfer with random CNN](https://github.com/mazzzystar/randomCNN-voice-transfer#readme)|Audio style transfer with shallow random parameters CNN|[![](https://img.shields.io/github/languages/top/mazzzystar/randomCNN-voice-transfer?color=pink&style=flat-square)](https://github.com/mazzzystar/randomCNN-voice-transfer/graphs/contributors)|[![](https://flat.badgen.net/github/license/mazzzystar/randomCNN-voice-transfer?label=)](https://github.com/mazzzystar/randomCNN-voice-transfer/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/mazzzystar/randomCNN-voice-transfer?style=flat-square&label=)](https://github.com/mazzzystar/randomCNN-voice-transfer/graphs/code-frequency)|
|[Robust-Voice-Style-Transfer](https://github.com/jlian2/Robust-Voice-Style-Transfer#readme)|Code for [Robust Disentangled Variational Speech Representation Learning for Zero-Shot Voice Conversion](https://arxiv.org/abs/2203.16705) paper|[![](https://img.shields.io/github/languages/top/jlian2/Robust-Voice-Style-Transfer?color=pink&style=flat-square)](https://github.com/jlian2/Robust-Voice-Style-Transfer/graphs/contributors)|[![](https://flat.badgen.net/github/license/jlian2/Robust-Voice-Style-Transfer?label=)](https://github.com/jlian2/Robust-Voice-Style-Transfer/issues/4)|[![](https://img.shields.io/github/last-commit/jlian2/Robust-Voice-Style-Transfer?style=flat-square&label=)](https://github.com/jlian2/Robust-Voice-Style-Transfer/graphs/code-frequency)|


### Speech [⌂](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[ASRT](https://github.com/nl8590687/ASRT_SpeechRecognition#readme)|A Deep-Learning-Based Chinese Speech Recognition System|[![](https://img.shields.io/github/languages/top/nl8590687/ASRT_SpeechRecognition?color=pink&style=flat-square)](https://github.com/nl8590687/ASRT_SpeechRecognition/graphs/contributors)|[![](https://flat.badgen.net/github/license/nl8590687/ASRT_SpeechRecognition?label=)](https://github.com/nl8590687/ASRT_SpeechRecognition/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/nl8590687/ASRT_SpeechRecognition?style=flat-square&label=)](https://github.com/nl8590687/ASRT_SpeechRecognition/graphs/code-frequency)|
|[whisper.cpp](https://github.com/ggerganov/whisper.cpp#readme)|High-performance inference of [OpenAI's Whisper](https://github.com/openai/whisper) automatic speech recognition (ASR) model|[![](https://img.shields.io/github/languages/top/ggerganov/whisper.cpp?color=pink&style=flat-square)](https://github.com/ggerganov/whisper.cpp/graphs/contributors)|[![](https://flat.badgen.net/github/license/ggerganov/whisper.cpp?label=)](https://github.com/ggerganov/whisper.cpp/blob/master/LICENSE)|[![](https://img.shields.io/github/last-commit/ggerganov/whisper.cpp?style=flat-square&label=)](https://github.com/ggerganov/whisper.cpp/graphs/code-frequency)|


### TTSers [⌂](#---) 
|Repository|Short description|Language|License|Last commit|
|:-:|:-:|:-:|:-:|:-:|
|[OpenTTS](https://github.com/ningjx/OpenTTS#readme)|Use Microsoft speech synthesis to generate your own voice package|[![](https://img.shields.io/github/languages/top/ningjx/OpenTTS?color=pink&style=flat-square)](https://github.com/ningjx/OpenTTS/graphs/contributors)|[![](https://flat.badgen.net/github/license/ningjx/OpenTTS?label=)](https://github.com/ningjx/OpenTTS/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/ningjx/OpenTTS?style=flat-square&label=)](https://github.com/ningjx/OpenTTS/graphs/code-frequency)|
|[TorToiSe](https://github.com/neonbjb/tortoise-tts#readme)|A multi-voice TTS system trained with an emphasis on quality|[![](https://img.shields.io/github/languages/top/neonbjb/tortoise-tts?color=pink&style=flat-square)](https://github.com/neonbjb/tortoise-tts/graphs/contributors)|[![](https://flat.badgen.net/github/license/neonbjb/tortoise-tts?label=)](https://github.com/neonbjb/tortoise-tts/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/neonbjb/tortoise-tts?style=flat-square&label=)](https://github.com/neonbjb/tortoise-tts/graphs/code-frequency)|
|[coquiTTS](https://github.com/coqui-ai/TTS#readme)|A deep learning toolkit for Text-to-Speech, battle-tested in research and production|[![](https://img.shields.io/github/languages/top/coqui-ai/TTS?color=pink&style=flat-square)](https://github.com/coqui-ai/TTS/graphs/contributors)|[![](https://flat.badgen.net/github/license/coqui-ai/TTS?label=)](https://github.com/coqui-ai/TTS/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/coqui-ai/TTS?style=flat-square&label=)](https://github.com/coqui-ai/TTS/graphs/code-frequency)|
|[Fish Speech](https://github.com/fishaudio/fish-speech#readme)|SOTA Open Source TTS|[![](https://img.shields.io/github/languages/top/fishaudio/fish-speech?color=pink&style=flat-square)](https://github.com/fishaudio/fish-speech/graphs/contributors)|[![](https://flat.badgen.net/github/license/fishaudio/fish-speech?label=)](https://github.com/fishaudio/fish-speech/blob/main/LICENSE)|[![](https://img.shields.io/github/last-commit/fishaudio/fish-speech?style=flat-square&label=)](https://github.com/fishaudio/fish-speech/graphs/code-frequency)|

